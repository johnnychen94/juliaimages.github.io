<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Summary and function reference · JuliaImages</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../democards/cardtheme.css" rel="stylesheet" type="text/css"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="JuliaImages logo"/></a><div class="docs-package-name"><span class="docs-autofit">JuliaImages</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../install/">Getting started: Installation and testing your install</a></li><li><span class="tocitem">Manual</span><ul><li><a class="tocitem" href="../quickstart/">Quickstart</a></li><li><a class="tocitem" href="../arrays_colors/">Arrays, Numbers, and Colors</a></li><li><a class="tocitem" href="../conversions_views/">Conversions vs. views</a></li><li><a class="tocitem" href="../indexing/">Arrays: more advanced indexing</a></li><li><a class="tocitem" href="../imageaxes/">ImageAxes.jl</a></li><li><a class="tocitem" href="../imagefiltering/">ImageFiltering.jl</a></li><li><a class="tocitem" href="../imagemetadata/">ImageMetadata.jl</a></li><li><a class="tocitem" href="../imagesegmentation/">ImageSegmentation.jl</a></li><li><a class="tocitem" href="../imagetransformations/">ImageTransformations.jl</a></li><li><a class="tocitem" href="../imagefeatures/">ImageFeatures.jl</a></li><li><a class="tocitem" href="../troubleshooting/">Installation troubleshooting</a></li></ul></li><li><a class="tocitem" href="../democards/examples/">Demos</a></li><li class="is-active"><a class="tocitem" href>Summary and function reference</a><ul class="internal"><li><a class="tocitem" href="#Image-loading-and-saving-1"><span>Image loading and saving</span></a></li><li><a class="tocitem" href="#Image-construction,-conversion,-and-views-1"><span>Image construction, conversion, and views</span></a></li><li><a class="tocitem" href="#Traits-1"><span>Traits</span></a></li><li><a class="tocitem" href="#Element-transformation-and-intensity-scaling-1"><span>Element transformation and intensity scaling</span></a></li><li><a class="tocitem" href="#Storage-type-transformation-1"><span>Storage-type transformation</span></a></li><li><a class="tocitem" href="#Color-conversion-1"><span>Color conversion</span></a></li><li><a class="tocitem" href="#Image-algorithms-1"><span>Image algorithms</span></a></li><li><a class="tocitem" href="#Image-metadata-utilities-1"><span>Image metadata utilities</span></a></li><li><a class="tocitem" href="#Image-segmentation-1"><span>Image segmentation</span></a></li><li><a class="tocitem" href="#ImageFeatures-1"><span>ImageFeatures</span></a></li></ul></li><li><a class="tocitem" href="../api_comparison/">Comparison with other image processing frameworks</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Summary and function reference</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Summary and function reference</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaImages/juliaimages.github.io/blob/source/docs/src/function_reference.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Summary-and-function-reference-1"><a class="docs-heading-anchor" href="#Summary-and-function-reference-1">Summary and function reference</a><a class="docs-heading-anchor-permalink" href="#Summary-and-function-reference-1" title="Permalink"></a></h1><p>Below, <code>[]</code> in an argument list means an optional argument.</p><h2 id="Image-loading-and-saving-1"><a class="docs-heading-anchor" href="#Image-loading-and-saving-1">Image loading and saving</a><a class="docs-heading-anchor-permalink" href="#Image-loading-and-saving-1" title="Permalink"></a></h2><pre><code class="language-julia">using FileIO
img = load(&quot;myimage.png&quot;)
save(&quot;imagecopy.jpg&quot;, img)</code></pre><p>Standard test images are available in the <a href="http://juliaimages.github.io/TestImages.jl">TestImages</a> package:</p><pre><code class="language-julia">using TestImages
img = testimage(&quot;mandrill&quot;)</code></pre><h2 id="Image-construction,-conversion,-and-views-1"><a class="docs-heading-anchor" href="#Image-construction,-conversion,-and-views-1">Image construction, conversion, and views</a><a class="docs-heading-anchor-permalink" href="#Image-construction,-conversion,-and-views-1" title="Permalink"></a></h2><p>Any array can be treated as an Image.  In graphical environments, only arrays with <a href="https://github.com/JuliaGraphics/ColorTypes.jl"><code>Colorant</code></a> element types (<code>Gray</code>, <code>RGB</code>, <code>ARGB</code>, etc.) are automatically displayed as images.</p><article class="docstring"><header><a class="docstring-binding" id="ImageCore.colorview" href="#ImageCore.colorview"><code>ImageCore.colorview</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">colorview(C, A)</code></pre><p>returns a view of the numeric array <code>A</code>, interpreting successive elements of <code>A</code> as if they were channels of Colorant <code>C</code>.</p><p>Of relevance for types like RGB and BGR, the elements of <code>A</code> are interpreted in constructor-argument order, not memory order (see <code>reinterpretc</code> if you want to use memory order).</p><p><strong>Example</strong></p><pre><code class="language-jl">A = rand(3, 10, 10)
img = colorview(RGB, A)</code></pre><p>See also: <a href="#ImageCore.channelview"><code>channelview</code></a></p></div></section><section><div><pre><code class="language-none">colorview(C, gray1, gray2, ...) -&gt; imgC</code></pre><p>Combine numeric/grayscale images <code>gray1</code>, <code>gray2</code>, etc., into the separate color channels of an array <code>imgC</code> with element type <code>C&lt;:Colorant</code>.</p><p>As a convenience, the constant <code>zeroarray</code> fills in an array of matched size with all zeros.</p><p><strong>Example</strong></p><pre><code class="language-julia">imgC = colorview(RGB, r, zeroarray, b)</code></pre><p>creates an image with <code>r</code> in the red chanel, <code>b</code> in the blue channel, and nothing in the green channel.</p><p>See also: <a href="#ImageCore.StackedView"><code>StackedView</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageCore.channelview" href="#ImageCore.channelview"><code>ImageCore.channelview</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">channelview(A)</code></pre><p>returns a view of <code>A</code>, splitting out (if necessary) the color channels of <code>A</code> into a new first dimension.</p><p>Of relevance for types like RGB and BGR, the channels of the returned array will be in constructor-argument order, not memory order (see <code>reinterpretc</code> if you want to use memory order).</p><p><strong>Example</strong></p><p>```julia img = rand(RGB{N0f8}, 10, 10) A = channelview(img)   # a 3×10×10 array</p><p>See also: <a href="#ImageCore.colorview"><code>colorview</code></a></p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageCore.normedview" href="#ImageCore.normedview"><code>ImageCore.normedview</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">normedview([T], img::AbstractArray{Unsigned})</code></pre><p>returns a &quot;view&quot; of <code>img</code> where the values are interpreted in terms of <code>Normed</code> number types. For example, if <code>img</code> is an <code>Array{UInt8}</code>, the view will act like an <code>Array{N0f8}</code>.  Supply <code>T</code> if the element type of <code>img</code> is <code>UInt16</code>, to specify whether you want a <code>N6f10</code>, <code>N4f12</code>, <code>N2f14</code>, or <code>N0f16</code> result.</p><p>See also: <a href="#ImageCore.rawview"><code>rawview</code></a></p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageCore.rawview" href="#ImageCore.rawview"><code>ImageCore.rawview</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">rawview(img::AbstractArray{FixedPoint})</code></pre><p>returns a &quot;view&quot; of <code>img</code> where the values are interpreted in terms of their raw underlying storage. For example, if <code>img</code> is an <code>Array{N0f8}</code>, the view will act like an <code>Array{UInt8}</code>.</p><p>See also: <a href="#ImageCore.normedview"><code>normedview</code></a></p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageCore.permuteddimsview" href="#ImageCore.permuteddimsview"><code>ImageCore.permuteddimsview</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">permuteddimsview(A, perm)</code></pre><p>returns a &quot;view&quot; of <code>A</code> with its dimensions permuted as specified by <code>perm</code>. This is like <code>permutedims</code>, except that it produces a view rather than a copy of <code>A</code>; consequently, any manipulations you make to the output will be mirrored in <code>A</code>. Compared to the copy, the view is much faster to create, but generally slower to use.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageCore.StackedView" href="#ImageCore.StackedView"><code>ImageCore.StackedView</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">StackedView(B, C, ...) -&gt; A</code></pre><p>Present arrays <code>B</code>, <code>C</code>, etc, as if they are separate channels along the first dimension of <code>A</code>. In particular,</p><pre><code class="language-none">B == A[1,:,:...]
C == A[2,:,:...]</code></pre><p>and so on. Combined with <code>colorview</code>, this allows one to combine two or more grayscale images into a single color image.</p><p>See also: <a href="#ImageCore.colorview"><code>colorview</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="PaddedViews.paddedviews" href="#PaddedViews.paddedviews"><code>PaddedViews.paddedviews</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">Aspad = paddedviews(fillvalue, A1, A2, ....)</code></pre><p>Pad the arrays <code>A1</code>, <code>A2</code>, ..., to a common size or set of axes, chosen as the span of axes enclosing all of the input arrays.</p><p><strong>Example:</strong></p><pre><code class="language-julia">julia&gt; a1 = reshape([1,2], 2, 1)
2×1 Array{Int64,2}:
 1
 2

julia&gt; a2 = [1.0,2.0]&#39;
1×2 Array{Float64,2}:
 1.0  2.0

julia&gt; a1p, a2p = paddedviews(0, a1, a2);

julia&gt; a1p
2×2 PaddedViews.PaddedView{Int64,2,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},Array{Int64,2}}:
 1  0
 2  0

julia&gt; a2p
2×2 PaddedViews.PaddedView{Float64,2,Tuple{Base.OneTo{Int64},Base.OneTo{Int64}},Array{Float64,2}}:
 1.0  2.0
 0.0  0.0</code></pre></div></section></article><p>Images with defined geometry and axis meaning can be constructed using the <a href="https://github.com/JuliaArrays/AxisArrays.jl"><code>AxisArrays</code></a> package:</p><pre><code class="language-julia">using AxisArrays
img = AxisArray(A, (:y, :x, :time), (0.25μm, 0.25μm, 0.125s))  # see Unitful.jl for units</code></pre><p>Custom metadata can be added as follows:</p><pre><code class="language-julia">img = ImageMeta(A, date=now(), patientID=12345)</code></pre><p>Any of these operations may be composed together, e.g., if you have an <code>m×n×3 UInt8</code> array, you can put it in canonical RGB format and add metadata:</p><pre><code class="language-julia">img = ImageMeta(colorview(RGB, normedview(permuteddimsview(A, (3,1,2)))), sample=&quot;control&quot;)</code></pre><h2 id="Traits-1"><a class="docs-heading-anchor" href="#Traits-1">Traits</a><a class="docs-heading-anchor-permalink" href="#Traits-1" title="Permalink"></a></h2><p>These functions are the preferred way to access certain types of &quot;internal&quot; data about an image. They can sometimes be useful in allowing you to write generic code.</p><article class="docstring"><header><a class="docstring-binding" id="ImageCore.pixelspacing" href="#ImageCore.pixelspacing"><code>ImageCore.pixelspacing</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">pixelspacing(img) -&gt; (sx, sy, ...)</code></pre><p>Return a tuple representing the separation between adjacent pixels along each axis of the image.  Defaults to (1,1,...).  Use ImagesAxes for images with anisotropic spacing or to encode the spacing using physical units.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageCore.spacedirections" href="#ImageCore.spacedirections"><code>ImageCore.spacedirections</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">spacedirections(img) -&gt; (axis1, axis2, ...)</code></pre><p>Return a tuple-of-tuples, each <code>axis[i]</code> representing the displacement vector between adjacent pixels along spatial axis <code>i</code> of the image array, relative to some external coordinate system (&quot;physical coordinates&quot;).</p><p>By default this is computed from <code>pixelspacing</code>, but you can set this manually using ImagesMeta.</p></div></section><section><div><pre><code class="language-none">spacedirections(img)</code></pre><p>Using ImageMetadata, you can set this property manually. For example, you could indicate that a photograph was taken with the camera tilted 30-degree relative to vertical using</p><pre><code class="language-none">img[&quot;spacedirections&quot;] = ((0.866025,-0.5),(0.5,0.866025))</code></pre><p>If not specified, it will be computed from <code>pixelspacing(img)</code>, placing the spacing along the &quot;diagonal&quot;.  If desired, you can set this property in terms of physical units, and each axis can have distinct units.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageCore.sdims" href="#ImageCore.sdims"><code>ImageCore.sdims</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">sdims(img)</code></pre><p>Return the number of spatial dimensions in the image. Defaults to the same as <code>ndims</code>, but with ImagesAxes you can specify that some axes correspond to other quantities (e.g., time) and thus not included by <code>sdims</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageCore.coords_spatial" href="#ImageCore.coords_spatial"><code>ImageCore.coords_spatial</code></a> — <span class="docstring-category">Function</span></header><section><div><p>coords_spatial(img)</p><p>Return a tuple listing the spatial dimensions of <code>img</code>.</p><p>Note that a better strategy may be to use ImagesAxes and take slices along the time axis.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageCore.size_spatial" href="#ImageCore.size_spatial"><code>ImageCore.size_spatial</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">size_spatial(img)</code></pre><p>Return a tuple listing the sizes of the spatial dimensions of the image. Defaults to the same as <code>size</code>, but using ImagesAxes you can mark some axes as being non-spatial.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageCore.indices_spatial" href="#ImageCore.indices_spatial"><code>ImageCore.indices_spatial</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">indices_spatial(img)</code></pre><p>Return a tuple with the indices of the spatial dimensions of the image. Defaults to the same as <code>indices</code>, but using ImagesAxes you can mark some axes as being non-spatial.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageCore.nimages" href="#ImageCore.nimages"><code>ImageCore.nimages</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">nimages(img)</code></pre><p>Return the number of time-points in the image array. Defaults to</p><ol><li>Use ImagesAxes if you want to use an explicit time dimension.</li></ol></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageCore.assert_timedim_last" href="#ImageCore.assert_timedim_last"><code>ImageCore.assert_timedim_last</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">assert_timedim_last(img)</code></pre><p>Throw an error if the image has a time dimension that is not the last dimension.</p></div></section></article><h2 id="Element-transformation-and-intensity-scaling-1"><a class="docs-heading-anchor" href="#Element-transformation-and-intensity-scaling-1">Element transformation and intensity scaling</a><a class="docs-heading-anchor-permalink" href="#Element-transformation-and-intensity-scaling-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ImageCore.clamp01" href="#ImageCore.clamp01"><code>ImageCore.clamp01</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">clamp01(x) -&gt; y</code></pre><p>Produce a value <code>y</code> that lies between 0 and 1, and equal to <code>x</code> when <code>x</code> is already in this range. Equivalent to <code>clamp(x, 0, 1)</code> for numeric values. For colors, this function is applied to each color channel separately.</p><p>See also: <a href="@ref"><code>clamp01!</code></a>, <a href="#ImageCore.clamp01nan"><code>clamp01nan</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageCore.clamp01nan" href="#ImageCore.clamp01nan"><code>ImageCore.clamp01nan</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">clamp01nan(x) -&gt; y</code></pre><p>Similar to <code>clamp01</code>, except that any <code>NaN</code> values are changed to 0.</p><p>See also: <a href="@ref"><code>clamp01nan!</code></a>, <a href="#ImageCore.clamp01"><code>clamp01</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageCore.scaleminmax" href="#ImageCore.scaleminmax"><code>ImageCore.scaleminmax</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">scaleminmax(min, max) -&gt; f
scaleminmax(T, min, max) -&gt; f</code></pre><p>Return a function <code>f</code> which maps values less than or equal to <code>min</code> to 0, values greater than or equal to <code>max</code> to 1, and uses a linear scale in between. <code>min</code> and <code>max</code> should be real values.</p><p>Optionally specify the return type <code>T</code>. If <code>T</code> is a colorant (e.g., RGB), then scaling is applied to each color channel.</p><p><strong>Examples</strong></p><p><strong>Example 1</strong></p><pre><code class="language-julia">julia&gt; f = scaleminmax(-10, 10)
(::#9) (generic function with 1 method)

julia&gt; f(10)
1.0

julia&gt; f(-10)
0.0

julia&gt; f(5)
0.75</code></pre><p><strong>Example 2</strong></p><pre><code class="language-julia">julia&gt; c = RGB(255.0,128.0,0.0)
RGB{Float64}(255.0,128.0,0.0)

julia&gt; f = scaleminmax(RGB, 0, 255)
(::#13) (generic function with 1 method)

julia&gt; f(c)
RGB{Float64}(1.0,0.5019607843137255,0.0)</code></pre><p>See also: <a href="#ImageCore.takemap"><code>takemap</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageCore.scalesigned" href="#ImageCore.scalesigned"><code>ImageCore.scalesigned</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">scalesigned(maxabs) -&gt; f</code></pre><p>Return a function <code>f</code> which scales values in the range <code>[-maxabs, maxabs]</code> (clamping values that lie outside this range) to the range <code>[-1, 1]</code>.</p><p>See also: <a href="#ImageCore.colorsigned"><code>colorsigned</code></a>.</p></div></section><section><div><pre><code class="language-none">scalesigned(min, center, max) -&gt; f</code></pre><p>Return a function <code>f</code> which scales values in the range <code>[min, center]</code> to <code>[-1,0]</code> and <code>[center,max]</code> to <code>[0,1]</code>. Values smaller than <code>min</code>/<code>max</code> get clamped to <code>min</code>/<code>max</code>, respectively.</p><p>See also: <a href="#ImageCore.colorsigned"><code>colorsigned</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageCore.colorsigned" href="#ImageCore.colorsigned"><code>ImageCore.colorsigned</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">colorsigned()
colorsigned(colorneg, colorpos) -&gt; f
colorsigned(colorneg, colorcenter, colorpos) -&gt; f</code></pre><p>Define a function that maps negative values (in the range [-1,0]) to the linear colormap between <code>colorneg</code> and <code>colorcenter</code>, and positive values (in the range [0,1]) to the linear colormap between <code>colorcenter</code> and <code>colorpos</code>.</p><p>The default colors are:</p><ul><li><code>colorcenter</code>: white</li><li><code>colorneg</code>: green1</li><li><code>colorpos</code>: magenta</li></ul><p>See also: <a href="#ImageCore.scalesigned"><code>scalesigned</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageCore.takemap" href="#ImageCore.takemap"><code>ImageCore.takemap</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">takemap(f, A) -&gt; fnew
takemap(f, T, A) -&gt; fnew</code></pre><p>Given a value-mapping function <code>f</code> and an array <code>A</code>, return a &quot;concrete&quot; mapping function <code>fnew</code>. When applied to elements of <code>A</code>, <code>fnew</code> should return valid values for storage or display, for example in the range from 0 to 1 (for grayscale) or valid colorants. <code>fnew</code> may be adapted to the actual values present in <code>A</code>, and may not produce valid values for any inputs not in <code>A</code>.</p><p>Optionally one can specify the output type <code>T</code> that <code>fnew</code> should produce.</p><p><strong>Example:</strong></p><pre><code class="language-julia">julia&gt; A = [0, 1, 1000];

julia&gt; f = takemap(scaleminmax, A)
(::#7) (generic function with 1 method)

julia&gt; f.(A)
3-element Array{Float64,1}:
 0.0
 0.001
 1.0</code></pre></div></section></article><h2 id="Storage-type-transformation-1"><a class="docs-heading-anchor" href="#Storage-type-transformation-1">Storage-type transformation</a><a class="docs-heading-anchor-permalink" href="#Storage-type-transformation-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ImageCore.float32" href="#ImageCore.float32"><code>ImageCore.float32</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">float32.(img)</code></pre><p>converts the raw storage type of <code>img</code> to <code>Float32</code>, without changing the color space.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageCore.float64" href="#ImageCore.float64"><code>ImageCore.float64</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">float64.(img)</code></pre><p>converts the raw storage type of <code>img</code> to <code>Float64</code>, without changing the color space.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageCore.n0f8" href="#ImageCore.n0f8"><code>ImageCore.n0f8</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">n0f8.(img)</code></pre><p>converts the raw storage type of <code>img</code> to <code>N0f8</code>, without changing the color space.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageCore.n6f10" href="#ImageCore.n6f10"><code>ImageCore.n6f10</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">n6f10.(img)</code></pre><p>converts the raw storage type of <code>img</code> to <code>N6f10</code>, without changing the color space.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageCore.n4f12" href="#ImageCore.n4f12"><code>ImageCore.n4f12</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">n4f12.(img)</code></pre><p>converts the raw storage type of <code>img</code> to <code>N4f12</code>, without changing the color space.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageCore.n2f14" href="#ImageCore.n2f14"><code>ImageCore.n2f14</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">n2f14.(img)</code></pre><p>converts the raw storage type of <code>img</code> to <code>N2f14</code>, without changing the color space.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageCore.n0f16" href="#ImageCore.n0f16"><code>ImageCore.n0f16</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">n0f16.(img)</code></pre><p>converts the raw storage type of <code>img</code> to <code>N0f16</code>, without changing the color space.</p></div></section></article><h2 id="Color-conversion-1"><a class="docs-heading-anchor" href="#Color-conversion-1">Color conversion</a><a class="docs-heading-anchor-permalink" href="#Color-conversion-1" title="Permalink"></a></h2><pre><code class="language-julia">imgg = Gray.(img)</code></pre><p>calculates a grayscale representation of a color image using the <a href="http://en.wikipedia.org/wiki/Luma_%28video%29#Rec._601_luma_versus_Rec._709_luma_coefficients">Rec 601 luma</a>.</p><pre><code class="language-julia">imghsv = HSV.(img)</code></pre><p>converts to an HSV representation of color information.</p><h2 id="Image-algorithms-1"><a class="docs-heading-anchor" href="#Image-algorithms-1">Image algorithms</a><a class="docs-heading-anchor-permalink" href="#Image-algorithms-1" title="Permalink"></a></h2><h3 id="Linear-filtering-1"><a class="docs-heading-anchor" href="#Linear-filtering-1">Linear filtering</a><a class="docs-heading-anchor-permalink" href="#Linear-filtering-1" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.imfilter" href="#ImageFiltering.imfilter"><code>ImageFiltering.imfilter</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">imfilter([T], img, kernel, [border=&quot;replicate&quot;], [alg]) --&gt; imgfilt
imfilter([r], img, kernel, [border=&quot;replicate&quot;], [alg]) --&gt; imgfilt
imfilter(r, T, img, kernel, [border=&quot;replicate&quot;], [alg]) --&gt; imgfilt</code></pre><p>Filter a one, two or multidimensional array <code>img</code> with a <code>kernel</code> by computing their correlation.</p><p><strong>Details</strong></p><p>The term <em>filtering</em> emerges in the context of a Fourier transformation of an image, which maps an image from its canonical spatial domain to its concomitant frequency domain. Manipulating an image in the frequency domain amounts to retaining or discarding particular frequency components—a process analogous to sifting or filtering [1].  Because the Fourier transform establishes a link between the spatial and frequency representation of an image, one can interpret various image manipulations in the spatial domain as filtering operations which accept or reject specific frequencies.</p><p>The phrase <em>spatial filtering</em> is often used to emphasise that an operation is, at least conceptually, devised in the context of the spatial domain of an image. One further distinguishes between linear and non-linear spatial filtering. A filter is called linear if the operation performed on the pixels is linear, and is labeled non-linear otherwise.</p><p>An image filter can be represented by a function</p><div>\[ w: \{s\in \mathbb{Z} \mid -k_1 \le s \le k_1  \} \times  \{t \in \mathbb{Z} \mid -k_2 \le t \le k_2  \}   \rightarrow \mathbb{R},\]</div><p>where <span>$k_i  \in \mathbb{N}$</span> (i = 1,2). It is common to define <span>$k_1 = 2a+1$</span> and <span>$k_2 = 2b + 1$</span>, where <span>$a$</span> and <span>$b$</span> are integers, which ensures that the filter dimensions are of odd size. Typically, <span>$k_1$</span> equals <span>$k_2$</span> and so, dropping the subscripts, one speaks of a <span>$k \times k$</span> filter. Since the domain of the filter represents a grid of spatial coordinates, the filter is often called a mask and is visualized as a grid. For example, a <span>$3 \times 3$</span> mask can be potrayed as follows:</p><div>\[\scriptsize
\begin{matrix}
\boxed{
\begin{matrix}
\phantom{w(-9,-9)} \\
w(-1,-1) \\
\phantom{w(-9,-9)} \\
\end{matrix}
}

&amp;

\boxed{
\begin{matrix}
\phantom{w(-9,-9)} \\
w(-1,0) \\
\phantom{w(-9,-9)} \\
\end{matrix}
}
 &amp;
\boxed{
\begin{matrix}
\phantom{w(-9,-9)} \\
w(-1,1) \\
\phantom{w(-9,-9)} \\
\end{matrix}
}
\\
\\
\boxed{
\begin{matrix}
\phantom{w(-9,-9)} \\
w(0,-1) \\
\phantom{w(-9,-9)} \\
\end{matrix}
}

&amp;

\boxed{
\begin{matrix}
\phantom{w(-9,-9)} \\
w(0,0) \\
\phantom{w(-9,-9)} \\
\end{matrix}
}
 &amp;
\boxed{
\begin{matrix}
\phantom{w(-9,-9)} \\
w(0,1) \\
\phantom{w(-9,-9)} \\
\end{matrix}
}
\\
\\
\boxed{
\begin{matrix}
\phantom{w(-9,-9)} \\
w(1,-1) \\
\phantom{w(-9,-9)} \\
\end{matrix}
}

&amp;

\boxed{
\begin{matrix}
\phantom{w(-9,-9)} \\
w(1,0) \\
\phantom{w(-9,-9)} \\
\end{matrix}
}
 &amp;
\boxed{
\begin{matrix}
\phantom{w(-9,-9)} \\
w(1,1) \\
\phantom{w(-9,-9)} \\
\end{matrix}
}
\end{matrix}.\]</div><p>The values of <span>$w(s,t)$</span> are referred to as <em>filter coefficients</em>.</p><p><strong>Discrete convolution versus correlation</strong></p><p>There are two fundamental and closely related operations that one regularly performs on an image with a filter. The operations are called discrete <em>correlation</em> and <em>convolution</em>.</p><p>The correlation operation, denoted by the symbol <span>$\star$</span>,  is given in two dimensions by the expression</p><div>\[\begin{aligned}
g(x,y) = w(x,y) \star f(x,y) = \sum_{s = -a}^{a} \sum_{t=-b}^{b} w(s,t) f(x+s, y+t),
\end{aligned}\]</div><p>whereas the comparable convolution operation, denoted by the symbol <span>$\ast$</span>, is given in two dimensions by</p><div>\[\begin{aligned}
h(x,y) = w(x,y) \ast f(x,y) = \sum_{s = -a}^{a} \sum_{t=-b}^{b} w(s,t) f(x-s, y-t).
\end{aligned}\]</div><p>Since a digital image is of finite extent, both of these operations are undefined at the borders of the image. In particular, for an image of size <span>$M \times N$</span>, the function <span>$f(x \pm s, y \pm t)$</span> is only defined for <span>$1 \le x \pm s \le N$</span> and <span>$1 \le y \pm t \le M$</span>. In practice one addresses this problem by artificially expanding the domain of the image. For example, one can pad the image with zeros. Other padding strategies are possible, and they are discussed in more detail in the <em>Options</em> section of this documentation.</p><p><strong>One-dimensional illustration</strong></p><p>The difference between correlation and convolution is best understood with recourse to a one-dimensional example  adapted from [1]. Suppose that a filter <span>$w:\{-1,0,1\}\rightarrow \mathbb{R}$</span> has coefficients</p><div>\[\begin{matrix}
\boxed{1} &amp; \boxed{2} &amp; \boxed{3}
\end{matrix}.\]</div><p>Consider a discrete unit impulse function <span>$f: \{x \in \mathbb{Z} \mid 1 \le x \le 7  \} \rightarrow \{0,1\}$</span>  that has been padded with zeros. The function can be visualised as an image</p><div>\[\boxed{
\begin{matrix}
0 &amp; \boxed{0} &amp; \boxed{0} &amp; \boxed{0} &amp; \boxed{1} &amp; \boxed{0} &amp; \boxed{0} &amp; \boxed{0} &amp; 0
\end{matrix}}.\]</div><p>The correlation operation can be interpreted as sliding <span>$w$</span> along the image and computing the sum of products at each location. For example,</p><div>\[\begin{matrix}
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
1 &amp; 2 &amp; 3  &amp;  &amp; &amp; &amp; &amp; &amp; \\
&amp; 1 &amp; 2 &amp; 3  &amp;  &amp; &amp; &amp; &amp;  \\
&amp; &amp; 1 &amp; 2 &amp; 3  &amp;  &amp; &amp; &amp;  \\
&amp; &amp; &amp; 1 &amp; 2 &amp; 3  &amp;  &amp; &amp;  \\
&amp; &amp; &amp; &amp; 1 &amp; 2 &amp; 3  &amp;  &amp;  \\
&amp; &amp; &amp; &amp; &amp; 1 &amp; 2 &amp; 3  &amp;  \\
&amp; &amp; &amp; &amp; &amp; &amp; 1 &amp; 2 &amp; 3,
\end{matrix}\]</div><p>yields the output <span>$g: \{x \in \mathbb{Z} \mid 1 \le x \le 7  \} \rightarrow \mathbb{R}$</span>, which when visualized as a digital image, is equal to</p><div>\[\boxed{
\begin{matrix}
\boxed{0} &amp; \boxed{0} &amp; \boxed{3} &amp; \boxed{2} &amp; \boxed{1} &amp; \boxed{0} &amp; \boxed{0}
\end{matrix}}.\]</div><p>The interpretation of the convolution operation is analogous to correlation, except that the filter <span>$w$</span> has been rotated by 180 degrees. In particular,</p><div>\[\begin{matrix}
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
3 &amp; 2 &amp; 1  &amp;  &amp; &amp; &amp; &amp; &amp; \\
&amp; 3 &amp; 2 &amp; 1  &amp;  &amp; &amp; &amp; &amp;  \\
&amp; &amp; 3 &amp; 2 &amp; 1  &amp;  &amp; &amp; &amp;  \\
&amp; &amp; &amp; 3 &amp; 2 &amp; 1  &amp;  &amp; &amp;  \\
&amp; &amp; &amp; &amp; 3 &amp; 2 &amp; 1  &amp;  &amp;  \\
&amp; &amp; &amp; &amp; &amp; 3 &amp; 2 &amp; 1  &amp;  \\
&amp; &amp; &amp; &amp; &amp; &amp; 3 &amp; 2 &amp; 1,
\end{matrix}\]</div><p>yields the output <span>$h: \{x \in \mathbb{Z} \mid 1 \le x \le 7  \} \rightarrow \mathbb{R}$</span> equal to</p><div>\[\boxed{
\begin{matrix}
\boxed{0} &amp; \boxed{0} &amp; \boxed{1} &amp; \boxed{2} &amp; \boxed{3} &amp; \boxed{0} &amp; \boxed{0}
\end{matrix}}.\]</div><p>Instead of rotating the filter mask, one could instead rotate <span>$f$</span> and still obtained the same convolution result. In fact, the conventional notation for convolution indicates that <span>$f$</span> is flipped and not <span>$w$</span>. If <span>$w$</span> is symmetric, then convolution and correlation give the same outcome.</p><p><strong>Two-dimensional illustration</strong></p><p>For a two-dimensional example, suppose the filter <span>$w:\{-1, 0 ,1\} \times  \{-1,0,1\} \rightarrow \mathbb{R}$</span>  has coefficients</p><div>\[ \begin{matrix}
 \boxed{1} &amp; \boxed{2} &amp; \boxed{3} \\ \\
 \boxed{4} &amp; \boxed{5} &amp; \boxed{6} \\ \\
 \boxed{7} &amp; \boxed{8} &amp; \boxed{9}
 \end{matrix},\]</div><p>and consider a two-dimensional discrete unit impulse function</p><div>\[ f:\{x \in \mathbb{Z} \mid 1 \le x \le 7  \} \times  \{y \in \mathbb{Z} \mid 1 \le y \le 7  \}\rightarrow \{ 0,1\}\]</div><p>that has been padded with zeros:</p><div>\[ \boxed{
 \begin{matrix}
   0 &amp;        0  &amp;        0  &amp;        0   &amp;        0  &amp;        0  &amp;   0  \\ \\
   0 &amp; \boxed{0} &amp; \boxed{0} &amp; \boxed{0}  &amp; \boxed{0} &amp; \boxed{0} &amp;   0  \\ \\
   0 &amp; \boxed{0} &amp; \boxed{0} &amp; \boxed{0}  &amp; \boxed{0} &amp; \boxed{0} &amp;   0 \\ \\
   0 &amp; \boxed{0} &amp; \boxed{0} &amp; \boxed{1}  &amp; \boxed{0} &amp; \boxed{0} &amp;   0 \\ \\
   0 &amp; \boxed{0} &amp; \boxed{0} &amp; \boxed{0}  &amp; \boxed{0} &amp; \boxed{0} &amp;   0 \\ \\
   0 &amp; \boxed{0} &amp; \boxed{0} &amp; \boxed{0}  &amp; \boxed{0} &amp; \boxed{0} &amp;   0 \\ \\
   0 &amp;        0  &amp;        0  &amp;        0   &amp;        0  &amp;        0  &amp;   0
 \end{matrix}}.\]</div><p>The correlation operation <span>$w(x,y) \star f(x,y)$</span>  yields the output</p><div>\[ \boxed{
 \begin{matrix}
 \boxed{0} &amp; \boxed{0}  &amp; \boxed{0} &amp; \boxed{0} &amp; \boxed{0} \\ \\
 \boxed{0} &amp;  \boxed{9} &amp; \boxed{8} &amp; \boxed{7} &amp; \boxed{0} \\ \\
 \boxed{0} &amp;  \boxed{6} &amp; \boxed{5} &amp; \boxed{4} &amp; \boxed{0} \\ \\
 \boxed{0} &amp;  \boxed{3} &amp; \boxed{2} &amp; \boxed{1} &amp; \boxed{0} \\ \\
 \boxed{0} &amp; \boxed{0}  &amp; \boxed{0} &amp; \boxed{0} &amp; \boxed{0}
 \end{matrix}},\]</div><p>whereas the convolution operation <span>$w(x,y) \ast f(x,y)$</span> produces</p><div>\[ \boxed{
 \begin{matrix}
 \boxed{0} &amp; \boxed{0} &amp; \boxed{0} &amp; \boxed{0} &amp; \boxed{0} \\ \\
 \boxed{0} &amp; \boxed{1} &amp; \boxed{2} &amp; \boxed{3} &amp; \boxed{0}\\ \\
 \boxed{0} &amp; \boxed{4} &amp; \boxed{5} &amp; \boxed{6} &amp; \boxed{0} \\ \\
 \boxed{0} &amp; \boxed{7} &amp; \boxed{8} &amp; \boxed{9} &amp; \boxed{0} \\ \\
 \boxed{0} &amp; \boxed{0} &amp; \boxed{0} &amp; \boxed{0} &amp; \boxed{0}
 \end{matrix}}.\]</div><p><strong>Discrete convolution and correlation as matrix multiplication</strong></p><p>Discrete convolution and correlation operations can also be formulated as a matrix multiplication, where one of the inputs is converted to a <a href="https://en.wikipedia.org/wiki/Toeplitz_matrix">Toeplitz</a> matrix, and the other is represented as a column vector. For example, consider a function <span>$f:\{x \in \mathbb{N} \mid 1 \le x \le M \} \rightarrow \mathbb{R}$</span> and a filter <span>$w: \{s \in \mathbb{N} \mid  -k_1 \le s \le k_1  \} \rightarrow \mathbb{R}$</span>. Then the matrix multiplication</p><div>\[\begin{bmatrix}
w(-k_1) 	&amp;  0	    &amp; \ldots	&amp; 0		   &amp; 0			\\
\vdots 	&amp; w(-k_1) 	&amp; \ldots	&amp; \vdots  &amp; 0	        \\
w(k_1) 	    &amp; \vdots   &amp; \ldots	&amp; 0		   &amp; \vdots    \\
0 	    	&amp; w(k_1)	&amp; \ldots   &amp; w(-k_1)  &amp; 0		    \\
0 	        &amp; 0		    &amp; \ldots	&amp; \vdots  &amp; w(-k_1)	\\
\vdots     &amp; \vdots	&amp; \ldots	&amp; w(k_1)   &amp; \vdots	\\
0           &amp; 0         &amp; 0			&amp; 0		   &amp; w(k_1)
\end{bmatrix}
\begin{bmatrix}
f(1) \\
f(2) \\
f(3) \\
\vdots \\
f(M)
\end{bmatrix}\]</div><p>is equivalent to the convolution <span>$w(s) \ast f(x)$</span> assuming that the border of <span>$f(x)$</span> has been padded with zeros.</p><p>To represent multidimensional convolution as matrix multiplication one reshapes the multidimensional arrays into column vectors and proceeds in an analogous manner. Naturally, the result of the matrix multiplication will need to be reshaped into an appropriate multidimensional array.</p><p><strong>Options</strong></p><p>The following subsections describe valid options for the function arguments in more detail.</p><p><strong>Choices for <code>r</code></strong></p><p>You can dispatch to different implementations by passing in a resource <code>r</code> as defined by the <a href="https://github.com/timholy/ComputationalResources.jl">ComputationalResources</a> package. For example,</p><pre><code class="language-julia">    imfilter(ArrayFireLibs(), img, kernel)</code></pre><p>would request that the computation be performed on the GPU using the ArrayFire libraries.</p><p><strong>Choices for <code>T</code></strong></p><p>Optionally, you can control the element type of the output image by passing in a type <code>T</code> as the first argument.</p><p><strong>Choices for <code>img</code></strong></p><p>You can specify a one, two or multidimensional array defining your image.</p><p><strong>Choices for <code>kernel</code></strong></p><p>The <code>kernel[0,0,..]</code> parameter corresponds to the origin (zero displacement) of the kernel; you can use <code>centered</code> to place the origin at the array center, or use the OffsetArrays package to set <code>kernel</code>&#39;s indices manually. For example, to filter with a random <em>centered</em> 3x3 kernel, you could use either of the following:</p><pre><code class="language-none">kernel = centered(rand(3,3))
kernel = OffsetArray(rand(3,3), -1:1, -1:1)</code></pre><p>The <code>kernel</code> parameter can be specified as an array or as a &quot;factored kernel&quot;, a tuple <code>(filt1, filt2, ...)</code> of filters to apply along each axis of the image. In cases where you know your kernel is separable, this format can speed processing. Each of these should have the same dimensionality as the image itself, and be shaped in a manner that indicates the filtering axis, e.g., a 3x1 filter for filtering the first dimension and a 1x3 filter for filtering the second dimension. In two dimensions, any kernel passed as a single matrix is checked for separability; if you want to eliminate that check, pass the kernel as a single-element tuple, <code>(kernel,)</code>.</p><p><strong>Choices for <code>border</code></strong></p><p>At the image edge, <code>border</code> is used to specify the padding which will be used to extrapolate the image beyond its original bounds. As an indicative example of each option the results of the padding are illustrated on an image consisting of a row of six pixels which are specified alphabetically: <span>$\boxed{a \, b \, c \, d \, e \, f}$</span>. We show the effects of padding only on the left and right border, but analogous consequences hold for the top and bottom border.</p><p><strong><code>&quot;replicate&quot;</code> (default)</strong></p><p>The border pixels extend beyond the image boundaries.</p><div>\[\boxed{
\begin{array}{l|c|r}
  a\, a\, a\, a  &amp;  a \, b \, c \, d \, e \, f &amp; f \, f \, f \, f
\end{array}
}\]</div><p>See also: <a href="#ImageFiltering.Pad"><code>Pad</code></a>, <a href="#ImageFiltering.padarray"><code>padarray</code></a>, <a href="#ImageFiltering.Inner"><code>Inner</code></a>, <a href="#ImageFiltering.NA"><code>NA</code></a>  and <a href="#ImageFiltering.NoPad"><code>NoPad</code></a></p><p><strong><code>&quot;circular&quot;</code></strong></p><p>The border pixels wrap around. For instance, indexing beyond the left border returns values starting from the right border.</p><div>\[\boxed{
\begin{array}{l|c|r}
  c\, d\, e\, f  &amp;  a \, b \, c \, d \, e \, f &amp; a \, b \, c \, d
\end{array}
}\]</div><p>See also: <a href="#ImageFiltering.Pad"><code>Pad</code></a>, <a href="#ImageFiltering.padarray"><code>padarray</code></a>, <a href="#ImageFiltering.Inner"><code>Inner</code></a>, <a href="#ImageFiltering.NA"><code>NA</code></a>  and <a href="#ImageFiltering.NoPad"><code>NoPad</code></a></p><p><strong><code>&quot;reflect&quot;</code></strong></p><p>The border pixels reflect relative to a position between pixels. That is, the border pixel is omitted when mirroring.</p><div>\[\boxed{
\begin{array}{l|c|r}
  e\, d\, c\, b  &amp;  a \, b \, c \, d \, e \, f &amp; e \, d \, c \, b
\end{array}
}\]</div><p>See also: <a href="#ImageFiltering.Pad"><code>Pad</code></a>, <a href="#ImageFiltering.padarray"><code>padarray</code></a>, <a href="#ImageFiltering.Inner"><code>Inner</code></a>, <a href="#ImageFiltering.NA"><code>NA</code></a>  and <a href="#ImageFiltering.NoPad"><code>NoPad</code></a></p><p><strong><code>&quot;symmetric&quot;</code></strong></p><p>The border pixels reflect relative to the edge itself.</p><div>\[\boxed{
\begin{array}{l|c|r}
  d\, c\, b\, a  &amp;  a \, b \, c \, d \, e \, f &amp; f \, e \, d \, c
\end{array}
}\]</div><p>See also: <a href="#ImageFiltering.Pad"><code>Pad</code></a>, <a href="#ImageFiltering.padarray"><code>padarray</code></a>, <a href="#ImageFiltering.Inner"><code>Inner</code></a>, <a href="#ImageFiltering.NA"><code>NA</code></a>  and <a href="#ImageFiltering.NoPad"><code>NoPad</code></a></p><p><strong><code>Fill(m)</code></strong></p><p>The border pixels are filled with a specified value <span>$m$</span>.</p><div>\[\boxed{
\begin{array}{l|c|r}
  m\, m\, m\, m  &amp;  a \, b \, c \, d \, e \, f &amp; m \, m \, m \, m
\end{array}
}\]</div><p>See also: <a href="#ImageFiltering.Pad"><code>Pad</code></a>, <a href="#ImageFiltering.padarray"><code>padarray</code></a>, <a href="#ImageFiltering.Inner"><code>Inner</code></a>, <a href="#ImageFiltering.NA"><code>NA</code></a>  and <a href="#ImageFiltering.NoPad"><code>NoPad</code></a></p><p><strong><code>Inner()</code></strong></p><p>Indicate that edges are to be discarded in filtering, only the interior of the result is to be returned.</p><p>See also: <a href="#ImageFiltering.Pad"><code>Pad</code></a>, <a href="#ImageFiltering.padarray"><code>padarray</code></a>, <a href="#ImageFiltering.Inner"><code>Inner</code></a>, <a href="#ImageFiltering.NA"><code>NA</code></a>  and <a href="#ImageFiltering.NoPad"><code>NoPad</code></a></p><p><strong><code>NA()</code></strong></p><p>Choose filtering using &quot;NA&quot; (Not Available) boundary conditions. This is most appropriate for filters that have only positive weights, such as blurring filters.</p><p>See also: <a href="#ImageFiltering.Pad"><code>Pad</code></a>, <a href="#ImageFiltering.padarray"><code>padarray</code></a>, <a href="#ImageFiltering.Inner"><code>Inner</code></a>, <a href="#ImageFiltering.NA"><code>NA</code></a>  and <a href="#ImageFiltering.NoPad"><code>NoPad</code></a></p><p><strong>Choices for <code>alg</code></strong></p><p>The <code>alg</code> parameter allows you to choose the particular algorithm: <code>FIR()</code> (finite impulse response, aka traditional digital filtering) or <code>FFT()</code> (Fourier-based filtering). If no choice is specified, one will be chosen based on the size of the image and kernel in a way that strives to deliver good performance. Alternatively you can use a custom filter type, like <a href="#ImageFiltering.KernelFactors.IIRGaussian"><code>KernelFactors.IIRGaussian</code></a>.</p><p><strong>Examples</strong></p><p>The following subsections highlight some common use cases.</p><p><strong>Convolution versus correlation</strong></p><pre><code class="language-julia">
# Create a two-dimensional discrete unit impulse function.
f = fill(0,(9,9));
f[5,5] = 1;

# Specify a filter coefficient mask and set the center of the mask as the origin.
w = centered([1 2 3; 4 5 6 ; 7 8 9]);

#=
 The default operation of `imfilter` is correlation.  By reflecting `w` we
 compute the convolution of `f` and `w`.  `Fill(0,w)` indicates that we wish to
 pad the border of `f` with zeros. The amount of padding is automatically
 determined by considering the length of w.
=#
correlation = imfilter(f,w,Fill(0,w))
convolution = imfilter(f,reflect(w),Fill(0,w))
</code></pre><p><strong>Miscellaneous border padding options</strong></p><pre><code class="language-julia"># Example function values f, and filter coefficients w.
f = reshape(1.0:81.0,9,9)
w = centered(reshape(1.0:9.0,3,3))

# You can designate the type of padding by specifying an appropriate string.
imfilter(f,w,&quot;replicate&quot;)
imfilter(f,w,&quot;circular&quot;)
imfilter(f,w,&quot;symmetric&quot;)
imfilter(f,w,&quot;reflect&quot;)

# Alternatively, you can explicitly use the Pad type to designate the padding style.
imfilter(f,w,Pad(:replicate))
imfilter(f,w,Pad(:circular))
imfilter(f,w,Pad(:symmetric))
imfilter(f,w,Pad(:reflect))

# If you want to pad with a specific value then use the Fill type.
imfilter(f,w,Fill(0,w))
imfilter(f,w,Fill(1,w))
imfilter(f,w,Fill(-1,w))

#=
  Specify &#39;Inner()&#39; if you want to retrieve the interior sub-array of f for which
  the filtering operation is defined without padding.
=#
imfilter(f,w,Inner())</code></pre><p><strong>References</strong></p><ol><li>R. C. Gonzalez and R. E. Woods. <em>Digital Image Processing (3rd Edition)</em>.  Upper Saddle River, NJ, USA: Prentice-Hall,  2006.</li></ol><p>See also: <a href="#ImageFiltering.imfilter!"><code>imfilter!</code></a>, <a href="#ImageFiltering.centered"><code>centered</code></a>, <a href="#ImageFiltering.padarray"><code>padarray</code></a>, <a href="#ImageFiltering.Pad"><code>Pad</code></a>, <a href="#ImageFiltering.Fill"><code>Fill</code></a>, <a href="#ImageFiltering.Inner"><code>Inner</code></a>, <a href="#ImageFiltering.KernelFactors.IIRGaussian"><code>KernelFactors.IIRGaussian</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.imfilter!" href="#ImageFiltering.imfilter!"><code>ImageFiltering.imfilter!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">imfilter!(imgfilt, img, kernel, [border=&quot;replicate&quot;], [alg])
imfilter!(r, imgfilt, img, kernel, border, [inds])
imfilter!(r, imgfilt, img, kernel, border::NoPad, [inds=axes(imgfilt)])</code></pre><p>Filter an array <code>img</code> with kernel <code>kernel</code> by computing their correlation, storing the result in <code>imgfilt</code>.</p><p>The indices of <code>imgfilt</code> determine the region over which the filtered image is computed–-you can use this fact to select just a specific region of interest, although be aware that the input <code>img</code> might still get padded.  Alteratively, explicitly provide the indices <code>inds</code> of <code>imgfilt</code> that you want to calculate, and use <code>NoPad</code> boundary conditions. In such cases, you are responsible for supplying appropriate padding: <code>img</code> must be indexable for all of the locations needed for calculating the output. This syntax is best-supported for FIR filtering; in particular, that that IIR filtering can lead to results that are inconsistent with respect to filtering the entire array.</p><p>See also: <a href="#ImageFiltering.imfilter"><code>imfilter</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.imgradients" href="#ImageFiltering.imgradients"><code>ImageFiltering.imgradients</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">    imgradients(img, kernelfun=KernelFactors.ando3, border=&quot;replicate&quot;) -&gt; gimg1, gimg2, ...</code></pre><p>Estimate the gradient of <code>img</code> in the direction of the first and second dimension at all points of the image, using a kernel specified by <code>kernelfun</code>.</p><p><strong>Output</strong></p><p>The gradient is returned as a tuple-of-arrays, one for each dimension of the input; <code>gimg1</code> corresponds to the derivative with respect to the first dimension, <code>gimg2</code> to the second, and so on.</p><p><strong>Details</strong></p><p>To appreciate the difference between various gradient estimation methods it is helpful to distinguish between: (1) a continuous scalar-valued <em>analogue</em> image <span>$f_\textrm{A}(x_1,x_2)$</span>, where <span>$x_1,x_2 \in \mathbb{R}$</span>, and (2) its discrete <em>digital</em> realization <span>$f_\textrm{D}(x_1&#39;,x_2&#39;)$</span>, where <span>$x_1&#39;,x_2&#39; \in \mathbb{N}$</span>, <span>$1 \le x_1&#39; \le M$</span> and <span>$1 \le x_2&#39; \le N$</span>.</p><p><strong>Analogue image</strong></p><p>The gradient of a continuous analogue image <span>$f_{\textrm{A}}(x_1,x_2)$</span> at location <span>$(x_1,x_2)$</span> is defined as the vector</p><div>\[\nabla \mathbf{f}_{\textrm{A}}(x_1,x_2) = \frac{\partial
f_{\textrm{A}}(x_1,x_2)}{\partial x_1} \mathbf{e}_{1} +
\frac{\partial f_{\textrm{A}}(x_1,x_2)}{\partial x_2} \mathbf{e}_{2},\]</div><p>where <span>$\mathbf{e}_{d}$</span> <span>$(d = 1,2)$</span> is the unit vector in the <span>$x_d$</span>-direction. The gradient points in the direction of maximum rate of change of <span>$f_{\textrm{A}}$</span> at the coordinates <span>$(x_1,x_2)$</span>. The gradient can be used to compute the derivative of a function in an arbitrary direction. In particular, the derivative of <span>$f_{\textrm{A}}$</span> in the direction of a unit vector <span>$\mathbf{u}$</span> is given by <span>$\nabla_{\mathbf{u}}f_\textrm{A}(x_1,x_2) = \nabla \mathbf{f}_{\textrm{A}}(x_1,x_2) \cdot \mathbf{u}$</span>, where <span>$\cdot$</span> denotes the dot product.</p><p><strong>Digital image</strong></p><p>In practice, we acquire a digital image <span>$f_\textrm{D}(x_1&#39;,x_2&#39;)$</span> where the light intensity is known only at a discrete set of locations. This means that the required partial derivatives are undefined and need to be approximated using discrete difference formulae [1].</p><p>A straightforward way to approximate the partial derivatives is to use central-difference formulae</p><div>\[ \frac{\partial f_{\textrm{D}}(x_1&#39;,x_2&#39;)}{\partial x_1&#39;}  \approx
        \frac{f_{\textrm{D}}(x_1&#39;+1,x_2&#39;) - f_{\textrm{D}}(x_1&#39;-1,x_2&#39;) }{2}\]</div><p>and</p><div>\[ \frac{\partial f_{\textrm{D}}(x_1&#39;,x_2&#39;)}{\partial x_2&#39;}   \approx
         \frac{f_{\textrm{D}}(x_1&#39;,x_2&#39;+1) - f_{\textrm{D}}(x_1&#39;,x_2&#39;+1)}{2}.\]</div><p>However, the central-difference formulae are very sensitive to noise. When working with noisy image data, one can obtain a better approximation of the partial derivatives by using a suitable weighted combination of the neighboring image intensities. The weighted combination can be represented as a <em>discrete convolution</em> operation between the image and a <em>kernel</em> which characterizes the requisite weights. In particular, if <span>$h_{x_d}$</span> (<span>$d = 1,2)$</span> represents a <span>$2r+1 \times 2r+1$</span> kernel, then</p><div>\[ \frac{\partial f_{\textrm{D}}(x_1&#39;,x_2&#39;)}{\partial x_d&#39;}  \approx
\sum_{i = -r}^r \sum_{j = -r}^r
f_\textrm{D}(x_1&#39;-i,x_2&#39;-j)
  h_{x_d}(i,j).\]</div><p>The kernel is frequently also called a <em>mask</em> or <em>convolution matrix</em>.</p><p><strong>Weighting schemes and approximation error</strong></p><p>The choice of weights determines the magnitude of the approximation error and whether the finite-difference scheme is <em>isotropic</em>. A finite-difference scheme is isotropic if the approximation error does not depend on the orientation of the coordinate system and <em>anisotropic</em> if the approximation error has a directional bias [2]. With a continuous analogue image the magnitude of the gradient would be invariant upon rotation of the coordinate system, but in practice one cannot obtain perfect isotropy with a finite set of discrete points. Hence a finite-difference scheme is typically considered isotropic if the leading error term in the approximation does not have preferred directions.</p><p>Most finite-difference schemes that are used in image processing are based on <span>$3 \times 3$</span> kernels, and as noted by [7], many can also be parametrized by a single parameter <span>$\alpha$</span> as follows:</p><div>\[\mathbf{H}_{x_{1}} =
\frac{1}{4 + 2\alpha}
\begin{bmatrix}
-1 &amp; -\alpha &amp; -1 \\
0 &amp; 0 &amp; 0 \\
 1 &amp; \alpha &amp; 1
\end{bmatrix}
\quad
\text{and}
\quad
\mathbf{H}_{x_{2}} =
\frac{1}{2 + 4\alpha}
\begin{bmatrix}
-1 &amp; 0 &amp; 1 \\
-\alpha &amp; 0 &amp; \alpha \\
 -1 &amp; 0 &amp; 1
\end{bmatrix},\]</div><p>where</p><div>\[\alpha =
\begin{cases}
0,  &amp; \text{Simple Finite Difference}; \\
1, &amp;  \text{Prewitt}; \\
2, &amp;  \text{Sobel}; \\
2.4351, &amp;  \text{Ando}; \\
\frac{10}{3}, &amp;  \text{Scharr}; \\
4, &amp;  \text{Bickley}.
\end{cases}\]</div><p><strong>Separable kernel</strong></p><p>A kernel is called <em>separable</em> if it can be expressed as the convolution of two one-dimensional filters. With a matrix representation of the kernel, separability means that the kernel matrix can be written as an outer product of two vectors. Separable kernels offer computational advantages since instead of performing a two-dimensional convolution one can perform a sequence of one-dimensional convolutions.</p><p><strong>Options</strong></p><p>You can specify your choice of the finite-difference scheme via the <code>kernelfun</code> parameter. You can also indicate how to deal with the pixels on the border of the image with the <code>border</code> parameter.</p><p><strong>Choices for <code>kernelfun</code></strong></p><p>In general <code>kernelfun</code> can be any function which satisfies the following interface:</p><pre><code class="language-julia">    kernelfun(extended::NTuple{N,Bool}, d) -&gt; kern_d,</code></pre><p>where <code>kern_d</code> is the kernel for producing the derivative with respect to the <span>$d$</span>th dimension of an <span>$N$</span>-dimensional array. The parameter <code>extended[i]</code> is true if the image is of size &gt; 1 along dimension <span>$i$</span>. The parameter <code>kern_d</code> may be provided as a dense or factored kernel, with factored representations recommended when the kernel is separable.</p><p>Some valid <code>kernelfun</code> options are described below.</p><p><strong><code>KernelFactors.prewitt</code></strong></p><p>With the <em>prewit</em> option [3] the computation of the gradient is based on the kernels</p><div>\[\begin{aligned}
\mathbf{H}_{x_1} &amp; = \frac{1}{6}
    \begin{bmatrix}
    -1 &amp; -1 &amp; -1 \\
    0 &amp; 0 &amp; 0 \\
    1 &amp; 1 &amp; 1
    \end{bmatrix}
&amp;
\mathbf{H}_{x_2} &amp; =  \frac{1}{6}
    \begin{bmatrix}
    -1 &amp; 0 &amp; 1 \\
    -1 &amp; 0 &amp; 1 \\
    -1 &amp; 0 &amp; 1
    \end{bmatrix} \\
&amp; = \frac{1}{6}
    \begin{bmatrix}
    1 \\
    1  \\
    1
    \end{bmatrix}
    \begin{bmatrix}
    -1 &amp; 0 &amp; 1
    \end{bmatrix}
&amp;
&amp; = \frac{1}{6}
    \begin{bmatrix}
    -1 \\
    0  \\
    1
    \end{bmatrix}
    \begin{bmatrix}
    1 &amp; 1 &amp; 1
    \end{bmatrix}.
\end{aligned}\]</div><p>See also: <a href="#ImageFiltering.KernelFactors.prewitt"><code>KernelFactors.prewitt</code></a> and <a href="#ImageFiltering.Kernel.prewitt"><code>Kernel.prewitt</code></a></p><p><strong><code>KernelFactors.sobel</code></strong></p><p>The <em>sobel</em> option [4] designates the kernels</p><div>\[\begin{aligned}
\mathbf{H}_{x_1} &amp; = \frac{1}{8}
    \begin{bmatrix}
    -1 &amp; -2 &amp; -1 \\
     0 &amp; 0 &amp; 0 \\
     1 &amp; 2 &amp; 1
    \end{bmatrix}
&amp;
\mathbf{H}_{x_2} &amp; = \frac{1}{8}
    \begin{bmatrix}
    -1 &amp; 0 &amp; 1 \\
    -2 &amp; 0 &amp; 2 \\
    -1 &amp; 0 &amp; 1
    \end{bmatrix} \\
&amp; = \frac{1}{8}
    \begin{bmatrix}
    -1 \\
    0  \\
    1
    \end{bmatrix}
    \begin{bmatrix}
    1 &amp; 2 &amp; 1
    \end{bmatrix}
&amp;
&amp; = \frac{1}{8}
    \begin{bmatrix}
    1 \\
    2  \\
    1
    \end{bmatrix}
    \begin{bmatrix}
    -1 &amp; 0 &amp; 1
    \end{bmatrix}.
\end{aligned}\]</div><p>See also:  <a href="#ImageFiltering.KernelFactors.sobel"><code>KernelFactors.sobel</code></a> and <a href="#ImageFiltering.Kernel.sobel"><code>Kernel.sobel</code></a></p><p><strong><code>KernelFactors.ando3</code></strong></p><p>The <em>ando3</em> option [5] specifies the kernels</p><div>\[\begin{aligned}
\mathbf{H}_{x_1} &amp;  =
    \begin{bmatrix}
    -0.112737 &amp; -0.274526 &amp; -0.112737 \\
     0 &amp; 0 &amp; 0 \\
     0.112737 &amp; 0.274526 &amp; 0.112737
    \end{bmatrix}
&amp;
\mathbf{H}_{x_2}  &amp; =
    \begin{bmatrix}
    -0.112737 &amp; 0 &amp; 0.112737 \\
    -0.274526 &amp; 0 &amp; 0.274526 \\
    -0.112737 &amp; 0 &amp; 0.112737
    \end{bmatrix} \\
&amp;  = \begin{bmatrix}
    -1 \\
    0  \\
    1
    \end{bmatrix}
    \begin{bmatrix}
    0.112737 &amp; 0.274526 &amp; 0.112737
    \end{bmatrix}
&amp;
&amp;  = \begin{bmatrix}
    0.112737 \\
    0.274526  \\
    0.112737
    \end{bmatrix}
    \begin{bmatrix}
    -1 &amp; 0 &amp; 1
    \end{bmatrix}.
\end{aligned}\]</div><p>See also:  <a href="#ImageFiltering.KernelFactors.ando3"><code>KernelFactors.ando3</code></a>, and <a href="#ImageFiltering.Kernel.ando3"><code>Kernel.ando3</code></a>;  <a href="#ImageFiltering.KernelFactors.ando4"><code>KernelFactors.ando4</code></a>, and <a href="#ImageFiltering.Kernel.ando4"><code>Kernel.ando4</code></a>; <a href="#ImageFiltering.KernelFactors.ando5"><code>KernelFactors.ando5</code></a>, and <a href="#ImageFiltering.Kernel.ando5"><code>Kernel.ando5</code></a></p><p><strong><code>KernelFactors.scharr</code></strong></p><p>The <em>scharr</em> option [6] designates the kernels</p><div>\[\begin{aligned}
\mathbf{H}_{x_{1}} &amp; =
\frac{1}{32}
\begin{bmatrix}
-3 &amp; -10 &amp; -3 \\
0 &amp; 0 &amp; 0 \\
 3 &amp; 10 &amp; 3
\end{bmatrix}
&amp;
\mathbf{H}_{x_{2}} &amp; =
\frac{1}{32}
\begin{bmatrix}
-3 &amp; 0 &amp; 3 \\
-10 &amp; 0 &amp; 10\\
-3 &amp; 0 &amp; 3
\end{bmatrix} \\
&amp; = \frac{1}{32}
\begin{bmatrix}
    -1 \\
    0  \\
    1
\end{bmatrix}
\begin{bmatrix}
    3 &amp; 10 &amp; 3
\end{bmatrix}
&amp;
&amp; = \frac{1}{32}
\begin{bmatrix}
    3 \\
    10  \\
    3
\end{bmatrix}
\begin{bmatrix}
    -1 &amp; 0 &amp; 1
\end{bmatrix}.
\end{aligned}\]</div><p>See also:  <a href="@ref"><code>KernelFactors.scharr</code></a> and <a href="@ref"><code>Kernel.scharr</code></a></p><p><strong><code>KernelFactors.bickley</code></strong></p><p>The <em>bickley</em> option [7,8] designates the kernels</p><div>\[\begin{aligned}
\mathbf{H}_{x_1} &amp; = \frac{1}{12}
    \begin{bmatrix}
        -1 &amp; -4 &amp; -1 \\
         0 &amp; 0 &amp; 0 \\
         1 &amp; 4 &amp; 1
    \end{bmatrix}
&amp;
\mathbf{H}_{x_2} &amp; = \frac{1}{12}
    \begin{bmatrix}
        -1 &amp; 0 &amp; 1 \\
        -4 &amp; 0 &amp; 4 \\
        -1 &amp; 0 &amp; 1
    \end{bmatrix} \\
&amp; = \frac{1}{12}
    \begin{bmatrix}
        -1 \\
        0  \\
        1
    \end{bmatrix}
    \begin{bmatrix}
        1 &amp; 4 &amp; 1
    \end{bmatrix}
&amp;
&amp;  = \frac{1}{12}
   \begin{bmatrix}
        1 \\
        4  \\
        1
   \end{bmatrix}
   \begin{bmatrix}
        -1 &amp; 0 &amp; 1
   \end{bmatrix}.
\end{aligned}\]</div><p>See also:  <a href="@ref"><code>KernelFactors.bickley</code></a> and <a href="@ref"><code>Kernel.bickley</code></a></p><p><strong>Choices for <code>border</code></strong></p><p>At the image edge, <code>border</code> is used to specify the padding which will be used to extrapolate the image beyond its original bounds. As an indicative example of each option the results of the padding are illustrated on an image consisting of a row of six pixels which are specified alphabetically: <span>$\boxed{a \, b \, c \, d \, e \, f}$</span>. We show the effects of padding only on the left and right border, but analogous consequences hold for the top and bottom border.</p><p><strong><code>&quot;replicate&quot;</code></strong></p><p>The border pixels extend beyond the image boundaries.</p><div>\[\boxed{
\begin{array}{l|c|r}
  a\, a\, a\, a  &amp;  a \, b \, c \, d \, e \, f &amp; f \, f \, f \, f
\end{array}
}\]</div><p>See also: <a href="#ImageFiltering.Pad"><code>Pad</code></a>, <a href="#ImageFiltering.padarray"><code>padarray</code></a>, <a href="#ImageFiltering.Inner"><code>Inner</code></a> and <a href="#ImageFiltering.NoPad"><code>NoPad</code></a></p><p><strong><code>&quot;circular&quot;</code></strong></p><p>The border pixels wrap around. For instance, indexing beyond the left border returns values starting from the right border.</p><div>\[\boxed{
\begin{array}{l|c|r}
  c\, d\, e\, f  &amp;  a \, b \, c \, d \, e \, f &amp; a \, b \, c \, d
\end{array}
}\]</div><p>See also: <a href="#ImageFiltering.Pad"><code>Pad</code></a>, <a href="#ImageFiltering.padarray"><code>padarray</code></a>, <a href="#ImageFiltering.Inner"><code>Inner</code></a> and <a href="#ImageFiltering.NoPad"><code>NoPad</code></a></p><p><strong><code>&quot;symmetric&quot;</code></strong></p><p>The border pixels reflect relative to a position between pixels. That is, the border pixel is omitted when mirroring.</p><div>\[\boxed{
\begin{array}{l|c|r}
  e\, d\, c\, b  &amp;  a \, b \, c \, d \, e \, f &amp; e \, d \, c \, b
\end{array}
}\]</div><p>See also: <a href="#ImageFiltering.Pad"><code>Pad</code></a>, <a href="#ImageFiltering.padarray"><code>padarray</code></a>, <a href="#ImageFiltering.Inner"><code>Inner</code></a> and <a href="#ImageFiltering.NoPad"><code>NoPad</code></a></p><p><strong><code>&quot;reflect&quot;</code></strong></p><p>The border pixels reflect relative to the edge itself.</p><div>\[\boxed{
\begin{array}{l|c|r}
  d\, c\, b\, a  &amp;  a \, b \, c \, d \, e \, f &amp; f \, e \, d \, c
\end{array}
}\]</div><p>See also: <a href="#ImageFiltering.Pad"><code>Pad</code></a>, <a href="#ImageFiltering.padarray"><code>padarray</code></a>, <a href="#ImageFiltering.Inner"><code>Inner</code></a> and <a href="#ImageFiltering.NoPad"><code>NoPad</code></a></p><p><strong>Example</strong></p><p>This example compares the quality of the gradient estimation methods in terms of the accuracy with which the orientation of the gradient is estimated.</p><pre><code class="language-julia">using Images

values = LinRange(-1,1,128);
w = 1.6*pi;

# Define a function of a sinusoidal grating, f(x,y) = sin( (w*x)^2 + (w*y)^2 ),
# together with its exact partial derivatives.
I = [sin( (w*x)^2 + (w*y)^2 ) for y in values, x in values];
Ix = [2*w*x*cos( (w*x)^2 + (w*y)^2 ) for y in values, x in values];
Iy = [2*w*y*cos( (w*x)^2 + (w*y)^2 ) for y in values, x in values];

# Determine the exact orientation of the gradients.
direction_true = atan.(Iy./Ix);

for kernelfunc in (KernelFactors.prewitt, KernelFactors.sobel,
                   KernelFactors.ando3, KernelFactors.scharr,
                   KernelFactors.bickley)

    # Estimate the gradients and their orientations.
    Gy, Gx = imgradients(I,kernelfunc, &quot;replicate&quot;);
    direction_estimated = atan.(Gy./Gx);

    # Determine the mean absolute deviation between the estimated and true
    # orientation. Ignore the values at the border since we expect them to be
    # erroneous.
    error = mean(abs.(direction_true[2:end-1,2:end-1] -
                     direction_estimated[2:end-1,2:end-1]));

    error = round(error, digits=5);
    println(&quot;Using $kernelfunc results in a mean absolute deviation of $error&quot;)
end

# output

Using ImageFiltering.KernelFactors.prewitt results in a mean absolute deviation of 0.01069
Using ImageFiltering.KernelFactors.sobel results in a mean absolute deviation of 0.00522
Using ImageFiltering.KernelFactors.ando3 results in a mean absolute deviation of 0.00365
Using ImageFiltering.KernelFactors.scharr results in a mean absolute deviation of 0.00126
Using ImageFiltering.KernelFactors.bickley results in a mean absolute deviation of 0.00038</code></pre><p><strong>References</strong></p><ol><li>B. Jahne, <em>Digital Image Processing</em> (5th ed.). Springer Publishing Company, Incorporated, 2005. <a href="https://doi.org/10.1007/3-540-27563-0">10.1007/3-540-27563-0</a></li><li>M. Patra  and  M. Karttunen, &quot;Stencils with isotropic discretization error for differential operators,&quot; <em>Numer. Methods Partial Differential Eq.</em>, vol. 22, pp. 936–953, 2006. <a href="https://doi.org/doi:10.1002/num.20129">doi:10.1002/num.20129</a></li><li>J. M. Prewitt, &quot;Object enhancement and extraction,&quot; <em>Picture processing and Psychopictorics</em>, vol. 10, no. 1, pp. 15–19, 1970.</li><li>P.-E. Danielsson and O. Seger, &quot;Generalized and separable sobel operators,&quot; in  <em>Machine Vision for Three-Dimensional Scenes</em>,  H. Freeman, Ed.  Academic Press, 1990,  pp. 347–379. <a href="https://doi.org/doi:10.1016/b978-0-12-266722-0.50016-6">doi:10.1016/b978-0-12-266722-0.50016-6</a></li><li>S. Ando, &quot;Consistent gradient operators,&quot; <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, vol. 22, no.3, pp. 252–265, 2000. <a href="https://doi.org/doi:10.1109/34.841757">doi:10.1109/34.841757</a></li><li>H. Scharr and  J. Weickert, &quot;An anisotropic diffusion algorithm with optimized rotation invariance,&quot; <em>Mustererkennung 2000</em>, pp. 460–467, 2000. <a href="https://doi.org/doi:10.1007/978-3-642-59802-9_58">doi:10.1007/978-3-642-59802-9_58</a></li><li>A. Belyaev, &quot;Implicit image differentiation and filtering with applications to image sharpening,&quot; <em>SIAM Journal on Imaging Sciences</em>, vol. 6, no. 1, pp. 660–679, 2013. <a href="https://doi.org/doi:10.1137/12087092x">doi:10.1137/12087092x</a></li><li>W. G. Bickley, &quot;Finite difference formulae for the square lattice,&quot; <em>The Quarterly Journal of Mechanics and Applied Mathematics</em>, vol. 1, no. 1, pp. 35–42, 1948.  <a href="https://doi.org/doi:10.1093/qjmam/1.1.35">doi:10.1093/qjmam/1.1.35</a></li></ol><hr/></div></section></article><h4 id="Kernel-1"><a class="docs-heading-anchor" href="#Kernel-1">Kernel</a><a class="docs-heading-anchor-permalink" href="#Kernel-1" title="Permalink"></a></h4><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.Kernel.sobel" href="#ImageFiltering.Kernel.sobel"><code>ImageFiltering.Kernel.sobel</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">    diff1, diff2 = sobel()</code></pre><p>Return <span>$3 \times 3$</span> kernels for two-dimensional gradient compution using the Sobel operator. The <code>diff1</code> kernel computes the gradient along the y-axis (first dimension), and the <code>diff2</code> kernel computes the gradient along the x-axis (second dimension).</p><p><strong>Citation</strong></p><p>P.-E. Danielsson and O. Seger, &quot;Generalized and separable sobel operators,&quot; in  <em>Machine Vision for Three-Dimensional Scenes</em>,  H. Freeman, Ed.  Academic Press, 1990,  pp. 347–379. <a href="https://doi.org/doi:10.1016/b978-0-12-266722-0.50016-6">doi:10.1016/b978-0-12-266722-0.50016-6</a></p><p>See also: <a href="#ImageFiltering.KernelFactors.sobel"><code>KernelFactors.sobel</code></a>, <a href="#ImageFiltering.Kernel.prewitt"><code>Kernel.prewitt</code></a>, <a href="#ImageFiltering.Kernel.ando3"><code>Kernel.ando3</code></a>, <a href="@ref"><code>Kernel.scharr</code></a>, <a href="@ref"><code>Kernel.bickley</code></a> and <a href="#ImageFiltering.imgradients"><code>imgradients</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.Kernel.prewitt" href="#ImageFiltering.Kernel.prewitt"><code>ImageFiltering.Kernel.prewitt</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">    diff1, diff2 = prewitt()</code></pre><p>Return <span>$3 \times 3$</span> kernels for two-dimensional gradient compution using the Prewitt operator.  The <code>diff1</code> kernel computes the gradient along the y-axis (first dimension), and the <code>diff2</code> kernel computes the gradient along the x-axis (second dimension).</p><p><strong>Citation</strong></p><p>J. M. Prewitt, &quot;Object enhancement and extraction,&quot; <em>Picture processing and Psychopictorics</em>, vol. 10, no. 1, pp. 15–19, 1970.</p><p>See also: <a href="#ImageFiltering.KernelFactors.prewitt"><code>KernelFactors.prewitt</code></a>, <a href="#ImageFiltering.Kernel.sobel"><code>Kernel.sobel</code></a>, <a href="#ImageFiltering.Kernel.ando3"><code>Kernel.ando3</code></a>, <a href="@ref"><code>Kernel.scharr</code></a>,<a href="@ref"><code>Kernel.bickley</code></a> and <a href="#ImageFiltering.imgradients"><code>ImageFiltering.imgradients</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.Kernel.ando3" href="#ImageFiltering.Kernel.ando3"><code>ImageFiltering.Kernel.ando3</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">    diff1, diff2 = ando3()</code></pre><p>Return <span>$3 \times 3$</span> for two-dimensional gradient compution using  Ando&#39;s &quot;optimal&quot; filters. The <code>diff1</code> kernel computes the gradient along the y-axis (first dimension), and the <code>diff2</code> kernel computes the gradient along the x-axis (second dimension).</p><p><strong>Citation</strong></p><p>S. Ando, &quot;Consistent gradient operators,&quot; <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, vol. 22, no.3, pp. 252–265, 2000. <a href="https://doi.org/doi:10.1109/34.841757">doi:10.1109/34.841757</a></p><p>See also: <a href="#ImageFiltering.KernelFactors.ando3"><code>KernelFactors.ando3</code></a>, <a href="#ImageFiltering.Kernel.ando4"><code>Kernel.ando4</code></a>, <a href="#ImageFiltering.Kernel.ando5"><code>Kernel.ando5</code></a> and  <a href="#ImageFiltering.imgradients"><code>ImageFiltering.imgradients</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.Kernel.ando4" href="#ImageFiltering.Kernel.ando4"><code>ImageFiltering.Kernel.ando4</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">    diff1, diff2 = ando4()</code></pre><p>Return <span>$4 \times 4$</span> kernels for two-dimensional gradient compution using Ando&#39;s &quot;optimal&quot; filters.  The <code>diff1</code> kernel computes the gradient along the y-axis (first dimension), and  the <code>diff2</code> kernel computes the gradient along the x-axis (second dimension).</p><p><strong>Citation</strong></p><p>S. Ando, &quot;Consistent gradient operators,&quot; <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, vol. 22, no.3, pp. 252–265, 2000. <a href="https://doi.org/doi:10.1109/34.841757">doi:10.1109/34.841757</a></p><p>See also: <a href="#ImageFiltering.KernelFactors.ando4"><code>KernelFactors.ando4</code></a>, <a href="#ImageFiltering.Kernel.ando3"><code>Kernel.ando3</code></a>, <a href="#ImageFiltering.Kernel.ando5"><code>Kernel.ando5</code></a> and <a href="#ImageFiltering.imgradients"><code>ImageFiltering.imgradients</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.Kernel.ando5" href="#ImageFiltering.Kernel.ando5"><code>ImageFiltering.Kernel.ando5</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">    diff1, diff2 = ando5()</code></pre><p>Return <span>$5 \times 5$</span> kernels for two-dimensional gradient compution using Ando&#39;s &quot;optimal&quot; filters. The <code>diff1</code> kernel computes the gradient along the y-axis (first dimension), and the <code>diff2</code> kernel computes the gradient along the x-axis (second dimension).</p><p><strong>Citation</strong></p><p>S. Ando, &quot;Consistent gradient operators,&quot; <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, vol. 22, no.3, pp. 252–265, 2000. <a href="https://doi.org/doi:10.1109/34.841757">doi:10.1109/34.841757</a></p><p>See also: <a href="#ImageFiltering.KernelFactors.ando5"><code>KernelFactors.ando5</code></a>, <a href="#ImageFiltering.Kernel.ando3"><code>Kernel.ando3</code></a>, <a href="#ImageFiltering.Kernel.ando4"><code>Kernel.ando4</code></a> and  <a href="#ImageFiltering.imgradients"><code>ImageFiltering.imgradients</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.Kernel.gaussian" href="#ImageFiltering.Kernel.gaussian"><code>ImageFiltering.Kernel.gaussian</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gaussian((σ1, σ2, ...), [(l1, l2, ...)]) -&gt; g
gaussian(σ)                  -&gt; g</code></pre><p>Construct a multidimensional gaussian filter, with standard deviation <code>σd</code> along dimension <code>d</code>. Optionally provide the kernel length <code>l</code>, which must be a tuple of the same length.</p><p>If <code>σ</code> is supplied as a single number, a symmetric 2d kernel is constructed.</p><p>See also: <a href="#ImageFiltering.KernelFactors.gaussian"><code>KernelFactors.gaussian</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.Kernel.DoG" href="#ImageFiltering.Kernel.DoG"><code>ImageFiltering.Kernel.DoG</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">DoG((σp1, σp2, ...), (σm1, σm2, ...), [l1, l2, ...]) -&gt; k
DoG((σ1, σ2, ...))                                   -&gt; k
DoG(σ::Real)                                         -&gt; k</code></pre><p>Construct a multidimensional difference-of-gaussian kernel <code>k</code>, equal to <code>gaussian(σp, l)-gaussian(σm, l)</code>.  When only a single <code>σ</code> is supplied, the default is to choose <code>σp = σ, σm = √2 σ</code>. Optionally provide the kernel length <code>l</code>; the default is to extend by two <code>max(σp,σm)</code> in each direction from the center. <code>l</code> must be odd.</p><p>If <code>σ</code> is provided as a single number, a symmetric 2d DoG kernel is returned.</p><p>See also: <a href="#ImageFiltering.KernelFactors.IIRGaussian"><code>KernelFactors.IIRGaussian</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.Kernel.LoG" href="#ImageFiltering.Kernel.LoG"><code>ImageFiltering.Kernel.LoG</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">LoG((σ1, σ2, ...)) -&gt; k
LoG(σ)             -&gt; k</code></pre><p>Construct a Laplacian-of-Gaussian kernel <code>k</code>. <code>σd</code> is the gaussian width along dimension <code>d</code>.  If <code>σ</code> is supplied as a single number, a symmetric 2d kernel is returned.</p><p>See also: <a href="#ImageFiltering.KernelFactors.IIRGaussian"><code>KernelFactors.IIRGaussian</code></a> and <a href="#ImageFiltering.Kernel.Laplacian"><code>Kernel.Laplacian</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.Kernel.Laplacian" href="#ImageFiltering.Kernel.Laplacian"><code>ImageFiltering.Kernel.Laplacian</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Laplacian((true,true,false,...))
Laplacian(dims, N)
Laplacian()</code></pre><p>Laplacian kernel in <code>N</code> dimensions, taking derivatives along the directions marked as <code>true</code> in the supplied tuple. Alternatively, one can pass <code>dims</code>, a listing of the dimensions for differentiation. (However, this variant is not inferrable.)</p><p><code>Laplacian()</code> is the 2d laplacian, equivalent to <code>Laplacian((true,true))</code>.</p><p>The kernel is represented as an opaque type, but you can use <code>convert(AbstractArray, L)</code> to convert it into array format.</p></div></section></article><h4 id="KernelFactors-1"><a class="docs-heading-anchor" href="#KernelFactors-1">KernelFactors</a><a class="docs-heading-anchor-permalink" href="#KernelFactors-1" title="Permalink"></a></h4><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.KernelFactors.sobel" href="#ImageFiltering.KernelFactors.sobel"><code>ImageFiltering.KernelFactors.sobel</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">    kern1, kern2 = sobel()</code></pre><p>Return factored  Sobel filters for dimensions 1 and 2 of a two-dimensional image. Each is a 2-tuple of one-dimensional filters.</p><p><strong>Citation</strong></p><p>P.-E. Danielsson and O. Seger, &quot;Generalized and separable sobel operators,&quot; in  <em>Machine Vision for Three-Dimensional Scenes</em>,  H. Freeman, Ed.  Academic Press, 1990,  pp. 347–379. <a href="https://doi.org/doi:10.1016/b978-0-12-266722-0.50016-6">doi:10.1016/b978-0-12-266722-0.50016-6</a></p><p>See also: <a href="#ImageFiltering.Kernel.sobel"><code>Kernel.sobel</code></a>  and <a href="#ImageFiltering.imgradients"><code>ImageFiltering.imgradients</code></a>.</p></div></section><section><div><pre><code class="language-julia">    kern = sobel(extended::NTuple{N,Bool}, d)</code></pre><p>Return a factored Sobel filter for computing the gradient in <code>N</code> dimensions along axis <code>d</code>. If <code>extended[dim]</code> is false, <code>kern</code> will have size 1 along that dimension.</p><p>See also: <a href="#ImageFiltering.Kernel.sobel"><code>Kernel.sobel</code></a> and <a href="#ImageFiltering.imgradients"><code>ImageFiltering.imgradients</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.KernelFactors.prewitt" href="#ImageFiltering.KernelFactors.prewitt"><code>ImageFiltering.KernelFactors.prewitt</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">    kern1, kern2 = prewitt()</code></pre><p>Return factored Prewitt filters for dimensions 1 and 2 of your image. Each is a 2-tuple of one-dimensional filters.</p><p><strong>Citation</strong></p><p>J. M. Prewitt, &quot;Object enhancement and extraction,&quot; <em>Picture processing and Psychopictorics</em>, vol. 10, no. 1, pp. 15–19, 1970.</p><p>See also: <a href="#ImageFiltering.Kernel.prewitt"><code>Kernel.prewitt</code></a> and <a href="#ImageFiltering.imgradients"><code>ImageFiltering.imgradients</code></a>.</p></div></section><section><div><pre><code class="language-julia">    kern = prewitt(extended::NTuple{N,Bool}, d)</code></pre><p>Return a factored Prewitt filter for computing the gradient in <code>N</code> dimensions along axis <code>d</code>. If <code>extended[dim]</code> is false, <code>kern</code> will have size 1 along that dimension.</p><p>See also: <a href="#ImageFiltering.Kernel.prewitt"><code>Kernel.prewitt</code></a> and <a href="#ImageFiltering.imgradients"><code>ImageFiltering.imgradients</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.KernelFactors.ando3" href="#ImageFiltering.KernelFactors.ando3"><code>ImageFiltering.KernelFactors.ando3</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">    kern1, kern2 = ando3()</code></pre><p>Return a factored form of Ando&#39;s &quot;optimal&quot; <span>$3 \times 3$</span> gradient filters for dimensions 1 and 2 of your image.</p><p><strong>Citation</strong></p><p>S. Ando, &quot;Consistent gradient operators,&quot; <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, vol. 22, no.3, pp. 252–265, 2000. <a href="https://doi.org/doi:10.1109/34.841757">doi:10.1109/34.841757</a></p><p>See also: <a href="#ImageFiltering.Kernel.ando3"><code>Kernel.ando3</code></a>,<a href="#ImageFiltering.KernelFactors.ando4"><code>KernelFactors.ando4</code></a>, <a href="#ImageFiltering.KernelFactors.ando5"><code>KernelFactors.ando5</code></a> and <a href="#ImageFiltering.imgradients"><code>ImageFiltering.imgradients</code></a>.</p></div></section><section><div><pre><code class="language-julia">    kern = ando3(extended::NTuple{N,Bool}, d)</code></pre><p>Return a factored Ando filter (size 3) for computing the gradient in <code>N</code> dimensions along axis <code>d</code>.  If <code>extended[dim]</code> is false, <code>kern</code> will have size 1 along that dimension.</p><p>See also: <a href="#ImageFiltering.KernelFactors.ando4"><code>KernelFactors.ando4</code></a>, <a href="#ImageFiltering.KernelFactors.ando5"><code>KernelFactors.ando5</code></a> and <a href="#ImageFiltering.imgradients"><code>ImageFiltering.imgradients</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.KernelFactors.ando4" href="#ImageFiltering.KernelFactors.ando4"><code>ImageFiltering.KernelFactors.ando4</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">    kern1, kern2 = ando4()</code></pre><p>Return separable approximations of Ando&#39;s &quot;optimal&quot; 4x4 filters for dimensions 1 and 2 of your image.</p><p><strong>Citation</strong></p><p>S. Ando, &quot;Consistent gradient operators,&quot; <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, vol. 22, no.3, pp. 252–265, 2000. <a href="https://doi.org/doi:10.1109/34.841757">doi:10.1109/34.841757</a></p><p>See also: <a href="#ImageFiltering.Kernel.ando4"><code>Kernel.ando4</code></a> and <a href="#ImageFiltering.imgradients"><code>ImageFiltering.imgradients</code></a>.</p></div></section><section><div><pre><code class="language-julia">    kern = ando4(extended::NTuple{N,Bool}, d)</code></pre><p>Return a factored Ando filter (size 4) for computing the gradient in <code>N</code> dimensions along axis <code>d</code>.  If <code>extended[dim]</code> is false, <code>kern</code> will have size 1 along that dimension.</p><p><strong>Citation</strong></p><p>S. Ando, &quot;Consistent gradient operators,&quot; <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, vol. 22, no.3, pp. 252–265, 2000. <a href="https://doi.org/doi:10.1109/34.841757">doi:10.1109/34.841757</a></p><p>See also: <a href="#ImageFiltering.Kernel.ando4"><code>Kernel.ando4</code></a> and <a href="#ImageFiltering.imgradients"><code>ImageFiltering.imgradients</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.KernelFactors.ando5" href="#ImageFiltering.KernelFactors.ando5"><code>ImageFiltering.KernelFactors.ando5</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">    kern1, kern2 = ando5()</code></pre><p>Return a separable approximations of Ando&#39;s &quot;optimal&quot; 5x5 gradient filters for dimensions 1 and 2 of your image.</p><p><strong>Citation</strong></p><p>S. Ando, &quot;Consistent gradient operators,&quot; <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, vol. 22, no.3, pp. 252–265, 2000. <a href="https://doi.org/doi:10.1109/34.841757">doi:10.1109/34.841757</a></p><p>See also: <a href="#ImageFiltering.Kernel.ando5"><code>Kernel.ando5</code></a> and <a href="#ImageFiltering.imgradients"><code>ImageFiltering.imgradients</code></a>.</p></div></section><section><div><pre><code class="language-julia">    kern = ando5(extended::NTuple{N,Bool}, d)</code></pre><p>Return a factored Ando filter (size 5) for computing the gradient in <code>N</code> dimensions along axis <code>d</code>.  If <code>extended[dim]</code> is false, <code>kern</code> will have size 1 along that dimension.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.KernelFactors.gaussian" href="#ImageFiltering.KernelFactors.gaussian"><code>ImageFiltering.KernelFactors.gaussian</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gaussian(σ::Real, [l]) -&gt; g</code></pre><p>Construct a 1d gaussian kernel <code>g</code> with standard deviation <code>σ</code>, optionally providing the kernel length <code>l</code>. The default is to extend by two <code>σ</code> in each direction from the center. <code>l</code> must be odd.</p></div></section><section><div><pre><code class="language-none">gaussian((σ1, σ2, ...), [l]) -&gt; (g1, g2, ...)</code></pre><p>Construct a multidimensional gaussian filter as a product of single-dimension factors, with standard deviation <code>σd</code> along dimension <code>d</code>. Optionally provide the kernel length <code>l</code>, which must be a tuple of the same length.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.KernelFactors.IIRGaussian" href="#ImageFiltering.KernelFactors.IIRGaussian"><code>ImageFiltering.KernelFactors.IIRGaussian</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">IIRGaussian([T], σ; emit_warning::Bool=true)</code></pre><p>Construct an infinite impulse response (IIR) approximation to a Gaussian of standard deviation <code>σ</code>. <code>σ</code> may either be a single real number or a tuple of numbers; in the latter case, a tuple of such filters will be created, each for filtering a different dimension of an array.</p><p>Optionally specify the type <code>T</code> for the filter coefficients; if not supplied, it will match <code>σ</code> (unless <code>σ</code> is not floating-point, in which case <code>Float64</code> will be chosen).</p><p><strong>Citation</strong></p><p>I. T. Young, L. J. van Vliet, and M. van Ginkel, &quot;Recursive Gabor Filtering&quot;. IEEE Trans. Sig. Proc., 50: 2798-2805 (2002).</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.KernelFactors.TriggsSdika" href="#ImageFiltering.KernelFactors.TriggsSdika"><code>ImageFiltering.KernelFactors.TriggsSdika</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">TriggsSdika(a, b, scale, M)</code></pre><p>Defines a kernel for one-dimensional infinite impulse response (IIR) filtering. <code>a</code> is a &quot;forward&quot; filter, <code>b</code> a &quot;backward&quot; filter, <code>M</code> is a matrix for matching boundary conditions at the right edge, and <code>scale</code> is a constant scaling applied to each element at the conclusion of filtering.</p><p><strong>Citation</strong></p><p>B. Triggs and M. Sdika, &quot;Boundary conditions for Young-van Vliet recursive filtering&quot;. IEEE Trans. on Sig. Proc. 54: 2365-2367 (2006).</p></div></section><section><div><pre><code class="language-none">TriggsSdika(ab, scale)</code></pre><p>Create a symmetric Triggs-Sdika filter (with <code>a = b = ab</code>). <code>M</code> is calculated for you. Only length 3 filters are currently supported.</p></div></section></article><h4 id="Kernel-utilities-1"><a class="docs-heading-anchor" href="#Kernel-utilities-1">Kernel utilities</a><a class="docs-heading-anchor-permalink" href="#Kernel-utilities-1" title="Permalink"></a></h4><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.centered" href="#ImageFiltering.centered"><code>ImageFiltering.centered</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">shiftedkernel = centered(kernel)</code></pre><p>Shift the origin-of-coordinates to the center of <code>kernel</code>. The center-element of <code>kernel</code> will be accessed by <code>shiftedkernel[0, 0, ...]</code>.</p><p>This function makes it easy to supply kernels using regular Arrays, and provides compatibility with other languages that do not support arbitrary axes.</p><p>See also: <a href="#ImageFiltering.imfilter"><code>imfilter</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.KernelFactors.kernelfactors" href="#ImageFiltering.KernelFactors.kernelfactors"><code>ImageFiltering.KernelFactors.kernelfactors</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">kernelfactors(factors::Tuple)</code></pre><p>Prepare a factored kernel for filtering. If passed a 2-tuple of vectors of lengths <code>m</code> and <code>n</code>, this will return a 2-tuple of <code>ReshapedVector</code>s that are effectively of sizes <code>m×1</code> and <code>1×n</code>. In general, each successive <code>factor</code> will be reshaped to extend along the corresponding dimension.</p><p>If passed a tuple of general arrays, it is assumed that each is shaped appropriately along its &quot;leading&quot; dimensions; the dimensionality of each is &quot;extended&quot; to <code>N = length(factors)</code>, appending 1s to the size as needed.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.Kernel.reflect" href="#ImageFiltering.Kernel.reflect"><code>ImageFiltering.Kernel.reflect</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">reflect(kernel) --&gt; reflectedkernel</code></pre><p>Compute the pointwise reflection around 0, 0, ... of the kernel <code>kernel</code>.  Using <code>imfilter</code> with a <code>reflectedkernel</code> performs convolution, rather than correlation, with respect to the original <code>kernel</code>.</p></div></section></article><h4 id="Boundaries-and-padding-1"><a class="docs-heading-anchor" href="#Boundaries-and-padding-1">Boundaries and padding</a><a class="docs-heading-anchor-permalink" href="#Boundaries-and-padding-1" title="Permalink"></a></h4><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.padarray" href="#ImageFiltering.padarray"><code>ImageFiltering.padarray</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">    padarray([T], img, border) --&gt; imgpadded</code></pre><p>Generate a padded image from an array <code>img</code> and a specification <code>border</code> of the boundary conditions and amount of padding to add.</p><p><strong>Output</strong></p><p>An expansion of the input image in which additional pixels are derived from the border of the input image using the extrapolation scheme specified by <code>border</code>.</p><p><strong>Details</strong></p><p>The function supports one, two or multi-dimensional images. You can specify the element type <code>T</code> of the output image.</p><p><strong>Options</strong></p><p>Valid <code>border</code> options are described below.</p><p><strong><code>Pad</code></strong></p><p>The type <code>Pad</code> designates the form of padding which should be used to extrapolate pixels beyond the boundary of an image. Instances must set <code>style</code>, a Symbol specifying the boundary conditions of the image.</p><p>Symbol must be on one of:</p><ul><li><code>:replicate</code> (repeat edge values to infinity),</li><li><code>:circular</code> (image edges &quot;wrap around&quot;),</li><li><code>:symmetric</code> (the image reflects relative to a position between pixels),</li><li><code>:reflect</code> (the image reflects relative to the edge itself).</li></ul><p>Refer to the documentation of <a href="#ImageFiltering.Pad"><code>Pad</code></a> for more details and examples for each option.</p><p><strong><code>Fill</code></strong></p><p>The type <code>Fill</code> designates a particular value which will be used to extrapolate pixels beyond the boundary of an image. Refer to the documentation of <a href="#ImageFiltering.Fill"><code>Fill</code></a> for more details and illustrations.</p><p><strong>2D Examples</strong></p><p>Each example is based on the input array</p><div>\[\mathbf{A} =
\boxed{
\begin{matrix}
 1  &amp; 2  &amp;  3  &amp;  4 &amp; 5  &amp; 6 \\
 2  &amp; 4  &amp;  6  &amp;  8 &amp; 10 &amp; 12 \\
 3  &amp; 6  &amp;  9  &amp; 12 &amp; 15 &amp; 18 \\
 4  &amp; 8  &amp; 12  &amp; 16 &amp; 20 &amp; 24 \\
 5  &amp; 10 &amp; 15  &amp; 20 &amp; 25 &amp; 30 \\
 6  &amp; 12 &amp; 18  &amp; 24 &amp; 30 &amp; 36
 \end{matrix}}.\]</div><p><strong>Examples with <code>Pad</code></strong></p><p>The command <code>padarray(A, Pad(:replicate,4,4))</code> yields</p><div>\[\boxed{
\begin{array}{ccccccccccccc}
1 &amp; 1 &amp; 1 &amp; 1 &amp;         1   &amp;          2   &amp;          3   &amp;          4   &amp;          5   &amp;          6   &amp;  6  &amp;  6  &amp;  6  &amp;  6 \\
1 &amp; 1 &amp; 1 &amp; 1 &amp;         1   &amp;          2   &amp;          3   &amp;          4   &amp;          5   &amp;          6   &amp;  6  &amp;  6  &amp;  6  &amp;  6 \\
1 &amp; 1 &amp; 1 &amp; 1 &amp;         1   &amp;          2   &amp;          3   &amp;          4   &amp;          5   &amp;          6   &amp;  6  &amp;  6  &amp;  6  &amp;  6 \\
1 &amp; 1 &amp; 1 &amp; 1 &amp;         1   &amp;          2   &amp;          3   &amp;          4   &amp;          5   &amp;          6   &amp;  6  &amp;  6  &amp;  6  &amp;  6 \\
1 &amp; 1 &amp; 1 &amp; 1 &amp;  \boxed{1}  &amp;   \boxed{2}  &amp;   \boxed{3}  &amp;   \boxed{4}  &amp;   \boxed{5}  &amp;   \boxed{6}  &amp;  6  &amp;  6  &amp;  6  &amp;  6 \\
2 &amp; 2 &amp; 2 &amp; 2 &amp;  \boxed{2}  &amp;   \boxed{4}  &amp;   \boxed{6}  &amp;   \boxed{8}  &amp;  \boxed{10}  &amp;  \boxed{12}  &amp; 12  &amp; 12  &amp; 12  &amp; 12 \\
3 &amp; 3 &amp; 3 &amp; 3 &amp;  \boxed{3}  &amp;   \boxed{6}  &amp;   \boxed{9}  &amp;  \boxed{12}  &amp;  \boxed{15}  &amp;  \boxed{18}  &amp; 18  &amp; 18  &amp; 18  &amp; 18 \\
4 &amp; 4 &amp; 4 &amp; 4 &amp;  \boxed{4}  &amp;   \boxed{8}  &amp;  \boxed{12}  &amp;  \boxed{16}  &amp;  \boxed{20}  &amp;  \boxed{24}  &amp; 24  &amp; 24  &amp; 24  &amp; 24 \\
5 &amp; 5 &amp; 5 &amp; 5 &amp;  \boxed{5}  &amp;  \boxed{10}  &amp;  \boxed{15}  &amp;  \boxed{20}  &amp;  \boxed{25}  &amp;  \boxed{30}  &amp; 30  &amp; 30  &amp; 30  &amp; 30 \\
6 &amp; 6 &amp; 6 &amp; 6 &amp;  \boxed{6}  &amp;  \boxed{12}  &amp;  \boxed{18}  &amp;  \boxed{24}  &amp;  \boxed{30}  &amp;  \boxed{36}  &amp; 36  &amp; 36  &amp; 36  &amp; 36 \\
6 &amp; 6 &amp; 6 &amp; 6 &amp;         6   &amp;         12   &amp;         18   &amp;         24   &amp;         30   &amp;         36   &amp; 36  &amp; 36  &amp; 36  &amp; 36 \\
6 &amp; 6 &amp; 6 &amp; 6 &amp;         6   &amp;         12   &amp;         18   &amp;         24   &amp;         30   &amp;         36   &amp; 36  &amp; 36  &amp; 36  &amp; 36 \\
6 &amp; 6 &amp; 6 &amp; 6 &amp;         6   &amp;         12   &amp;         18   &amp;         24   &amp;         30   &amp;         36   &amp; 36  &amp; 36  &amp; 36  &amp; 36 \\
6 &amp; 6 &amp; 6 &amp; 6 &amp;         6   &amp;         12   &amp;         18   &amp;         24   &amp;         30   &amp;         36   &amp; 36  &amp; 36  &amp; 36  &amp; 36
 \end{array}
}.\]</div><p>The command <code>padarray(A, Pad(:circular,4,4))</code> yields</p><div>\[\boxed{
\begin{array}{ccccccccccccc}
9  &amp; 12 &amp; 15 &amp; 18 &amp;         3  &amp;         6   &amp;         9   &amp;         12  &amp;          15  &amp;         18  &amp; 3 &amp;  6 &amp;  9 &amp; 12 \\
12 &amp; 16 &amp; 20 &amp; 24 &amp;         4  &amp;         8   &amp;        12   &amp;         16  &amp;          20  &amp;         24  &amp; 4 &amp;  8 &amp; 12 &amp; 16 \\
15 &amp; 20 &amp; 25 &amp; 30 &amp;         5  &amp;        10   &amp;        15   &amp;         20  &amp;          25  &amp;         30  &amp; 5 &amp; 10 &amp; 15 &amp; 20 \\
18 &amp; 24 &amp; 30 &amp; 36 &amp;         6  &amp;        12   &amp;        18   &amp;         24  &amp;          30  &amp;         36  &amp; 6 &amp; 12 &amp; 18 &amp; 24 \\
3  &amp;  4 &amp;  5 &amp;  6 &amp;  \boxed{1} &amp;  \boxed{2}  &amp;  \boxed{3}  &amp;  \boxed{4}  &amp;  \boxed{5}   &amp;  \boxed{6}  &amp; 1 &amp;  2 &amp;  3 &amp;  4 \\
6  &amp;  8 &amp; 10 &amp; 12 &amp;  \boxed{2} &amp;  \boxed{4}  &amp;  \boxed{6}  &amp;  \boxed{8}  &amp;  \boxed{10}  &amp;  \boxed{12} &amp; 2 &amp;  4 &amp;  6 &amp;  8 \\
9  &amp; 12 &amp; 15 &amp; 18 &amp;  \boxed{3} &amp;  \boxed{6}  &amp;  \boxed{9}  &amp;  \boxed{12} &amp;  \boxed{15}  &amp;  \boxed{18} &amp; 3 &amp;  6 &amp;  9 &amp; 12 \\
12 &amp; 16 &amp; 20 &amp; 24 &amp;  \boxed{4} &amp;  \boxed{8}  &amp;  \boxed{12} &amp;  \boxed{16} &amp;  \boxed{20}  &amp;  \boxed{24} &amp; 4 &amp;  8 &amp; 12 &amp; 16 \\
15 &amp; 20 &amp; 25 &amp; 30 &amp;  \boxed{5} &amp;  \boxed{10} &amp;  \boxed{15} &amp;  \boxed{20} &amp;  \boxed{25}  &amp;  \boxed{30} &amp; 5 &amp; 10 &amp; 15 &amp; 20 \\
18 &amp; 24 &amp; 30 &amp; 36 &amp;  \boxed{6} &amp;  \boxed{12} &amp;  \boxed{18} &amp;  \boxed{24} &amp;  \boxed{30}  &amp;  \boxed{36} &amp; 6 &amp; 12 &amp; 18 &amp; 24 \\
3  &amp;  4 &amp;  5 &amp;  6 &amp;         1  &amp;          2  &amp;          3  &amp;          4  &amp;           5  &amp;          6  &amp; 1 &amp;  2 &amp;  3 &amp;  4 \\
6  &amp;  8 &amp; 10 &amp; 12 &amp;         2  &amp;          4  &amp;          6  &amp;          8  &amp;          10  &amp;         12  &amp; 2 &amp;  4 &amp;  6 &amp;  8 \\
9  &amp; 12 &amp; 15 &amp; 18 &amp;         3  &amp;          6  &amp;          9  &amp;         12  &amp;          15  &amp;         18  &amp; 3 &amp;  6 &amp;  9 &amp; 12 \\
12 &amp; 16 &amp; 20 &amp; 24 &amp;         4  &amp;          8  &amp;         12  &amp;         16  &amp;          20  &amp;         24  &amp; 4 &amp;  8 &amp; 12 &amp; 16
\end{array}
}.\]</div><p>The command <code>padarray(A, Pad(:symmetric,4,4))</code> yields</p><div>\[\boxed{
\begin{array}{ccccccccccccc}
16 &amp; 12 &amp;  8 &amp; 4 &amp;         4  &amp;          8  &amp;         12  &amp;          16 &amp;          20 &amp;         24  &amp; 24 &amp; 20 &amp; 16 &amp; 12 \\
12 &amp;  9 &amp;  6 &amp; 3 &amp;         3  &amp;          6  &amp;         9   &amp;          12 &amp;          15 &amp;         18  &amp; 18 &amp; 15 &amp; 12 &amp;  9 \\
 8 &amp;  6 &amp;  4 &amp; 2 &amp;         2  &amp;          4  &amp;         6   &amp;          8  &amp;          10 &amp;         12  &amp; 12 &amp; 10 &amp;  8 &amp;  6 \\
 4 &amp;  3 &amp;  2 &amp; 1 &amp;         1  &amp;          2  &amp;         3   &amp;          4  &amp;          5  &amp;         6   &amp;  6 &amp;  5 &amp;  4 &amp;  3 \\
 4 &amp;  3 &amp;  2 &amp; 1 &amp;  \boxed{1} &amp;   \boxed{2} &amp;  \boxed{3}  &amp;   \boxed{4} &amp;  \boxed{5}  &amp;  \boxed{6}  &amp;  6 &amp;  5 &amp;  4 &amp;  3 \\
 8 &amp;  6 &amp;  4 &amp; 2 &amp;  \boxed{2} &amp;   \boxed{4} &amp;  \boxed{6}  &amp;   \boxed{8} &amp;  \boxed{10} &amp;  \boxed{12} &amp; 12 &amp; 10 &amp;  8 &amp;  6 \\
12 &amp;  9 &amp;  6 &amp; 3 &amp;  \boxed{3} &amp;   \boxed{6} &amp;  \boxed{9}  &amp;  \boxed{12} &amp;  \boxed{15} &amp;  \boxed{18} &amp; 18 &amp; 15 &amp; 12 &amp;  9 \\
16 &amp; 12 &amp;  8 &amp; 4 &amp;  \boxed{4} &amp;   \boxed{8} &amp;  \boxed{12} &amp;  \boxed{16} &amp;  \boxed{20} &amp;  \boxed{24} &amp; 24 &amp; 20 &amp; 16 &amp; 12 \\
20 &amp; 15 &amp; 10 &amp; 5 &amp;  \boxed{5} &amp;  \boxed{10} &amp;  \boxed{15} &amp;  \boxed{20} &amp;  \boxed{25} &amp;  \boxed{30} &amp; 30 &amp; 25 &amp; 20 &amp; 15 \\
24 &amp; 18 &amp; 12 &amp; 6 &amp;  \boxed{6} &amp;  \boxed{12} &amp;  \boxed{18} &amp;  \boxed{24} &amp;  \boxed{30} &amp;  \boxed{36} &amp; 36 &amp; 30 &amp; 24 &amp; 18 \\
24 &amp; 18 &amp; 12 &amp; 6 &amp;         6  &amp;         12  &amp;         18  &amp;         24  &amp;         30  &amp;         36  &amp; 36 &amp; 30 &amp; 24 &amp; 18 \\
20 &amp; 15 &amp; 10 &amp; 5 &amp;         5  &amp;         10  &amp;         15  &amp;         20  &amp;         25  &amp;         30  &amp; 30 &amp; 25 &amp; 20 &amp; 15 \\
16 &amp; 12 &amp;  8 &amp; 4 &amp;         4  &amp;          8  &amp;         12  &amp;         16  &amp;         20  &amp;         24  &amp; 24 &amp; 20 &amp; 16 &amp; 12 \\
12 &amp;  9 &amp;  6 &amp; 3 &amp;         3  &amp;          6  &amp;          9  &amp;         12  &amp;         15  &amp;         18  &amp; 18 &amp; 15 &amp; 12 &amp;  9
\end{array}
}.\]</div><p>The command <code>padarray(A, Pad(:reflect,4,4))</code> yields</p><div>\[\boxed{
\begin{array}{ccccccccccccc}
25 &amp; 20 &amp; 15 &amp; 10 &amp;         5  &amp;         10  &amp;         15   &amp;         20  &amp;          25  &amp;         30  &amp; 25 &amp; 20 &amp; 15 &amp; 10 \\
20 &amp; 16 &amp; 12 &amp;  8 &amp;         4  &amp;         8   &amp;         12   &amp;         16  &amp;          20  &amp;         24  &amp; 20 &amp; 16 &amp; 12 &amp;  8 \\
15 &amp; 12 &amp;  9 &amp;  6 &amp;         3  &amp;         6   &amp;          9   &amp;         12  &amp;          15  &amp;         18  &amp; 15 &amp; 12 &amp;  9 &amp;  6 \\
10 &amp;  8 &amp;  6 &amp;  4 &amp;         2  &amp;         4   &amp;          6   &amp;         8   &amp;          10  &amp;         12  &amp; 10 &amp;  8 &amp;  6 &amp;  4 \\
5  &amp;  4 &amp;  3 &amp;  2 &amp;  \boxed{1} &amp;  \boxed{2}  &amp;   \boxed{3}  &amp;  \boxed{4}  &amp;   \boxed{5}  &amp;  \boxed{6}  &amp;  5 &amp;  4 &amp;  3 &amp;  2 \\
10 &amp;  8 &amp;  6 &amp;  4 &amp;  \boxed{2} &amp;  \boxed{4}  &amp;   \boxed{6}  &amp;  \boxed{8}  &amp;   \boxed{10} &amp;  \boxed{12} &amp; 10 &amp;  8 &amp;  6 &amp;  4 \\
15 &amp; 12 &amp;  9 &amp;  6 &amp;  \boxed{3} &amp;  \boxed{6}  &amp;   \boxed{9}  &amp;  \boxed{12} &amp;   \boxed{15} &amp;  \boxed{18} &amp; 15 &amp; 12 &amp;  9 &amp;  6 \\
20 &amp; 16 &amp; 12 &amp;  8 &amp;  \boxed{4} &amp;  \boxed{8}  &amp;   \boxed{12} &amp;  \boxed{16} &amp;   \boxed{20} &amp;  \boxed{24} &amp; 20 &amp; 16 &amp; 12 &amp;  8 \\
25 &amp; 20 &amp; 15 &amp; 10 &amp;  \boxed{5} &amp;  \boxed{10} &amp;   \boxed{15} &amp;  \boxed{20} &amp;   \boxed{25} &amp;  \boxed{30} &amp; 25 &amp; 20 &amp; 15 &amp; 10 \\
30 &amp; 24 &amp; 18 &amp; 12 &amp;  \boxed{6} &amp;  \boxed{12} &amp;   \boxed{18} &amp;  \boxed{24} &amp;   \boxed{30} &amp;  \boxed{36} &amp; 30 &amp; 24 &amp; 18 &amp; 12 \\
25 &amp; 20 &amp; 15 &amp; 10 &amp;         5  &amp;         10  &amp;          15  &amp;         20  &amp;          25  &amp;         30  &amp; 25 &amp; 20 &amp; 15 &amp; 10 \\
20 &amp; 16 &amp; 12 &amp;  8 &amp;         4  &amp;         8   &amp;          12  &amp;         16  &amp;          20  &amp;         24  &amp; 20 &amp; 16 &amp; 12 &amp;  8 \\
15 &amp; 12 &amp;  9 &amp;  6 &amp;         3  &amp;         6   &amp;           9  &amp;         12  &amp;          15  &amp;         18  &amp; 15 &amp; 12 &amp;  9 &amp;  6 \\
10 &amp;  8 &amp;  6 &amp;  4 &amp;         2  &amp;         4   &amp;           6  &amp;          8  &amp;          10  &amp;         12  &amp; 10 &amp;  8 &amp;  6 &amp;  4
\end{array}
}.\]</div><p><strong>Examples with <code>Fill</code></strong></p><p>The command <code>padarray(A, Fill(0,(4,4),(4,4)))</code> yields</p><div>\[\boxed{
\begin{array}{ccccccccccccc}
0 &amp; 0 &amp; 0 &amp; 0 &amp;         0  &amp;         0   &amp;         0   &amp;         0   &amp;         0   &amp;          0   &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp;         0  &amp;         0   &amp;         0   &amp;         0   &amp;         0   &amp;          0   &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp;         0  &amp;         0   &amp;         0   &amp;         0   &amp;         0   &amp;          0   &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp;         0  &amp;         0   &amp;         0   &amp;         0   &amp;         0   &amp;          0   &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp;  \boxed{1} &amp;  \boxed{2}  &amp;  \boxed{3}  &amp;  \boxed{4}  &amp;  \boxed{5}  &amp;   \boxed{6}  &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp;  \boxed{2} &amp;  \boxed{4}  &amp;  \boxed{6}  &amp;  \boxed{8}  &amp;  \boxed{10} &amp;   \boxed{12} &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp;  \boxed{3} &amp;  \boxed{6}  &amp;  \boxed{9}  &amp;  \boxed{12} &amp;  \boxed{15} &amp;   \boxed{18} &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp;  \boxed{4} &amp;  \boxed{8}  &amp;  \boxed{12} &amp;  \boxed{16} &amp;  \boxed{20} &amp;   \boxed{24} &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp;  \boxed{5} &amp;  \boxed{10} &amp;  \boxed{15} &amp;  \boxed{20} &amp;  \boxed{25} &amp;   \boxed{30} &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp;  \boxed{6} &amp;  \boxed{12} &amp;  \boxed{18} &amp;  \boxed{24} &amp;  \boxed{30} &amp;   \boxed{36} &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp;         0  &amp;         0   &amp;         0   &amp;         0   &amp;         0   &amp;          0   &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp;         0  &amp;         0   &amp;         0   &amp;         0   &amp;         0   &amp;          0   &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp;         0  &amp;         0   &amp;         0   &amp;         0   &amp;         0   &amp;          0   &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp;         0  &amp;         0   &amp;         0   &amp;         0   &amp;         0   &amp;          0   &amp; 0 &amp; 0 &amp; 0 &amp; 0
\end{array}
}.\]</div><p><strong>3D Examples</strong></p><p>Each example is based on a multi-dimensional array <span>$\mathsf{A} \in\mathbb{R}^{2 \times 2 \times 2}$</span> given by</p><div>\[\mathsf{A}(:,:,1) =
\boxed{
\begin{array}{cc}
1 &amp; 2 \\
3 &amp; 4
\end{array}}
\quad
\text{and}
\quad
\mathsf{A}(:,:,2) =
\boxed{
\begin{array}{cc}
5 &amp; 6 \\
7 &amp; 8
\end{array}}.\]</div><p>Note that each example will yield a new multi-dimensional array <span>$\mathsf{A}&#39; \in \mathbb{R}^{4 \times 4 \times 4}$</span> of type <code>OffsetArray</code>, where prepended dimensions may be negative or start from zero.</p><p><strong>Examples with <code>Pad</code></strong></p><p>The command <code>padarray(A,Pad(:replicate,1,1,1))</code> yields</p><div>\[\begin{aligned}
\mathsf{A}&#39;(:,:,0) &amp; =
\boxed{
\begin{array}{cccc}
1 &amp; 1 &amp; 2 &amp; 2 \\
1 &amp; 1 &amp; 2 &amp; 2 \\
3 &amp; 3 &amp; 4 &amp; 4 \\
3 &amp; 3 &amp; 4 &amp; 4
\end{array}}
&amp;
\mathsf{A}&#39;(:,:,1) &amp; =
\boxed{
\begin{array}{cccc}
1 &amp;         1  &amp;         2  &amp; 2 \\
1 &amp;  \boxed{1} &amp;  \boxed{2} &amp; 2 \\
3 &amp;  \boxed{3} &amp;  \boxed{4} &amp; 4 \\
3 &amp;         3  &amp;         4  &amp; 4
\end{array}} \\
\mathsf{A}&#39;(:,:,2) &amp; =
\boxed{
\begin{array}{cccc}
5 &amp;         5  &amp;         6  &amp; 6 \\
5 &amp;  \boxed{5} &amp;  \boxed{6} &amp; 6 \\
7 &amp;  \boxed{7} &amp;  \boxed{8} &amp; 8 \\
7 &amp;         7  &amp;         8  &amp; 8
\end{array}}
&amp;
\mathsf{A}&#39;(:,:,3) &amp; =
\boxed{
\begin{array}{cccc}
5 &amp; 5 &amp; 6 &amp; 6 \\
5 &amp; 5 &amp; 6 &amp; 6 \\
7 &amp; 7 &amp; 8 &amp; 8 \\
7 &amp; 7 &amp; 8 &amp; 8
\end{array}}
\end{aligned}
.\]</div><p>The command <code>padarray(A,Pad(:circular,1,1,1))</code> yields</p><div>\[\begin{aligned}
\mathsf{A}&#39;(:,:,0) &amp; =
\boxed{
\begin{array}{cccc}
8 &amp; 7 &amp; 8 &amp; 7 \\
6 &amp; 5 &amp; 6 &amp; 5 \\
8 &amp; 7 &amp; 8 &amp; 7 \\
6 &amp; 5 &amp; 6 &amp; 5
\end{array}}
&amp;
\mathsf{A}&#39;(:,:,1) &amp; =
\boxed{
\begin{array}{cccc}
4 &amp;         3  &amp;         4  &amp; 3 \\
2 &amp;  \boxed{1} &amp;  \boxed{2} &amp; 1 \\
4 &amp;  \boxed{3} &amp;  \boxed{4} &amp; 3 \\
2 &amp;         1  &amp;         2  &amp; 1
\end{array}} \\
\mathsf{A}&#39;(:,:,2) &amp; =
\boxed{
\begin{array}{cccc}
8 &amp;         7  &amp;         8  &amp; 7 \\
6 &amp;  \boxed{5} &amp;  \boxed{6} &amp; 5 \\
8 &amp;  \boxed{7} &amp;  \boxed{8} &amp; 7 \\
6 &amp;         5  &amp;         6  &amp; 5
\end{array}}
&amp;
\mathsf{A}&#39;(:,:,3) &amp; =
\boxed{
\begin{array}{cccc}
4 &amp; 3 &amp; 4 &amp; 3 \\
2 &amp; 1 &amp; 2 &amp; 1 \\
4 &amp; 3 &amp; 4 &amp; 3 \\
2 &amp; 1 &amp; 2 &amp; 1
\end{array}}
\end{aligned}
.\]</div><p>The command <code>padarray(A,Pad(:symmetric,1,1,1))</code> yields</p><div>\[\begin{aligned}
\mathsf{A}&#39;(:,:,0) &amp; =
\boxed{
\begin{array}{cccc}
1 &amp; 1 &amp; 2 &amp; 2 \\
1 &amp; 1 &amp; 2 &amp; 2 \\
3 &amp; 3 &amp; 4 &amp; 4 \\
3 &amp; 3 &amp; 4 &amp; 4
\end{array}}
&amp;
\mathsf{A}&#39;(:,:,1) &amp; =
\boxed{
\begin{array}{cccc}
1 &amp;         1  &amp;         2  &amp; 2 \\
1 &amp;  \boxed{1} &amp;  \boxed{2} &amp; 2 \\
2 &amp;  \boxed{3} &amp;  \boxed{4} &amp; 4 \\
2 &amp;         3  &amp;         4  &amp; 4
\end{array}} \\
\mathsf{A}&#39;(:,:,2) &amp; =
\boxed{
\begin{array}{cccc}
5 &amp;         5  &amp;         6  &amp; 6 \\
5 &amp;  \boxed{5} &amp;  \boxed{6} &amp; 6 \\
7 &amp;  \boxed{7} &amp;  \boxed{8} &amp; 8 \\
7 &amp;         7  &amp;         8  &amp; 8
\end{array}}
&amp;
\mathsf{A}&#39;(:,:,3) &amp; =
\boxed{
\begin{array}{cccc}
5 &amp; 5 &amp; 6 &amp; 6 \\
5 &amp; 5 &amp; 6 &amp; 6 \\
7 &amp; 7 &amp; 8 &amp; 8 \\
7 &amp; 7 &amp; 8 &amp; 8
\end{array}}
\end{aligned}
.\]</div><p>The command <code>padarray(A,Pad(:reflect,1,1,1))</code> yields</p><div>\[\begin{aligned}
\mathsf{A}&#39;(:,:,0) &amp; =
\boxed{
\begin{array}{cccc}
8 &amp; 7 &amp; 8 &amp; 7 \\
6 &amp; 5 &amp; 6 &amp; 5 \\
8 &amp; 7 &amp; 8 &amp; 7 \\
6 &amp; 5 &amp; 6 &amp; 5
\end{array}}
&amp;
\mathsf{A}&#39;(:,:,1) &amp; =
\boxed{
\begin{array}{cccc}
4 &amp;         3  &amp;         4  &amp; 3 \\
2 &amp;  \boxed{1} &amp;  \boxed{2} &amp; 1 \\
4 &amp;  \boxed{3} &amp;  \boxed{4} &amp; 3 \\
2 &amp;         1  &amp;         2  &amp; 1
\end{array}} \\
\mathsf{A}&#39;(:,:,2) &amp; =
\boxed{
\begin{array}{cccc}
8 &amp;         7  &amp;         8  &amp; 7 \\
6 &amp;  \boxed{5} &amp;  \boxed{6} &amp; 5 \\
8 &amp;  \boxed{7} &amp;  \boxed{8} &amp; 7 \\
6 &amp;         5  &amp;         6  &amp; 5
\end{array}}
&amp;
\mathsf{A}&#39;(:,:,3) &amp; =
\boxed{
\begin{array}{cccc}
4 &amp; 3 &amp; 4 &amp; 3 \\
2 &amp; 1 &amp; 2 &amp; 1 \\
4 &amp; 3 &amp; 4 &amp; 3 \\
2 &amp; 1 &amp; 2 &amp; 1
\end{array}}
\end{aligned}
.\]</div><p><strong>Examples with <code>Fill</code></strong></p><p>The command <code>padarray(A,Fill(0,(1,1,1)))</code> yields</p><div>\[\begin{aligned}
\mathsf{A}&#39;(:,:,0) &amp; =
\boxed{
\begin{array}{cccc}
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0
\end{array}}
&amp;
\mathsf{A}&#39;(:,:,1) &amp; =
\boxed{
\begin{array}{cccc}
0 &amp;         0  &amp;         0  &amp; 0 \\
0 &amp;  \boxed{1} &amp;  \boxed{2} &amp; 0 \\
0 &amp;  \boxed{3} &amp;  \boxed{4} &amp; 0 \\
0 &amp;         0  &amp;         0  &amp; 0
\end{array}} \\
\mathsf{A}&#39;(:,:,2) &amp; =
\boxed{
\begin{array}{cccc}
0 &amp;         0  &amp;         0  &amp; 0 \\
0 &amp;  \boxed{5} &amp;  \boxed{6} &amp; 0 \\
0 &amp;  \boxed{7} &amp;  \boxed{8} &amp; 0 \\
0 &amp;         0  &amp;         0  &amp; 0
\end{array}}
&amp;
\mathsf{A}&#39;(:,:,3) &amp; =
\boxed{
\begin{array}{cccc}
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0
\end{array}}
\end{aligned}
.\]</div><hr/></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.Pad" href="#ImageFiltering.Pad"><code>ImageFiltering.Pad</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">    struct Pad{N} &lt;: AbstractBorder
        style::Symbol
        lo::Dims{N}    # number to extend by on the lower edge for each dimension
        hi::Dims{N}    # number to extend by on the upper edge for each dimension
    end</code></pre><p><code>Pad</code> is a type that designates the form of padding which should be used to extrapolate pixels beyond the boundary of an image. Instances must set <code>style</code>, a Symbol specifying the boundary conditions of the image.</p><p><strong>Output</strong></p><p>The type <code>Pad</code> specifying how the boundary of an image should be padded.</p><p><strong>Details</strong></p><p>When representing a spatial two-dimensional image filtering operation as a discrete convolution between the image and a <span>$D \times D$</span> filter, the results are undefined for pixels closer than <span>$D$</span> pixels from the border of the image. To define the operation near and at the border, one needs a scheme for extrapolating pixels beyond the edge. The <code>Pad</code> type allows one to specify the necessary extrapolation scheme.</p><p>The type facilitates the padding of one, two or multi-dimensional images.</p><p>You can specify a different amount of padding at the lower and upper borders of each dimension of the image (top, left, bottom and right in two dimensions).</p><p><strong>Options</strong></p><p>Some valid <code>style</code> options are described below. As an indicative example of each option the results of the padding are illustrated on an image consisting of a row of six pixels which are specified alphabetically: <span>$\boxed{a \, b \, c \,d \, e \, f}$</span>. We show the effects of padding only on the left and right border, but analogous consequences hold for the top and bottom border.</p><p><strong><code>:replicate</code> (Default)</strong></p><p>The border pixels extend beyond the image boundaries.</p><div>\[\boxed{
\begin{array}{l|c|r}
  a\, a\, a\, a  &amp;  a \, b \, c \, d \, e \, f &amp; f \, f \, f \, f
\end{array}
}\]</div><p>See also: <a href="#ImageFiltering.Fill"><code>Fill</code></a>, <a href="#ImageFiltering.padarray"><code>padarray</code></a>, <a href="#ImageFiltering.Inner"><code>Inner</code></a> and <a href="#ImageFiltering.NoPad"><code>NoPad</code></a></p><p><strong><code>:circular</code></strong></p><p>The border pixels wrap around. For instance, indexing beyond the left border returns values starting from the right border.</p><div>\[\boxed{
\begin{array}{l|c|r}
  c\, d\, e\, f  &amp;  a \, b \, c \, d \, e \, f &amp; a \, b \, c \, d
\end{array}
}\]</div><p>See also: <a href="#ImageFiltering.Fill"><code>Fill</code></a>, <a href="#ImageFiltering.padarray"><code>padarray</code></a>, <a href="#ImageFiltering.Inner"><code>Inner</code></a> and <a href="#ImageFiltering.NoPad"><code>NoPad</code></a></p><p><strong><code>:symmetric</code></strong></p><p>The border pixels reflect relative to a position between pixels. That is, the border pixel is omitted when mirroring.</p><div>\[\boxed{
\begin{array}{l|c|r}
  e\, d\, c\, b  &amp;  a \, b \, c \, d \, e \, f &amp; e \, d \, c \, b
\end{array}
}\]</div><p>See also: <a href="#ImageFiltering.Fill"><code>Fill</code></a>,<a href="#ImageFiltering.padarray"><code>padarray</code></a>, <a href="#ImageFiltering.Inner"><code>Inner</code></a> and <a href="#ImageFiltering.NoPad"><code>NoPad</code></a></p><p><strong><code>:reflect</code></strong></p><p>The border pixels reflect relative to the edge itself.</p><div>\[\boxed{
\begin{array}{l|c|r}
  d\, c\, b\, a  &amp;  a \, b \, c \, d \, e \, f &amp; f \, e \, d \, c
\end{array}
}\]</div><p>See also: <a href="#ImageFiltering.Fill"><code>Fill</code></a>,<a href="#ImageFiltering.padarray"><code>padarray</code></a>, <a href="#ImageFiltering.Inner"><code>Inner</code></a> and <a href="#ImageFiltering.NoPad"><code>NoPad</code></a></p><hr/></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.Fill" href="#ImageFiltering.Fill"><code>ImageFiltering.Fill</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">    struct Fill{T,N} &lt;: AbstractBorder
        value::T
        lo::Dims{N}
        hi::Dims{N}
    end</code></pre><p><code>Fill</code> is a type that designates a particular value which will be used to extrapolate pixels beyond the boundary of an image.</p><p><strong>Output</strong></p><p>The type <code>Fill</code> specifying the value with which the boundary of the image should be padded.</p><p><strong>Details</strong></p><p>When representing a two-dimensional spatial image filtering operation as a discrete convolution between an image and a <span>$D \times D$</span> filter, the results are undefined for pixels closer than <span>$D$</span> pixels from the border of the image. To define the operation near and at the border, one needs a scheme for extrapolating pixels beyond the edge. The <code>Fill</code> type allows one to specify a particular value which will be used in the extrapolation. For more elaborate extrapolation schemes refer to the documentation of  <a href="#ImageFiltering.Pad"><code>Pad</code></a>.</p><p>The type facilitates the padding of one, two or multi-dimensional images.</p><p>You can specify a different amount of padding at the lower and upper borders of each dimension of the image (top, left, bottom and right in two dimensions).</p><p><strong>Example</strong></p><p>As an indicative illustration consider an image consisting of a row of six pixels which are specified alphabetically: <span>$\boxed{a \, b \, c \, d \, e \, f}$</span>. We show the effects of padding with a constant value <span>$m$</span> only on the left and right border, but analogous consequences hold for the top and bottom border.</p><div>\[\boxed{
\begin{array}{l|c|r}
  m\, m\, m\, m  &amp;  a \, b \, c \, d \, e \, f &amp; m \, m \, m \, m
\end{array}
}\]</div><p>See also: <a href="#ImageFiltering.Pad"><code>Pad</code></a>, <a href="#ImageFiltering.padarray"><code>padarray</code></a>, <a href="#ImageFiltering.Inner"><code>Inner</code></a> and <a href="#ImageFiltering.NoPad"><code>NoPad</code></a></p><hr/></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.Inner" href="#ImageFiltering.Inner"><code>ImageFiltering.Inner</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">Inner()
Inner(lo, hi)</code></pre><p>Indicate that edges are to be discarded in filtering, only the interior of the result is to be returned.</p><p><strong>Example:</strong></p><pre><code class="language-none">imfilter(img, kernel, Inner())</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.NA" href="#ImageFiltering.NA"><code>ImageFiltering.NA</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">NA()
NA(lo, hi)</code></pre><p>Choose filtering using &quot;NA&quot; (Not Available) boundary conditions. This is most appropriate for filters that have only positive weights, such as blurring filters. Effectively, the output pixel value is normalized in the following way:</p><pre><code class="language-none">          filtered img with Fill(0) boundary conditions
output =  ---------------------------------------------
          filtered 1   with Fill(0) boundary conditions</code></pre><p>As a consequence, filtering has the same behavior as <code>nanmean</code>. Indeed, invalid pixels in <code>img</code> can be marked as <code>NaN</code> and then they are effectively omitted from the filtered result.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.NoPad" href="#ImageFiltering.NoPad"><code>ImageFiltering.NoPad</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">NoPad()
NoPad(border)</code></pre><p>Indicates that no padding should be applied to the input array, or that you have already pre-padded the input image. Passing a <code>border</code> object allows you to preserve &quot;memory&quot; of a border choice; it can be retrieved by indexing with <code>[]</code>.</p><p><strong>Example</strong></p><p>The commands</p><pre><code class="language-none">np = NoPad(Pad(:replicate))
imfilter!(out, img, kernel, np)</code></pre><p>run filtering directly, skipping any padding steps.  Every entry of <code>out</code> must be computable using in-bounds operations on <code>img</code> and <code>kernel</code>.</p></div></section></article><h4 id="Algorithms-1"><a class="docs-heading-anchor" href="#Algorithms-1">Algorithms</a><a class="docs-heading-anchor-permalink" href="#Algorithms-1" title="Permalink"></a></h4><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.Algorithm.FIR" href="#ImageFiltering.Algorithm.FIR"><code>ImageFiltering.Algorithm.FIR</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Filter using a direct algorithm</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.Algorithm.FFT" href="#ImageFiltering.Algorithm.FFT"><code>ImageFiltering.Algorithm.FFT</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Filter using the Fast Fourier Transform</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.Algorithm.IIR" href="#ImageFiltering.Algorithm.IIR"><code>ImageFiltering.Algorithm.IIR</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Filter with an Infinite Impulse Response filter</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.Algorithm.Mixed" href="#ImageFiltering.Algorithm.Mixed"><code>ImageFiltering.Algorithm.Mixed</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Filter with a cascade of mixed types (IIR, FIR)</p></div></section></article><h4 id="Internal-machinery-1"><a class="docs-heading-anchor" href="#Internal-machinery-1">Internal machinery</a><a class="docs-heading-anchor-permalink" href="#Internal-machinery-1" title="Permalink"></a></h4><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.KernelFactors.ReshapedOneD" href="#ImageFiltering.KernelFactors.ReshapedOneD"><code>ImageFiltering.KernelFactors.ReshapedOneD</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ReshapedOneD{N,Npre}(data)</code></pre><p>Return an object of dimensionality <code>N</code>, where <code>data</code> must have dimensionality 1. The axes are <code>0:0</code> for the first <code>Npre</code> dimensions, have the axes of <code>data</code> for dimension <code>Npre+1</code>, and are <code>0:0</code> for the remaining dimensions.</p><p><code>data</code> must support <code>eltype</code> and <code>ndims</code>, but does not have to be an AbstractArray.</p><p>ReshapedOneDs allow one to specify a &quot;filtering dimension&quot; for a 1-dimensional filter.</p></div></section></article><h3 id="Nonlinear-filtering-and-transformation-1"><a class="docs-heading-anchor" href="#Nonlinear-filtering-and-transformation-1">Nonlinear filtering and transformation</a><a class="docs-heading-anchor-permalink" href="#Nonlinear-filtering-and-transformation-1" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="ImageFiltering.MapWindow.mapwindow" href="#ImageFiltering.MapWindow.mapwindow"><code>ImageFiltering.MapWindow.mapwindow</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">mapwindow(f, img, window; [border=&quot;replicate&quot;], [indices=axes(img)]) -&gt; imgf</code></pre><p>Apply <code>f</code> to sliding windows of <code>img</code>, with window size or axes specified by <code>window</code>. For example, <code>mapwindow(median!, img, window)</code> returns an <code>Array</code> of values similar to <code>img</code> (median-filtered, of course), whereas <code>mapwindow(extrema, img, window)</code> returns an <code>Array</code> of <code>(min,max)</code> tuples over a window of size <code>window</code> centered on each point of <code>img</code>.</p><p>The function <code>f</code> receives a buffer <code>buf</code> for the window of data surrounding the current point. If <code>window</code> is specified as a Dims-tuple (tuple-of-integers), then all the integers must be odd and the window is centered around the current image point. For example, if <code>window=(3,3)</code>, then <code>f</code> will receive an Array <code>buf</code> corresponding to offsets <code>(-1:1, -1:1)</code> from the <code>imgf[i,j]</code> for which this is currently being computed. Alternatively, <code>window</code> can be a tuple of AbstractUnitRanges, in which case the specified ranges are used for <code>buf</code>; this allows you to use asymmetric windows if needed.</p><p><code>border</code> specifies how the edges of <code>img</code> should be handled; see <code>imfilter</code> for details.</p><p>Finally <code>indices</code> allows to omit unnecessary computations, if you want to do things like <code>mapwindow</code> on a subimage, or a strided variant of mapwindow. It works as follows:</p><pre><code class="language-julia">mapwindow(f, img, window, indices=(2:5, 1:2:7)) == mapwindow(f,img,window)[2:5, 1:2:7]</code></pre><p>Except more efficiently because it omits computation of the unused values.</p><p>Because the data in the buffer <code>buf</code> that is received by <code>f</code> is copied from <code>img</code>, and the buffer&#39;s memory is reused, <code>f</code> should not return references to <code>buf</code>. This</p><pre><code class="language-julia">f = buf-&gt;copy(buf) # as opposed to f = buf-&gt;buf
mapwindow(f, img, window, indices=(2:5, 1:2:7))</code></pre><p>would work as expected.</p><p>For functions that can only take <code>AbstractVector</code> inputs, you might have to first specialize <code>default_shape</code>:</p><pre><code class="language-julia">f = v-&gt;quantile(v, 0.75)
ImageFiltering.MapWindow.default_shape(::typeof(f)) = vec</code></pre><p>and then <code>mapwindow(f, img, (m,n))</code> should filter at the 75th quantile.</p><p>See also: <a href="#ImageFiltering.imfilter"><code>imfilter</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Images.imROF" href="#Images.imROF"><code>Images.imROF</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">imgr = imROF(img, λ, iterations)</code></pre><p>Perform Rudin-Osher-Fatemi (ROF) filtering, more commonly known as Total Variation (TV) denoising or TV regularization. <code>λ</code> is the regularization coefficient for the derivative, and <code>iterations</code> is the number of relaxation iterations taken. 2d only.</p><p>See https://en.wikipedia.org/wiki/Total<em>variation</em>denoising and Chambolle, A. (2004). &quot;An algorithm for total variation minimization and applications&quot;.     Journal of Mathematical Imaging and Vision. 20: 89–97</p></div></section></article><h3 id="Edge-detection-1"><a class="docs-heading-anchor" href="#Edge-detection-1">Edge detection</a><a class="docs-heading-anchor-permalink" href="#Edge-detection-1" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="Images.magnitude" href="#Images.magnitude"><code>Images.magnitude</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">m = magnitude(grad_x, grad_y)</code></pre><p>Calculates the magnitude of the gradient images given by <code>grad_x</code> and <code>grad_y</code>. Equivalent to <code>sqrt(grad_x.^2 + grad_y.^2)</code>.</p><p>Returns a magnitude image the same size as <code>grad_x</code> and <code>grad_y</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Images.phase" href="#Images.phase"><code>Images.phase</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">phase(grad_x, grad_y) -&gt; p</code></pre><p>Calculate the rotation angle of the gradient given by <code>grad_x</code> and <code>grad_y</code>. Equivalent to <code>atan(-grad_y, grad_x)</code>, except that when both <code>grad_x</code> and <code>grad_y</code> are effectively zero, the corresponding angle is set to zero.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Images.orientation" href="#Images.orientation"><code>Images.orientation</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">orientation(grad_x, grad_y) -&gt; orient</code></pre><p>Calculate the orientation angle of the strongest edge from gradient images given by <code>grad_x</code> and <code>grad_y</code>.  Equivalent to <code>atan(grad_x, grad_y)</code>.  When both <code>grad_x</code> and <code>grad_y</code> are effectively zero, the corresponding angle is set to zero.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Images.magnitude_phase" href="#Images.magnitude_phase"><code>Images.magnitude_phase</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">magnitude_phase(grad_x, grad_y) -&gt; m, p</code></pre><p>Convenience function for calculating the magnitude and phase of the gradient images given in <code>grad_x</code> and <code>grad_y</code>.  Returns a tuple containing the magnitude and phase images.  See <code>magnitude</code> and <code>phase</code> for details.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Images.imedge" href="#Images.imedge"><code>Images.imedge</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">grad_y, grad_x, mag, orient = imedge(img, kernelfun=KernelFactors.ando3, border=&quot;replicate&quot;)</code></pre><p>Edge-detection filtering. <code>kernelfun</code> is a valid kernel function for <a href="#ImageFiltering.imgradients"><code>imgradients</code></a>, defaulting to <a href="#ImageFiltering.KernelFactors.ando3"><code>KernelFactors.ando3</code></a>. <code>border</code> is any of the boundary conditions specified in <code>padarray</code>.</p><p>Returns a tuple <code>(grad_y, grad_x, mag, orient)</code>, which are the horizontal gradient, vertical gradient, and the magnitude and orientation of the strongest edge, respectively.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Images.thin_edges" href="#Images.thin_edges"><code>Images.thin_edges</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">thinned = thin_edges(img, gradientangle, [border])
thinned, subpix = thin_edges_subpix(img, gradientangle, [border])
thinned, subpix = thin_edges_nonmaxsup(img, gradientangle, [border]; [radius::Float64=1.35], [theta=pi/180])
thinned, subpix = thin_edges_nonmaxsup_subpix(img, gradientangle, [border]; [radius::Float64=1.35], [theta=pi/180])</code></pre><p>Edge thinning for 2D edge images.  Currently the only algorithm available is non-maximal suppression, which takes an edge image and its gradient angle, and checks each edge point for local maximality in the direction of the gradient. The returned image is non-zero only at maximal edge locations.</p><p><code>border</code> is any of the boundary conditions specified in <code>padarray</code>.</p><p>In addition to the maximal edge image, the <code>_subpix</code> versions of these functions also return an estimate of the subpixel location of each local maxima, as a 2D array or image of <code>Graphics.Point</code> objects.  Additionally, each local maxima is adjusted to the estimated value at the subpixel location.</p><p>Currently, the <code>_nonmaxsup</code> functions are identical to the first two function calls, except that they also accept additional keyword arguments.  <code>radius</code> indicates the step size to use when searching in the direction of the gradient; values between 1.2 and 1.5 are suggested (default 1.35).  <code>theta</code> indicates the step size to use when discretizing angles in the <code>gradientangle</code> image, in radians (default: 1 degree in radians = pi/180).</p><p>Example:</p><pre><code class="language-none">g = rgb2gray(rgb_image)
gx, gy = imgradients(g)
mag, grad_angle = magnitude_phase(gx,gy)
mag[mag .&lt; 0.5] = 0.0  # Threshold magnitude image
thinned, subpix =  thin_edges_subpix(mag, grad_angle)</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Images.canny" href="#Images.canny"><code>Images.canny</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">canny_edges = canny(img, (upper, lower), sigma=1.4)</code></pre><p>Performs Canny Edge Detection on the input image.</p><p>Parameters :</p><p>(upper, lower) :  Bounds for hysteresis thresholding   sigma :           Specifies the standard deviation of the gaussian filter</p><p><strong>Example</strong></p><pre><code class="language-julia">imgedg = canny(img, (Percentile(80), Percentile(20)))</code></pre></div></section></article><h3 id="Corner-Detection-1"><a class="docs-heading-anchor" href="#Corner-Detection-1">Corner Detection</a><a class="docs-heading-anchor-permalink" href="#Corner-Detection-1" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="Images.imcorner" href="#Images.imcorner"><code>Images.imcorner</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">corners = imcorner(img; [method])
corners = imcorner(img, threshold, percentile; [method])</code></pre><p>Performs corner detection using one of the following methods -</p><pre><code class="language-none">1. harris
2. shi_tomasi
3. kitchen_rosenfeld</code></pre><p>The parameters of the individual methods are described in their documentation. The maxima values of the resultant responses are taken as corners. If a threshold is specified, the values of the responses are thresholded to give the corner pixels. The threshold is assumed to be a percentile value unless <code>percentile</code> is set to false.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Images.harris" href="#Images.harris"><code>Images.harris</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">harris_response = harris(img; [k], [border], [weights])</code></pre><p>Performs Harris corner detection. The covariances can be taken using either a mean weighted filter or a gamma kernel.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Images.shi_tomasi" href="#Images.shi_tomasi"><code>Images.shi_tomasi</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">shi_tomasi_response = shi_tomasi(img; [border], [weights])</code></pre><p>Performs Shi Tomasi corner detection. The covariances can be taken using either a mean weighted filter or a gamma kernel.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Images.kitchen_rosenfeld" href="#Images.kitchen_rosenfeld"><code>Images.kitchen_rosenfeld</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">kitchen_rosenfeld_response = kitchen_rosenfeld(img; [border])</code></pre><p>Performs Kitchen Rosenfeld corner detection. The covariances can be taken using either a mean weighted filter or a gamma kernel.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Images.fastcorners" href="#Images.fastcorners"><code>Images.fastcorners</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">fastcorners(img, n, threshold) -&gt; corners</code></pre><p>Performs FAST Corner Detection. <code>n</code> is the number of contiguous pixels which need to be greater (lesser) than intensity + threshold (intensity - threshold) for a pixel to be marked as a corner. The default value for n is 12.</p></div></section></article><h3 id="Feature-Extraction-1"><a class="docs-heading-anchor" href="#Feature-Extraction-1">Feature Extraction</a><a class="docs-heading-anchor-permalink" href="#Feature-Extraction-1" title="Permalink"></a></h3><p>See the <a href=".">ImageFeatures</a> package for a much more comprehensive set of tools.</p><article class="docstring"><header><a class="docstring-binding" id="Images.blob_LoG" href="#Images.blob_LoG"><code>Images.blob_LoG</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">blob_LoG(img, σscales, [edges], [σshape]) -&gt; Vector{BlobLoG}</code></pre><p>Find &quot;blobs&quot; in an N-D image using the negative Lapacian of Gaussians with the specifed vector or tuple of σ values. The algorithm searches for places where the filtered image (for a particular σ) is at a peak compared to all spatially- and σ-adjacent voxels, where σ is <code>σscales[i] * σshape</code> for some i. By default, <code>σshape</code> is an ntuple of 1s.</p><p>The optional <code>edges</code> argument controls whether peaks on the edges are included. <code>edges</code> can be <code>true</code> or <code>false</code>, or a N+1-tuple in which the first entry controls whether edge-σ values are eligible to serve as peaks, and the remaining N entries control each of the N dimensions of <code>img</code>.</p><p><strong>Citation:</strong></p><p>Lindeberg T (1998), &quot;Feature Detection with Automatic Scale Selection&quot;, International Journal of Computer Vision, 30(2), 79–116.</p><p>See also: <a href="#Images.BlobLoG"><code>BlobLoG</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Images.BlobLoG" href="#Images.BlobLoG"><code>Images.BlobLoG</code></a> — <span class="docstring-category">Type</span></header><section><div><p>BlobLoG stores information about the location of peaks as discovered by <code>blob_LoG</code>. It has fields:</p><ul><li>location: the location of a peak in the filtered image (a CartesianIndex)</li><li>σ: the value of σ which lead to the largest <code>-LoG</code>-filtered amplitude at this location</li><li>amplitude: the value of the <code>-LoG(σ)</code>-filtered image at the peak</li></ul><p>Note that the radius is equal to σ√2.</p><p>See also: <a href="#Images.blob_LoG"><code>blob_LoG</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Images.findlocalmaxima" href="#Images.findlocalmaxima"><code>Images.findlocalmaxima</code></a> — <span class="docstring-category">Function</span></header><section><div><p><code>findlocalmaxima(img, [region, edges]) -&gt; Vector{CartesianIndex}</code></p><p>Returns the coordinates of elements whose value is larger than all of their immediate neighbors.  <code>region</code> is a list of dimensions to consider.  <code>edges</code> is a boolean specifying whether to include the first and last elements of each dimension, or a tuple-of-Bool specifying edge behavior for each dimension separately.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Images.findlocalminima" href="#Images.findlocalminima"><code>Images.findlocalminima</code></a> — <span class="docstring-category">Function</span></header><section><div><p>Like <code>findlocalmaxima</code>, but returns the coordinates of the smallest elements.</p></div></section></article><h3 id="Exposure-1"><a class="docs-heading-anchor" href="#Exposure-1">Exposure</a><a class="docs-heading-anchor-permalink" href="#Exposure-1" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="Images.imhist" href="#Images.imhist"><code>Images.imhist</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">edges, count = imhist(img, nbins)
edges, count = imhist(img, nbins, minval, maxval)
edges, count = imhist(img, edges)</code></pre><p>Generates a histogram for the image over nbins spread between <code>(minval, maxval]</code>. Color images are automatically converted to grayscale.</p><p><strong>Output</strong></p><p>Returns <code>edges</code> which is a <a href="@ref"><code>range</code></a> type that specifies how the  interval <code>(minval, maxval]</code> is divided into bins, and an array <code>count</code> which records the concomitant bin frequencies. In particular, <code>count</code> has the following properties:</p><ul><li><code>count[i+1]</code> is the number of values <code>x</code> that satisfy <code>edges[i] &lt;= x &lt; edges[i+1]</code>.</li><li><code>count[1]</code> is the number satisfying <code>x &lt; edges[1]</code>, and</li><li><code>count[end]</code> is the number satisfying <code>x &gt;= edges[end]</code>.</li><li><code>length(count) == length(edges)+1</code>.</li></ul><p><strong>Details</strong></p><p>One can consider a histogram as a piecewise-constant model of a probability density function <span>$f$</span> [1]. Suppose that <span>$f$</span> has support on some interval <span>$I = [a,b]$</span>.  Let <span>$m$</span> be an integer and <span>$a = a_1 &lt; a_2 &lt; \ldots &lt; a_m &lt; a_{m+1} = b$</span> a sequence of real numbers. Construct a sequence of intervals</p><div>\[I_1 = [a_1,a_2], I_2 = (a_2, a_3], \ldots, I_{m} = (a_m,a_{m+1}]\]</div><p>which partition <span>$I$</span> into subsets <span>$I_j$</span> <span>$(j = 1, \ldots, m)$</span> on which <span>$f$</span> is constant. These subsets satisfy <span>$I_i \cap I_j = \emptyset, \forall i \neq j$</span>, and are commonly referred to as <em>bins</em>. Together they encompass the entire range of data values such that <span>$\sum_j |I_j | = | I |$</span>. Each bin has width <span>$w_j = |I_j| = a_{j+1} - a_j$</span> and height <span>$h_j$</span> which is the constant probability density over the region of the bin. Integrating the constant probability density over the width of the bin <span>$w_j$</span> yields a probability mass of <span>$\pi_j = h_j w_j$</span> for the bin.</p><p>For a sample <span>$x_1, x_2, \ldots, x_N$</span>, let</p><div>\[n_j = \sum_{n = 1}^{N}\mathbf{1}_{(I_j)}(x_n),
\quad \text{where} \quad
\mathbf{1}_{(I_j)}(x) =
\begin{cases}
 1 &amp; \text{if} x \in I_j,\\
 0 &amp; \text{otherwise},
\end{cases},\]</div><p>represents the number of samples falling into the interval <span>$I_j$</span>. An estimate for the probability mass of the <span>$j$</span>th bin is given by the relative frequency <span>$\hat{\pi} = \frac{n_j}{N}$</span>, and the histogram estimator of the probability density function is defined as</p><div>\[\begin{aligned}
\hat{f}_n(x)  &amp; = \sum_{j = 1}^{m}\frac{n_j}{Nw_j} \mathbf{1}_{(I_j)}(x) \\
&amp; = \sum_{j = 1}^{m}\frac{\hat{\pi}_j}{w_j} \mathbf{1}_{(I_j)}(x) \\
&amp; = \sum_{j = 1}^{m}\hat{h}_j \mathbf{1}_{(I_j)}(x).
\end{aligned}\]</div><p>The function <span>$\hat{f}_n(x)$</span> is a genuine density estimator because <span>$\hat{f}_n(x)  \ge 0$</span> and</p><div>\[\begin{aligned}
\int_{-\infty}^{\infty}\hat{f}_n(x) \operatorname{d}x &amp; = \sum_{j=1}^{m} \frac{n_j}{Nw_j} w_j \\
&amp; = 1.
\end{aligned}\]</div><p><strong>Options</strong></p><p>Various options for the parameters of this function are described in more detail below.</p><p><strong>Choices for <code>nbins</code></strong></p><p>You can specify the number of discrete bins for the histogram.</p><p><strong>Choices for <code>minval</code></strong></p><p>You have the option to specify the lower bound of the interval over which the histogram will be computed.  If <code>minval</code> is not specified then the minimum value present in the image is taken as the lower bound.</p><p><strong>Choices for <code>maxval</code></strong></p><p>You have the option to specify the upper bound of the interval over which the histogram will be computed.  If <code>maxval</code> is not specified then the maximum value present in the image is taken as the upper bound.</p><p><strong>Choices for <code>edges</code></strong></p><p>If you do not designate the number of bins, nor the lower or upper bound of the interval, then you have the option to directly stipulate how the intervals will be divided by specifying a <a href="@ref"><code>range</code></a> type.</p><p><strong>Example</strong></p><p>Compute the histogram of a grayscale image.</p><pre><code class="language-julia">
using TestImages, FileIO, ImageView

img =  testimage(&quot;mandril_gray&quot;);
edges, counts  = imhist(img,256);</code></pre><p>Given a color image, compute the hisogram of the red channel.</p><pre><code class="language-julia">img = testimage(&quot;mandrill&quot;)
r = red(img)
edges, counts  = imhist(r,256);</code></pre><p><strong>References</strong></p><p>[1] E. Herrholz, &quot;Parsimonious Histograms,&quot; Ph.D. dissertation, Inst. of Math. and Comp. Sci., University of Greifswald, Greifswald, Germany, 2011.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Images.cliphist" href="#Images.cliphist"><code>Images.cliphist</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">clipped_hist = cliphist(hist, clip)</code></pre><p>Clips the histogram above a certain value <code>clip</code>. The excess left in the bins exceeding <code>clip</code> is redistributed among the remaining bins.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Images.histeq" href="#Images.histeq"><code>Images.histeq</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">hist_equalised_img = histeq(img, nbins)
hist_equalised_img = histeq(img, nbins, minval, maxval)</code></pre><p>Returns a histogram equalised image with a granularity of approximately <code>nbins</code> number of bins.</p><p><strong>Details</strong></p><p>Histogram equalisation was initially conceived to  improve the contrast in a single-channel grayscale image. The method transforms the distribution of the intensities in an image so that they are as uniform as possible [1]. The natural justification for uniformity is that the image has better contrast  if the intensity levels of an image span a wide range on the intensity scale. As it turns out, the necessary transformation is a mapping based on the cumulative histogram.</p><p>One can consider an <span>$L$</span>-bit single-channel <span>$I \times J$</span> image with gray values in the set <span>$\{0,1,\ldots,L-1 \}$</span>, as a collection of independent and identically distributed random variables. Specifically, let the sample space <span>$\Omega$</span> be the set of all <span>$IJ$</span>-tuples <span>$\omega =(\omega_{11},\omega_{12},\ldots,\omega_{1J},\omega_{21},\omega_{22},\ldots,\omega_{2J},\omega_{I1},\omega_{I2},\ldots,\omega_{IJ})$</span>, where each <span>$\omega_{ij} \in \{0,1,\ldots, L-1 \}$</span>. Furthermore, impose a probability measure on <span>$\Omega$</span> such that the functions <span>$\Omega \ni \omega \to \omega_{ij} \in \{0,1,\ldots,L-1\}$</span> are independent and identically distributed.</p><p>One can then regard an image as a matrix of random variables <span>$\mathbf{G} = [G_{i,j}(\omega)]$</span>, where each function <span>$G_{i,j}: \Omega \to \mathbb{R}$</span> is defined by</p><div>\[G_{i,j}(\omega) = \frac{\omega_{ij}}{L-1},\]</div><p>and each <span>$G_{i,j}$</span> is distributed according to some unknown density <span>$f_{G}$</span>. While <span>$f_{G}$</span> is unknown, one can approximate it with a normalised histogram of gray levels,</p><div>\[\hat{f}_{G}(v)= \frac{n_v}{IJ},\]</div><p>where</p><div>\[n_v = \left | \left\{(i,j)\, |\,  G_{i,j}(\omega)  = v \right \} \right |\]</div><p>represents the number of times a gray level with intensity <span>$v$</span> occurs in <span>$\mathbf{G}$</span>. To transforming the distribution of the intensities so that they are as uniform as possible one needs to find a mapping <span>$T(\cdot)$</span> such that <span>$T(G_{i,j}) \thicksim U$</span>. The required mapping turns out to be the cumulative distribution function (CDF) of the empirical density <span>$\hat{f}_{G}$</span>,</p><div>\[ T(G_{i,j}) = \int_0^{G_{i,j}}\hat{f}_{G}(w)\mathrm{d} w.\]</div><p><strong>Options</strong></p><p>Various options for the parameters of this function are described in more detail below.</p><p><strong>Choices for <code>img</code></strong></p><p>The <code>histeq</code> function can handle a variety of input types. The returned image depends on the input type. If the input is an <code>Image</code> then the resulting image is of the same type and has the same properties.</p><p>For coloured images, the input is converted to <a href="https://en.wikipedia.org/wiki/YIQ">YIQ</a> type and the Y channel is equalised. This is the combined with the I and Q channels and the resulting image converted to the same type as the input.</p><p><strong>Choices for <code>nbins</code></strong></p><p>You can specify the total number of bins in the histogram.</p><p><strong>Choices for <code>minval</code> and <code>maxval</code></strong></p><p>If minval and maxval are specified then intensities are equalized to the range (minval, maxval). The default values are 0 and 1.</p><p><strong>Example</strong></p><pre><code class="language-julia">
using TestImages, FileIO, ImageView

img =  testimage(&quot;mandril_gray&quot;);
imgeq = histeq(img,256);

imshow(img)
imshow(imgeq)</code></pre><p><strong>References</strong></p><ol><li>R. C. Gonzalez and R. E. Woods. <em>Digital Image Processing (3rd Edition)</em>.  Upper Saddle River, NJ, USA: Prentice-Hall,  2006.</li></ol><p>See also: <a href="@ref">histmatch</a>,<a href="@ref">clahe</a>, <a href="@ref">imhist</a> and  <a href="@ref">adjust_gamma</a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Images.adjust_gamma" href="#Images.adjust_gamma"><code>Images.adjust_gamma</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">gamma_corrected_img = adjust_gamma(img, gamma)</code></pre><p>Returns a gamma corrected image.</p><p><strong>Details</strong></p><p>Gamma correction is a non-linear  transformation given by the relation</p><div>\[f(x) = x^\gamma \quad \text{for} \; x \in \mathbb{R}, \gamma &gt; 0.\]</div><p>It is called a <em>power law</em> transformation because one quantity varies as a power of another quantity.</p><p>Gamma correction has historically been used to preprocess an image to compensate for the fact that the intensity of light generated by a physical device is not usually a linear function of the applied signal but instead follows a power law [1]. For example, for many Cathode Ray Tubes (CRTs) the emitted light intensity on the display is approximately equal to the voltage raised to the power of γ, where γ ∈ [1.8, 2.8]. Hence preprocessing a raw image with an exponent of 1/γ  would have ensured a linear response to brightness.</p><p>Research in psychophysics has also established an <a href="https://en.wikipedia.org/wiki/Stevens%27s_power_law">empirical  power law </a>  between light intensity and perceptual brightness. Hence, gamma correction often serves as a useful image enhancement tool.</p><p><strong>Options</strong></p><p>Various options for the parameters of this function are described in more detail below.</p><p><strong>Choices for <code>img</code></strong></p><p>The <code>adjust_gamma</code> function can handle a variety of input types. The returned image depends on the input type. If the input is an <code>Image</code> then the resulting image is of the same type and has the same properties.</p><p>For coloured images, the input is converted to YIQ type and the Y channel is gamma corrected. This is the combined with the I and Q channels and the resulting image converted to the same type as the input.</p><p><strong>Choice for <code>gamma</code></strong></p><p>The <code>gamma</code> value must be a non-zero positive number.</p><p><strong>Example</strong></p><pre><code class="language-julia">using Images, ImageView

# Create an example image consisting of a linear ramp of intensities.
n = 32
intensities = 0.0:(1.0/n):1.0
img = repeat(intensities, inner=(20,20))&#39;

# Brighten the dark tones.
imgadj = adjust_gamma(img,1/2)

# Display the original and adjusted image.
imshow(img)
imshow(imgadj)</code></pre><p><strong>References</strong></p><ol><li>W. Burger and M. J. Burge. <em>Digital Image Processing</em>. Texts in Computer Science, 2016. <a href="https://doi.org/10.1007/978-1-4471-6684-9">doi:10.1007/978-1-4471-6684-9</a></li></ol><p>See also: <a href="@ref">histmatch</a>,<a href="@ref">clahe</a>, and <a href="@ref">imhist</a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Images.imstretch" href="#Images.imstretch"><code>Images.imstretch</code></a> — <span class="docstring-category">Function</span></header><section><div><p><code>imgs = imstretch(img, m, slope)</code> enhances or reduces (for slope &gt; 1 or &lt; 1, respectively) the contrast near saturation (0 and 1). This is essentially a symmetric gamma-correction. For a pixel of brightness <code>p</code>, the new intensity is <code>1/(1+(m/(p+eps))^slope)</code>.</p><p>This assumes the input <code>img</code> has intensities between 0 and 1.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Images.imadjustintensity" href="#Images.imadjustintensity"><code>Images.imadjustintensity</code></a> — <span class="docstring-category">Function</span></header><section><div><p><code>imadjustintensity(img [, (minval,maxval)]) -&gt; Image</code></p><p>Map intensities over the interval <code>(minval,maxval)</code> to the interval    <code>[0,1]</code>. This is equivalent to <code>map(ScaleMinMax(eltype(img), minval,    maxval), img)</code>.  (minval,maxval) defaults to <code>extrema(img)</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Images.complement" href="#Images.complement"><code>Images.complement</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">y = complement(x)</code></pre><p>Take the complement <code>1-x</code> of <code>x</code>.  If <code>x</code> is a color with an alpha channel, the alpha channel is left untouched. Don&#39;t forget to add a dot when <code>x</code> is an array: <code>complement.(x)</code></p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Images.histmatch" href="#Images.histmatch"><code>Images.histmatch</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">hist_matched_img = histmatch(img, oimg, nbins)</code></pre><p>Returns a histogram matched image with a granularity of <code>nbins</code> number of bins. The first argument <code>img</code> is the image to be matched, and the second argument <code>oimg</code> is the image having the desired histogram to be matched to.</p><p><strong>Details</strong></p><p>The purpose of histogram matching is to transform the intensities in a source image so that the intensities distribute according to the histogram of a specified target image. If one interprets histograms as piecewise-constant models of probability density functions (see <a href="@ref">imhist</a>), then the histogram matching task can be modelled as the problem of transforming one probability distribution into another [1].  It turns out that the solution to this transformation problem involves the cumulative and inverse cumulative distribution functions of the source and target probability density functions.</p><p>In particular, let the random variables <span>$x \thicksim p_{x}$</span> and <span>$z \thicksim p_{z}$</span>  represent an intensity in the source and target image respectively, and let</p><div>\[ S(x) = \int_0^{x}p_{x}(w)\mathrm{d} w \quad \text{and} \quad
 T(z) = \int_0^{z}p_{z}(w)\mathrm{d} w\]</div><p>represent their concomitant cumulative disitribution functions. Then the sought-after mapping <span>$Q(\cdot)$</span> such that <span>$Q(x) \thicksim p_{z}$</span> is given by</p><div>\[Q(x) =  T^{-1}\left( S(x) \right),\]</div><p>where <span>$T^{-1}(y) = \operatorname{min} \{ x \in \mathbb{R} : y \leq T(x) \}$</span> is the inverse cumulative distribution function of <span>$T(x)$</span>.</p><p>The mapping suggests that one can conceptualise histogram matching as performing histogram equalisation on the source and target image and relating the two equalised histograms. Refer to <a href="@ref">histeq</a> for more details on histogram equalisation.</p><p><strong>Options</strong></p><p>Various options for the parameters of this function are described in more detail below.</p><p><strong>Choices for <code>img</code> and <code>oimg</code></strong></p><p>The <code>histmatch</code> function can handle a variety of input types. The returned image depends on the input type. If the input is an <code>Image</code> then the resulting image is of the same type and has the same properties.</p><p>For coloured images, the input is converted to <a href="https://en.wikipedia.org/wiki/YIQ">YIQ</a>  type and the Y channel is gamma corrected. This is then combined with the I and Q channels and the resulting image converted to the same type as the input.</p><p><strong>Choices for <code>nbins</code></strong></p><p>You can specify the total number of bins in the histogram.</p><p><strong>Example</strong></p><pre><code class="language-julia">using Images, TestImages, ImageView

img_source = testimage(&quot;mandril_gray&quot;)
img_target = adjust_gamma(img_source,1/2)
img_transformed = histmatch(img_source, img_target)
#=
    A visual inspection confirms that img_transformed resembles img_target
    much more closely than img_source.
=#
imshow(img_source)
imshow(img_target)
imshow(img_transformed)</code></pre><p><strong>References</strong></p><ol><li>W. Burger and M. J. Burge. <em>Digital Image Processing</em>. Texts in Computer Science, 2016. <a href="https://doi.org/10.1007/978-1-4471-6684-9">doi:10.1007/978-1-4471-6684-9</a></li></ol><p>See also: <a href="@ref">histeq</a>,<a href="@ref">clahe</a>, and <a href="@ref">imhist</a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Images.clahe" href="#Images.clahe"><code>Images.clahe</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">hist_equalised_img = clahe(img, nbins, xblocks = 8, yblocks = 8, clip = 3)
</code></pre><p>Performs Contrast Limited Adaptive Histogram Equalisation (CLAHE) on the input image. It differs from ordinary histogram equalization in the respect that the adaptive method computes several histograms, each corresponding to a distinct section of the image, and uses them to redistribute the lightness values of the image. It is therefore suitable for improving the local contrast and enhancing the definitions of edges in each region of an image.</p><p><strong>Details</strong></p><p>Histogram equalisation was initially conceived to  improve the contrast in a single-channel grayscale image. The method transforms the distribution of the intensities in an image so that they are as uniform as possible [1]. The natural justification for uniformity is that the image has better contrast  if the intensity levels of an image span a wide range on the intensity scale. As it turns out, the necessary transformation is a mapping based on the cumulative histogram–-see <a href="@ref">histeq</a> for more details.</p><p>A natural extension of histogram equalisation is to apply the contrast enhancement locally rather than globally [2]. Conceptually, one can imagine that the process involves partitioning the image into a grid of rectangular regions and applying histogram equalisation based on the local CDF of each contextual region. However, to smooth the transition of the pixels from one contextual region to another,  the mapping of a pixel is not done soley based on the local CDF of its contextual region. Rather, the mapping of a pixel is a bilinear blend based on the CDF of its contextual region, and the CDFs of the immediate neighbouring regions.</p><p>In adaptive histogram equalisation the image <span>$\mathbf{G}$</span> is partitioned into <span>$P \times Q$</span> equisized submatrices,</p><div>\[\mathbf{G} =  \begin{bmatrix}
\mathbf{G}_{11} &amp; \mathbf{G}_{12} &amp; \ldots &amp; \mathbf{G}_{1C} \\
\mathbf{G}_{21} &amp; \mathbf{G}_{22} &amp; \ldots &amp; \mathbf{G}_{2C} \\
\vdots &amp; \vdots &amp; \ldots &amp; \vdots \\
\mathbf{G}_{R1} &amp; \mathbf{G}_{R2} &amp; \ldots &amp; \mathbf{G}_{RC} \\
\end{bmatrix}.\]</div><p>For each submatrix <span>$\mathbf{G}_{rc}$</span>, one computes a concomitant CDF, which we shall denote by <span>$T_{rc}(G_{i,j})$</span>. In order to determine which CDFs will be used in the bilinear interpolation step, it is useful to  introduce the function</p><div>\[\Phi(\mathbf{G}_{rc}) = \left(  \phi_{rc},  \phi&#39;_{rc}\right) \triangleq \left(\frac{rP}{2}, \frac{cQ}{2} \right)\]</div><p>and to form the sequences  <span>$\left(\phi_{11}, \phi_{21}, \ldots, \phi_{R1} \right)$</span> and <span>$\left(\phi&#39;_{11}, \phi&#39;_{12}, \ldots, \phi&#39;_{1C} \right)$</span>. For a given pixel <span>$G_{i,j}(\omega)$</span>, values of <span>$r$</span> and <span>$c$</span> are implicitly defined by the solution to the inequalities</p><div>\[\phi_{r1} \le i \le \phi_{(r+1)1}  \quad \text{and}  \quad  \phi&#39;_{1c} \le j \le \phi&#39;_{1(c+1)}.\]</div><p>With <span>$r$</span> and <span>$c$</span> appropriately defined, the requisite CDFs are given by</p><div>\[\begin{aligned}
T_1(v)  &amp; \triangleq  T_{rc}(G_{i,j}) \\
T_2(v)  &amp; \triangleq  T_{(r+1)c}(G_{i,j}) \\
T_3(v)  &amp; \triangleq  T_{(r+1)(c+1)}(G_{i,j}) \\
T_4(v)  &amp; \triangleq  T_{r(c+1)}(G_{i,j}).
\end{aligned}\]</div><p>Finally, with</p><div>\[\begin{aligned}
t  &amp; \triangleq  \frac{i - \phi_{r1}}{\phi_{(r+1)1} - \phi_{r1} } \\
u  &amp; \triangleq  \frac{j - \phi&#39;_{1c}}{\phi&#39;_{1(c+1)} - \phi&#39;_{1c} },
\end{aligned}\]</div><p>the bilinear interpolated transformation that maps an intensity <span>$v$</span> at location <span>$(i,j)$</span> in the image to an intensity <span>$v&#39;$</span> is given by [3]</p><div>\[v&#39; \triangleq \bar{T}(v)  = (1-t) (1-u)T_1(G_{i,j}) + t(1-u)T_2(G_{i,j}) + tuT_3(G_{i,j}) +(1-t)uT_4(G_{i,j}).\]</div><p>An unfortunate side-effect of contrast enhancement is that it has a tendency to amplify the level of noise in an image, especially when the magnitude of the contrast enhancement is very high. The magnitude of contrast enhancement is associated with the gradient of <span>$T(\cdot)$</span>, because the  gradient determines the extent to which consecutive input intensities are stretched across the grey-level spectrum. One can diminish the level of noise amplification by limiting the magnitude of the contrast enhancement, that is, by limiting the magnitude of the gradient.</p><p>Since the derivative of <span>$T(\cdot)$</span> is the empirical density <span>$\hat{f}_{G}$</span>, the slope of the mapping function at any input intensity is proportional to the height of the histogram  <span>$\hat{f}_{G}$</span> at that intensity.  Therefore, limiting the slope of the local mapping function is equivalent to clipping the height of the histogram. A detailed description of the  implementation  details of the clipping process can be found in [2].</p><p><strong>Options</strong></p><p>Various options for the parameters of this function are described in more detail below.</p><p><strong>Choices for <code>img</code></strong></p><p>The <code>clahe</code> function can handle a variety of input types. The returned image depends on the input type. If the input is an <code>Image</code> then the resulting image is of the same type and has the same properties.</p><p>For coloured images, the input is converted to <a href="https://en.wikipedia.org/wiki/YIQ">YIQ</a> type and the Y channel is equalised. This is the combined with the I and Q channels and the resulting image converted to the same type as the input.</p><p><strong>Choices for <code>nbins</code></strong></p><p>You can specify the total number of bins in the histogram of each local region.</p><p><strong>Choices for <code>xblocks</code> and <code>yblocks</code></strong></p><p>The <code>xblocks</code> and <code>yblocks</code> specify the number of blocks to divide the input image into in each direction. By default both values are set to eight.</p><p><strong>Choices for <code>clip</code></strong></p><p>The <code>clip</code> parameter specifies the value at which the histogram is clipped.  The default value is three. The excess in the histogram bins with value exceeding <code>clip</code> is redistributed among the other bins.</p><p><strong>Example</strong></p><pre><code class="language-julia">
using Images, TestImages, ImageView

img =  testimage(&quot;mandril_gray&quot;)
imgeq = clahe(img,256, xblocks = 50, yblocks = 50)

imshow(img)
imshow(imgeq)</code></pre><p><strong>References</strong></p><ol><li>R. C. Gonzalez and R. E. Woods. <em>Digital Image Processing (3rd Edition)</em>.  Upper Saddle River, NJ, USA: Prentice-Hall,  2006.</li><li>S. M. Pizer, E. P. Amburn, J. D. Austin, R. Cromartie, A. Geselowitz, T. Greer, B. ter Haar Romeny, J. B. Zimmerman and K. Zuiderveld “Adaptive histogram equalization and its variations,” <em>Computer Vision, Graphics, and Image Processing</em>, vol. 38, no. 1, p. 99, Apr. 1987. <a href="https://doi.org/10.1016/s0734-189x(87)80156-1">10.1016/S0734-189X(87)80186-X</a></li><li>W. H. Press, S. A. Teukolsky, W. T. Vetterling, and B. P. Flannery.  <em>Numerical Recipes: The Art of Scientific Computing (3rd Edition)</em>. New York, NY, USA: Cambridge University Press, 2007.</li></ol><p>See also: <a href="@ref">histmatch</a>,<a href="@ref">histeq</a>, <a href="@ref">imhist</a> and  <a href="@ref">adjust_gamma</a>.</p></div></section></article><h3 id="Spatial-transformations-and-resizing-1"><a class="docs-heading-anchor" href="#Spatial-transformations-and-resizing-1">Spatial transformations and resizing</a><a class="docs-heading-anchor-permalink" href="#Spatial-transformations-and-resizing-1" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="ImageTransformations.imresize" href="#ImageTransformations.imresize"><code>ImageTransformations.imresize</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">imresize(img, sz) -&gt; imgr
imresize(img, inds) -&gt; imgr
imresize(img; ratio) -&gt; imgr</code></pre><p>Change <code>img</code> to be of size <code>sz</code> (or to have indices <code>inds</code>). If <code>ratio</code> is used, then <code>sz = ceil(Int, size(img).*ratio)</code>. This interpolates the values at sub-pixel locations. If you are shrinking the image, you risk aliasing unless you low-pass filter <code>img</code> first.</p><p><strong>Examples</strong></p><pre><code class="language-julia">julia&gt; img = testimage(&quot;lena_gray_256&quot;) # 256*256
julia&gt; imresize(img, 128, 128) # 128*128
julia&gt; imresize(img, 1:128, 1:128) # 128*128
julia&gt; imresize(img, (128, 128)) # 128*128
julia&gt; imresize(img, (1:128, 1:128)) # 128*128
julia&gt; imresize(img, (1:128, )) # 128*256
julia&gt; imresize(img, 128) # 128*256
julia&gt; imresize(img, ratio = 0.5) # 128*128

σ = map((o,n)-&gt;0.75*o/n, size(img), sz)
kern = KernelFactors.gaussian(σ)   # from ImageFiltering
imgr = imresize(imfilter(img, kern, NA()), sz)</code></pre><p>See also <a href="#ImageTransformations.restrict"><code>restrict</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageTransformations.restrict" href="#ImageTransformations.restrict"><code>ImageTransformations.restrict</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">restrict(img[, region]) -&gt; imgr</code></pre><p>Reduce the size of <code>img</code> by approximately two-fold along the dimensions listed in <code>region</code>, or all spatial coordinates if <code>region</code> is not specified. The term <code>restrict</code> is taken from the coarsening operation of algebraic multigrid methods; it is the adjoint of &quot;prolongation&quot; (which is essentially interpolation). <code>restrict</code> anti-aliases the image as it goes, so is better than a naive summation over 2x2 blocks. The implementation of <code>restrict</code> has been tuned for performance, and should be a fast method for constructing <a href="https://en.wikipedia.org/wiki/Pyramid_(image_processing)">pyramids</a>.</p><p>If <code>l</code> is the size of <code>img</code> along a particular dimension, <code>restrict</code> produces an array of size <code>(l+1)÷2</code> for odd <code>l</code>, and <code>l÷2 + 1</code> for even <code>l</code>. See the example below for an explanation.</p><p>See also <a href="#ImageTransformations.imresize"><code>imresize</code></a>.</p><p><strong>Example</strong></p><pre><code class="language-julia">a_course = [0, 1, 0.3]</code></pre><p>If we were to interpolate this at the halfway points, we&#39;d get</p><pre><code class="language-julia">a_fine = [0, 0.5, 1, 0.65, 0.3]</code></pre><p>Note that <code>a_fine</code> is obtained from <code>a_course</code> via the <em>prolongation</em> operator <code>P</code> as <code>P*a_course</code>, where</p><pre><code class="language-julia">P = [1   0   0;      # this line &quot;copies over&quot; the first point
     0.5 0.5 0;      # this line takes the mean of the first and second point
     0   1   0;      # copy the second point
     0   0.5 0.5;    # take the mean of the second and third
     0   0   1]      # copy the third</code></pre><p><code>restrict</code> is the adjoint of prolongation. Consequently,</p><pre><code class="language-julia">julia&gt; restrict(a_fine)
3-element Array{Float64,1}:
 0.125
 0.7875
 0.3125

julia&gt; (P&#39;*a_fine)/2
3-element Array{Float64,1}:
 0.125
 0.7875
 0.3125</code></pre><p>where the division by 2 approximately preserves the mean intensity of the input.</p><p>As we see here, for odd-length <code>a_fine</code>, restriction is the adjoint of interpolation at half-grid points. When <code>length(a_fine)</code> is even, restriction is the adjoint of interpolation at 1/4 and 3/4-grid points. This turns out to be the origin of the <code>l-&gt;l÷2 + 1</code> behavior.</p><p>One consequence of this definition is that the edges move towards zero:</p><pre><code class="language-julia">julia&gt; restrict(ones(11))
6-element Array{Float64,1}:
 0.75
 1.0
 1.0
 1.0
 1.0
 0.75</code></pre><p>In some applications (e.g., image registration), you may find it useful to trim the edges.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageTransformations.warp" href="#ImageTransformations.warp"><code>ImageTransformations.warp</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">warp(img, tform, [indices], [degree = Linear()], [fill = NaN]) -&gt; imgw</code></pre><p>Transform the coordinates of <code>img</code>, returning a new <code>imgw</code> satisfying <code>imgw[I] = img[tform(I)]</code>. This approach is known as backward mode warping. The transformation <code>tform</code> must accept a <code>SVector</code> as input. A useful package to create a wide variety of such transformations is <a href="https://github.com/FugroRoames/CoordinateTransformations.jl">CoordinateTransformations.jl</a>.</p><p><strong>Reconstruction scheme</strong></p><p>During warping, values for <code>img</code> must be reconstructed at arbitrary locations <code>tform(I)</code> which do not lie on to the lattice of pixels. How this reconstruction is done depends on the type of <code>img</code> and the optional parameter <code>degree</code>.</p><p>When <code>img</code> is a plain array, then on-grid b-spline interpolation will be used. It is possible to configure what degree of b-spline to use with the parameter <code>degree</code>. For example one can use <code>degree = Linear()</code> for linear interpolation, <code>degree = Constant()</code> for nearest neighbor interpolation, or <code>degree = Quadratic(Flat())</code> for quadratic interpolation.</p><p>In the case <code>tform(I)</code> maps to indices outside the original <code>img</code>, those locations are set to a value <code>fill</code> (which defaults to <code>NaN</code> if the element type supports it, and <code>0</code> otherwise). The parameter <code>fill</code> also accepts extrapolation schemes, such as <code>Flat()</code>, <code>Periodic()</code> or <code>Reflect()</code>.</p><p>For more control over the reconstruction scheme –- and how beyond-the-edge points are handled –- pass <code>img</code> as an <code>AbstractInterpolation</code> or <code>AbstractExtrapolation</code> from <a href="https://github.com/JuliaMath/Interpolations.jl">Interpolations.jl</a>.</p><p><strong>The meaning of the coordinates</strong></p><p>The output array <code>imgw</code> has indices that would result from applying <code>inv(tform)</code> to the indices of <code>img</code>. This can be very handy for keeping track of how pixels in <code>imgw</code> line up with pixels in <code>img</code>.</p><p>If you just want a plain array, you can &quot;strip&quot; the custom indices with <code>parent(imgw)</code>.</p><p><strong>Examples: a 2d rotation (see JuliaImages documentation for pictures)</strong></p><pre><code class="language-none">julia&gt; using Images, CoordinateTransformations, TestImages, OffsetArrays

julia&gt; img = testimage(&quot;lighthouse&quot;);

julia&gt; axes(img)
(Base.OneTo(512),Base.OneTo(768))

# Rotate around the center of `img`
julia&gt; tfm = recenter(RotMatrix(-pi/4), center(img))
AffineMap([0.707107 0.707107; -0.707107 0.707107], [-196.755,293.99])

julia&gt; imgw = warp(img, tfm);

julia&gt; axes(imgw)
(-196:709,-68:837)

# Alternatively, specify the origin in the image itself
julia&gt; img0 = OffsetArray(img, -30:481, -384:383);  # origin near top of image

julia&gt; rot = LinearMap(RotMatrix(-pi/4))
LinearMap([0.707107 -0.707107; 0.707107 0.707107])

julia&gt; imgw = warp(img0, rot);

julia&gt; axes(imgw)
(-293:612,-293:611)

julia&gt; imgr = parent(imgw);

julia&gt; axes(imgr)
(Base.OneTo(906),Base.OneTo(905))</code></pre></div></section></article><h3 id="Image-statistics-1"><a class="docs-heading-anchor" href="#Image-statistics-1">Image statistics</a><a class="docs-heading-anchor-permalink" href="#Image-statistics-1" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="Images.minfinite" href="#Images.minfinite"><code>Images.minfinite</code></a> — <span class="docstring-category">Function</span></header><section><div><p><code>m = minfinite(A)</code> calculates the minimum value in <code>A</code>, ignoring any values that are not finite (Inf or NaN).</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Images.maxfinite" href="#Images.maxfinite"><code>Images.maxfinite</code></a> — <span class="docstring-category">Function</span></header><section><div><p><code>m = maxfinite(A)</code> calculates the maximum value in <code>A</code>, ignoring any values that are not finite (Inf or NaN).</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Images.maxabsfinite" href="#Images.maxabsfinite"><code>Images.maxabsfinite</code></a> — <span class="docstring-category">Function</span></header><section><div><p><code>m = maxabsfinite(A)</code> calculates the maximum absolute value in <code>A</code>, ignoring any values that are not finite (Inf or NaN).</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Images.meanfinite" href="#Images.meanfinite"><code>Images.meanfinite</code></a> — <span class="docstring-category">Function</span></header><section><div><p><code>M = meanfinite(img, region)</code> calculates the mean value along the dimensions listed in <code>region</code>, ignoring any non-finite values.</p></div></section></article><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>ssd</code>. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>ssdn</code>. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>sad</code>. Check Documenter&#39;s build log for details.</p></div></div><div class="admonition is-warning"><header class="admonition-header">Missing docstring.</header><div class="admonition-body"><p>Missing docstring for <code>sadn</code>. Check Documenter&#39;s build log for details.</p></div></div><h3 id="Morphological-operations-1"><a class="docs-heading-anchor" href="#Morphological-operations-1">Morphological operations</a><a class="docs-heading-anchor-permalink" href="#Morphological-operations-1" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="ImageMorphology.dilate" href="#ImageMorphology.dilate"><code>ImageMorphology.dilate</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">imgd = dilate(img, [region])</code></pre><p>perform a max-filter over nearest-neighbors. The default is 8-connectivity in 2d, 27-connectivity in 3d, etc. You can specify the list of dimensions that you want to include in the connectivity, e.g., <code>region = [1,2]</code> would exclude the third dimension from filtering.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageMorphology.erode" href="#ImageMorphology.erode"><code>ImageMorphology.erode</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">imge = erode(img, [region])</code></pre><p>perform a min-filter over nearest-neighbors. The default is 8-connectivity in 2d, 27-connectivity in 3d, etc. You can specify the list of dimensions that you want to include in the connectivity, e.g., <code>region = [1,2]</code> would exclude the third dimension from filtering.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageMorphology.opening" href="#ImageMorphology.opening"><code>ImageMorphology.opening</code></a> — <span class="docstring-category">Function</span></header><section><div><p><code>imgo = opening(img, [region])</code> performs the <code>opening</code> morphology operation, equivalent to <code>dilate(erode(img))</code>. <code>region</code> allows you to control the dimensions over which this operation is performed.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageMorphology.closing" href="#ImageMorphology.closing"><code>ImageMorphology.closing</code></a> — <span class="docstring-category">Function</span></header><section><div><p><code>imgc = closing(img, [region])</code> performs the <code>closing</code> morphology operation, equivalent to <code>erode(dilate(img))</code>. <code>region</code> allows you to control the dimensions over which this operation is performed.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageMorphology.tophat" href="#ImageMorphology.tophat"><code>ImageMorphology.tophat</code></a> — <span class="docstring-category">Function</span></header><section><div><p><code>imgth = tophat(img, [region])</code> performs <code>top hat</code> of an image, which is defined as the image minus its morphological opening. <code>region</code> allows you to control the dimensions over which this operation is performed.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageMorphology.bothat" href="#ImageMorphology.bothat"><code>ImageMorphology.bothat</code></a> — <span class="docstring-category">Function</span></header><section><div><p><code>imgbh = bothat(img, [region])</code> performs <code>bottom hat</code> of an image, which is defined as its morphological closing minus the original image. <code>region</code> allows you to control the dimensions over which this operation is performed.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageMorphology.morphogradient" href="#ImageMorphology.morphogradient"><code>ImageMorphology.morphogradient</code></a> — <span class="docstring-category">Function</span></header><section><div><p><code>imgmg = morphogradient(img, [region])</code> returns morphological gradient of the image, which is the difference between the dilation and the erosion of a given image. <code>region</code> allows you to control the dimensions over which this operation is performed.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageMorphology.morpholaplace" href="#ImageMorphology.morpholaplace"><code>ImageMorphology.morpholaplace</code></a> — <span class="docstring-category">Function</span></header><section><div><p><code>imgml = morpholaplace(img, [region])</code> performs <code>Morphological Laplacian</code> of an image, which is defined as the arithmetic difference between the internal and the external gradient. <code>region</code> allows you to control the dimensions over which this operation is performed.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageMorphology.label_components" href="#ImageMorphology.label_components"><code>ImageMorphology.label_components</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">label = label_components(tf, [connectivity])
label = label_components(tf, [region])</code></pre><p>Find the connected components in a binary array <code>tf</code>. There are two forms that <code>connectivity</code> can take:</p><ul><li>It can be a boolean array of the same dimensionality as <code>tf</code>, of size 1 or 3</li></ul><p>along each dimension. Each entry in the array determines whether a given neighbor is used for connectivity analyses. For example, <code>connectivity = trues(3,3)</code> would use 8-connectivity and test all pixels that touch the current one, even the corners.</p><ul><li>You can provide a list indicating which dimensions are used to</li></ul><p>determine connectivity. For example, <code>region = [1,3]</code> would not test neighbors along dimension 2 for connectivity. This corresponds to just the nearest neighbors, i.e., 4-connectivity in 2d and 6-connectivity in 3d.</p><p>The default is <code>region = 1:ndims(A)</code>.</p><p>The output <code>label</code> is an integer array, where 0 is used for background pixels, and each connected region gets a different integer index.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageMorphology.component_boxes" href="#ImageMorphology.component_boxes"><code>ImageMorphology.component_boxes</code></a> — <span class="docstring-category">Function</span></header><section><div><p><code>component_boxes(labeled_array)</code> -&gt; an array of bounding boxes for each label, including the background label 0</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageMorphology.component_lengths" href="#ImageMorphology.component_lengths"><code>ImageMorphology.component_lengths</code></a> — <span class="docstring-category">Function</span></header><section><div><p><code>component_lengths(labeled_array)</code> -&gt; an array of areas (2D), volumes (3D), etc. for each label, including the background label 0</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageMorphology.component_indices" href="#ImageMorphology.component_indices"><code>ImageMorphology.component_indices</code></a> — <span class="docstring-category">Function</span></header><section><div><p><code>component_indices(labeled_array)</code> -&gt; an array of pixels for each label, including the background label 0</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageMorphology.component_subscripts" href="#ImageMorphology.component_subscripts"><code>ImageMorphology.component_subscripts</code></a> — <span class="docstring-category">Function</span></header><section><div><p><code>component_subscripts(labeled_array)</code> -&gt; an array of pixels for each label, including the background label 0</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageMorphology.component_centroids" href="#ImageMorphology.component_centroids"><code>ImageMorphology.component_centroids</code></a> — <span class="docstring-category">Function</span></header><section><div><p><code>component_centroids(labeled_array)</code> -&gt; an array of centroids for each label, including the background label 0</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Images.FeatureTransform.feature_transform" href="#Images.FeatureTransform.feature_transform"><code>Images.FeatureTransform.feature_transform</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">feature_transform(I::AbstractArray{Bool, N}, [w=nothing]) -&gt; F</code></pre><p>Compute the feature transform of a binary image <code>I</code>, finding the closest &quot;feature&quot; (positions where <code>I</code> is <code>true</code>) for each location in <code>I</code>.  Specifically, <code>F[i]</code> is a <code>CartesianIndex</code> encoding the position closest to <code>i</code> for which <code>I[F[i]]</code> is <code>true</code>.  In cases where two or more features in <code>I</code> have the same distance from <code>i</code>, an arbitrary feature is chosen. If <code>I</code> has no <code>true</code> values, then all locations are mapped to an index where each coordinate is <code>typemin(Int)</code>.</p><p>Optionally specify the weight <code>w</code> assigned to each coordinate.  For example, if <code>I</code> corresponds to an image where voxels are anisotropic, <code>w</code> could be the voxel spacing along each coordinate axis. The default value of <code>nothing</code> is equivalent to <code>w=(1,1,...)</code>.</p><p>See also: <a href="#Images.FeatureTransform.distance_transform"><code>distance_transform</code></a>.</p><p><strong>Citation</strong></p><p>&#39;A Linear Time Algorithm for Computing Exact Euclidean Distance Transforms of Binary Images in Arbitrary Dimensions&#39; <a href="DOI: 10.1109/TPAMI.2003.1177156">Maurer et al., 2003</a></p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Images.FeatureTransform.distance_transform" href="#Images.FeatureTransform.distance_transform"><code>Images.FeatureTransform.distance_transform</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">distance_transform(F::AbstractArray{CartesianIndex}, [w=nothing]) -&gt; D</code></pre><p>Compute the distance transform of <code>F</code>, where each element <code>F[i]</code> represents a &quot;target&quot; or &quot;feature&quot; location assigned to <code>i</code>. Specifically, <code>D[i]</code> is the distance between <code>i</code> and <code>F[i]</code>. Optionally specify the weight <code>w</code> assigned to each coordinate; the default value of <code>nothing</code> is equivalent to <code>w=(1,1,...)</code>.</p><p>See also: <a href="#Images.FeatureTransform.feature_transform"><code>feature_transform</code></a>.</p></div></section></article><h3 id="Interpolation-1"><a class="docs-heading-anchor" href="#Interpolation-1">Interpolation</a><a class="docs-heading-anchor-permalink" href="#Interpolation-1" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="Images.bilinear_interpolation" href="#Images.bilinear_interpolation"><code>Images.bilinear_interpolation</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">P = bilinear_interpolation(img, r, c)</code></pre><p>Bilinear Interpolation is used to interpolate functions of two variables on a rectilinear 2D grid.</p><p>The interpolation is done in one direction first and then the values obtained are used to do the interpolation in the second direction.</p></div></section></article><h3 id="Integral-Images-1"><a class="docs-heading-anchor" href="#Integral-Images-1">Integral Images</a><a class="docs-heading-anchor-permalink" href="#Integral-Images-1" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="Images.integral_image" href="#Images.integral_image"><code>Images.integral_image</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">integral_img = integral_image(img)</code></pre><p>Returns the integral image of an image. The integral image is calculated by assigning to each pixel the sum of all pixels above it and to its left, i.e. the rectangle from (1, 1) to the pixel. An integral image is a data structure which helps in efficient calculation of sum of pixels in a rectangular subset of an image. See <code>boxdiff</code> for more information.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Images.boxdiff" href="#Images.boxdiff"><code>Images.boxdiff</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">sum = boxdiff(integral_image, ytop:ybot, xtop:xbot)
sum = boxdiff(integral_image, CartesianIndex(tl_y, tl_x), CartesianIndex(br_y, br_x))
sum = boxdiff(integral_image, tl_y, tl_x, br_y, br_x)</code></pre><p>An integral image is a data structure which helps in efficient calculation of sum of pixels in a rectangular subset of an image. It stores at each pixel the sum of all pixels above it and to its left. The sum of a window in an image can be directly calculated using four array references of the integral image, irrespective of the size of the window, given the <code>yrange</code> and <code>xrange</code> of the window. Given an integral image -</p><pre><code class="language-none">    A - - - - - - B -
    - * * * * * * * -
    - * * * * * * * -
    - * * * * * * * -
    - * * * * * * * -
    - * * * * * * * -
    C * * * * * * D -
    - - - - - - - - -</code></pre><p>The sum of pixels in the area denoted by * is given by S = D + A - B - C.</p></div></section></article><h3 id="Pyramids-1"><a class="docs-heading-anchor" href="#Pyramids-1">Pyramids</a><a class="docs-heading-anchor-permalink" href="#Pyramids-1" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="Images.gaussian_pyramid" href="#Images.gaussian_pyramid"><code>Images.gaussian_pyramid</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">pyramid = gaussian_pyramid(img, n_scales, downsample, sigma)</code></pre><p>Returns a  gaussian pyramid of scales <code>n_scales</code>, each downsampled by a factor <code>downsample</code> &gt; 1 and <code>sigma</code> for the gaussian kernel.</p></div></section></article><h3 id="Phantoms-1"><a class="docs-heading-anchor" href="#Phantoms-1">Phantoms</a><a class="docs-heading-anchor-permalink" href="#Phantoms-1" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="Images.shepp_logan" href="#Images.shepp_logan"><code>Images.shepp_logan</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">phantom = shepp_logan(N,[M]; highContrast=true)</code></pre><p>output the NxM Shepp-Logan phantom, which is a standard test image usually used for comparing image reconstruction algorithms in the field of computed tomography (CT) and magnetic resonance imaging (MRI). If the argument M is omitted, the phantom is of size NxN. When setting the keyword argument <code>highConstrast</code> to false, the CT version of the phantom is created. Otherwise, the high contrast MRI version is calculated.</p></div></section></article><h2 id="Image-metadata-utilities-1"><a class="docs-heading-anchor" href="#Image-metadata-utilities-1">Image metadata utilities</a><a class="docs-heading-anchor-permalink" href="#Image-metadata-utilities-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ImageMetadata.ImageMeta" href="#ImageMetadata.ImageMeta"><code>ImageMetadata.ImageMeta</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>ImageMeta</code> is an AbstractArray that can have metadata, stored in a dictionary.</p><p>Construct an image with <code>ImageMeta(A, props)</code> (for a properties dictionary <code>props</code>), or with <code>ImageMeta(A, prop1=val1, prop2=val2, ...)</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="Images.data" href="#Images.data"><code>Images.data</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">arraydata(img::ImageMeta) -&gt; array</code></pre><p>Extract the data from <code>img</code>, omitting the properties dictionary. <code>array</code> shares storage with <code>img</code>, so changes to one affect the other.</p><p>See also: <a href="#ImageMetadata.properties"><code>properties</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageMetadata.properties" href="#ImageMetadata.properties"><code>ImageMetadata.properties</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">properties(imgmeta) -&gt; props</code></pre><p>Extract the properties dictionary <code>props</code> for <code>imgmeta</code>. <code>props</code> shares storage with <code>img</code>, so changes to one affect the other.</p><p>See also: <a href="@ref"><code>data</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageMetadata.copyproperties" href="#ImageMetadata.copyproperties"><code>ImageMetadata.copyproperties</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">copyproperties(img::ImageMeta, data) -&gt; imgnew</code></pre><p>Create a new &quot;image,&quot; copying the properties dictionary of <code>img</code> but using the data of the AbstractArray <code>data</code>. Note that changing the properties of <code>imgnew</code> does not affect the properties of <code>img</code>.</p><p>See also: <a href="#ImageMetadata.shareproperties"><code>shareproperties</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageMetadata.shareproperties" href="#ImageMetadata.shareproperties"><code>ImageMetadata.shareproperties</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">shareproperties(img::ImageMeta, data) -&gt; imgnew</code></pre><p>Create a new &quot;image,&quot; reusing the properties dictionary of <code>img</code> but using the data of the AbstractArray <code>data</code>. The two images have synchronized properties; modifying one also affects the other.</p><p>See also: <a href="#ImageMetadata.copyproperties"><code>copyproperties</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageMetadata.spatialproperties" href="#ImageMetadata.spatialproperties"><code>ImageMetadata.spatialproperties</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">spatialproperties(img)</code></pre><p>Return a vector of strings, containing the names of properties that have been declared &quot;spatial&quot; and hence should be permuted when calling <code>permutedims</code>.  Declare such properties like this:</p><pre><code class="language-none">img[:spatialproperties] = [:spacedirections]</code></pre></div></section></article><h2 id="Image-segmentation-1"><a class="docs-heading-anchor" href="#Image-segmentation-1">Image segmentation</a><a class="docs-heading-anchor-permalink" href="#Image-segmentation-1" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="ImageSegmentation.SegmentedImage" href="#ImageSegmentation.SegmentedImage"><code>ImageSegmentation.SegmentedImage</code></a> — <span class="docstring-category">Type</span></header><section><div><p><code>SegmentedImage</code> type contains the index-label mapping, assigned labels, segment mean intensity and pixel count of each segment.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageSegmentation.ImageEdge" href="#ImageSegmentation.ImageEdge"><code>ImageSegmentation.ImageEdge</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">edge = ImageEdge(index1, index2, weight)</code></pre><p>Construct an edge in a Region Adjacency Graph. <code>index1</code> and <code>index2</code> are the integers corresponding to individual pixels/voxels (in the sense of linear indexing via <code>sub2ind</code>), and <code>weight</code> is the edge weight (measures the dissimilarity between pixels/voxels).</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageSegmentation.labels_map" href="#ImageSegmentation.labels_map"><code>ImageSegmentation.labels_map</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">img_labeled = labels_map(seg)</code></pre><p>Return an array containing the label assigned to each pixel.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageSegmentation.segment_labels" href="#ImageSegmentation.segment_labels"><code>ImageSegmentation.segment_labels</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">labels = segment_labels(seg)</code></pre><p>Returns the list of assigned labels</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageSegmentation.segment_pixel_count" href="#ImageSegmentation.segment_pixel_count"><code>ImageSegmentation.segment_pixel_count</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">c = segment_pixel_count(seg, l)</code></pre><p>Returns the count of pixels that are assigned label <code>l</code>. If no label is supplied, it returns a Dict(label=&gt;pixel_count) of all the labels.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageSegmentation.segment_mean" href="#ImageSegmentation.segment_mean"><code>ImageSegmentation.segment_mean</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">m = segment_mean(seg, l)</code></pre><p>Returns the mean intensity of label <code>l</code>. If no label is supplied, it returns a Dict(label=&gt;mean) of all the labels.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageSegmentation.seeded_region_growing" href="#ImageSegmentation.seeded_region_growing"><code>ImageSegmentation.seeded_region_growing</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">seg_img = seeded_region_growing(img, seeds, [kernel_dim], [diff_fn])
seg_img = seeded_region_growing(img, seeds, [neighbourhood], [diff_fn])</code></pre><p>Segments the N-D image <code>img</code> using the seeded region growing algorithm and returns a <a href="#ImageSegmentation.SegmentedImage"><code>SegmentedImage</code></a> containing information about the segments.</p><p><strong>Arguments:</strong></p><ul><li><code>img</code>             :  N-D image to be segmented (arbitrary axes are allowed)</li><li><code>seeds</code>           :  <code>Vector</code> containing seeds. Each seed is a Tuple of a                      CartesianIndex{N} and a label. See below note for more                      information on labels.</li><li><code>kernel_dim</code>      :  (Optional) <code>Vector{Int}</code> having length N or a <code>NTuple{N,Int}</code>                      whose ith element is an odd positive integer representing                      the length of the ith edge of the N-orthotopic neighbourhood</li><li><code>neighbourhood</code>   :  (Optional) Function taking CartesianIndex{N} as input and                      returning the neighbourhood of that point.</li><li><code>diff_fn</code>         :  (Optional) Function that returns a difference measure(δ)                      between the mean color of a region and color of a point</li></ul><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>The labels attached to points must be positive integers, although multiple points can be assigned the same label. The output includes a labelled array that has same indexing as that of input image. Every index is assigned to either one of labels or a special label &#39;0&#39; indicating that the algorithm was unable to assign that index to a unique label.</p></div></div><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; img = zeros(Gray{N0f8},4,4);

julia&gt; img[2:4,2:4] .= 1;

julia&gt; seeds = [(CartesianIndex(3,1),1),(CartesianIndex(2,2),2)];

julia&gt; seg = seeded_region_growing(img, seeds);

julia&gt; labels_map(seg)
4×4 Array{Int64,2}:
 1  1  1  1
 1  2  2  2
 1  2  2  2
 1  2  2  2</code></pre><p><strong>Citation:</strong></p><p>Albert Mehnert, Paul Jackaway (1997), &quot;An improved seeded region growing algorithm&quot;, Pattern Recognition Letters 18 (1997), 1065-1071</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageSegmentation.unseeded_region_growing" href="#ImageSegmentation.unseeded_region_growing"><code>ImageSegmentation.unseeded_region_growing</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">seg_img = unseeded_region_growing(img, threshold, [kernel_dim], [diff_fn])
seg_img = unseeded_region_growing(img, threshold, [neighbourhood], [diff_fn])</code></pre><p>Segments the N-D image using automatic (unseeded) region growing algorithm and returns a <a href="#ImageSegmentation.SegmentedImage"><code>SegmentedImage</code></a> containing information about the segments.</p><p><strong>Arguments:</strong></p><ul><li><code>img</code>             :  N-D image to be segmented (arbitrary axes are allowed)</li><li><code>threshold</code>       :  Upper bound of the difference measure (δ) for considering                      pixel into same segment</li><li><code>kernel_dim</code>      :  (Optional) <code>Vector{Int}</code> having length N or a <code>NTuple{N,Int}</code>                      whose ith element is an odd positive integer representing                      the length of the ith edge of the N-orthotopic neighbourhood</li><li><code>neighbourhood</code>   :  (Optional) Function taking CartesianIndex{N} as input and                      returning the neighbourhood of that point.</li><li><code>diff_fn</code>         :  (Optional) Function that returns a difference measure (δ)                      between the mean color of a region and color of a point</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; img = zeros(Gray{N0f8},4,4);

julia&gt; img[2:4,2:4] .= 1;

julia&gt; seg = unseeded_region_growing(img, 0.2);

julia&gt; labels_map(seg)
4×4 Array{Int64,2}:
 1  1  1  1
 1  2  2  2
 1  2  2  2
 1  2  2  2</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageSegmentation.felzenszwalb" href="#ImageSegmentation.felzenszwalb"><code>ImageSegmentation.felzenszwalb</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">segments                = felzenszwalb(img, k, [min_size])
index_map, num_segments = felzenszwalb(edges, num_vertices, k, [min_size])</code></pre><p>Segments an image using Felzenszwalb&#39;s graph-based algorithm. The function can be used in either of two ways -</p><ol><li><code>segments = felzenszwalb(img, k, [min_size])</code></li></ol><p>Segments an image using Felzenszwalb&#39;s segmentation algorithm and returns the result as <code>SegmentedImage</code>. The algorithm uses euclidean distance in color space as edge weights for the region adjacency graph.</p><p>Parameters:</p><ul><li>img            = input image</li><li>k              = Threshold for region merging step. Larger threshold will result in bigger segments.</li><li>min_size       = Minimum segment size</li></ul><ol><li><code>index_map, num_segments = felzenszwalb(edges, num_vertices, k, [min_size])</code></li></ol><p>Segments an image represented as Region Adjacency Graph(RAG) using Felzenszwalb&#39;s segmentation algorithm. Each pixel/region  corresponds to a node in the graph and weights on each edge measure the dissimilarity between pixels. The function returns the number of segments and index mapping from nodes of the RAG to segments.</p><p>Parameters:</p><ul><li>edges          = Array of edges in RAG. Each edge is represented as <code>ImageEdge</code>.</li><li>num_vertices   = Number of vertices in RAG</li><li>k              = Threshold for region merging step. Larger threshold will result in bigger segments.</li><li>min_size       = Minimum segment size</li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageSegmentation.fast_scanning" href="#ImageSegmentation.fast_scanning"><code>ImageSegmentation.fast_scanning</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">seg_img = fast_scanning(img, threshold, [diff_fn])</code></pre><p>Segments the N-D image using a fast scanning algorithm and returns a <a href="#ImageSegmentation.SegmentedImage"><code>SegmentedImage</code></a> containing information about the segments.</p><p><strong>Arguments:</strong></p><ul><li><code>img</code>         : N-D image to be segmented (arbitrary axes are allowed)</li><li><code>threshold</code>   : Upper bound of the difference measure (δ) for considering                 pixel into same segment; an <code>AbstractArray</code> can be passed                 having same number of dimensions as that of <code>img</code> for adaptive                 thresholding</li><li><code>diff_fn</code>     : (Optional) Function that returns a difference measure (δ)                 between the mean color of a region and color of a point</li></ul><p><strong>Examples:</strong></p><pre><code class="language-julia-repl">julia&gt; img = zeros(Float64, (3,3));

julia&gt; img[2,:] .= 0.5;

julia&gt; img[:,2] .= 0.6;

julia&gt; seg = fast_scanning(img, 0.2);

julia&gt; labels_map(seg)
3×3 Array{Int64,2}:
 1  4  5
 4  4  4
 3  4  6</code></pre><p><strong>Citation:</strong></p><p>Jian-Jiun Ding, Cheng-Jin Kuo, Wen-Chih Hong, &quot;An efficient image segmentation technique by fast scanning and adaptive merging&quot;</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageSegmentation.watershed" href="#ImageSegmentation.watershed"><code>ImageSegmentation.watershed</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">segments                = watershed(img, markers)</code></pre><p>Segments the image using watershed transform. Each basin formed by watershed transform corresponds to a segment. If you are using image local minimas as markers, consider using <a href="#ImageSegmentation.hmin_transform"><code>hmin_transform</code></a> to avoid oversegmentation.</p><p>Parameters:</p><ul><li>img            = input grayscale image</li><li>markers        = An array (same size as img) with each region&#39;s marker assigned a index starting from 1. Zero means not a marker.                     If two markers have the same index, their regions will be merged into a single region.                     If you have markers as a boolean array, use <code>label_components</code>.</li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageSegmentation.hmin_transform" href="#ImageSegmentation.hmin_transform"><code>ImageSegmentation.hmin_transform</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">out = hmin_transform(img, h)</code></pre><p>Suppresses all minima in grayscale image whose depth is less than h.</p><p>H-minima transform is defined as the reconstruction by erosion of (img + h) by img. See Morphological image analysis by Soille pg 170-172.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageSegmentation.region_adjacency_graph" href="#ImageSegmentation.region_adjacency_graph"><code>ImageSegmentation.region_adjacency_graph</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">G, vert_map = region_adjacency_graph(seg, weight_fn)</code></pre><p>Constructs a region adjacency graph (RAG) from the <code>SegmentedImage</code>. It returns the RAG along with a Dict(label=&gt;vertex) map. <code>weight_fn</code> is used to assign weights to the edges.</p><pre><code class="language-none">weight_fn(label1, label2)</code></pre><p>Returns a real number corresponding to the weight of the edge between label1 and label2.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageSegmentation.rem_segment" href="#ImageSegmentation.rem_segment"><code>ImageSegmentation.rem_segment</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">new_seg = rem_segment(seg, label, diff_fn)</code></pre><p>Removes the segment having label <code>label</code> and returns the new <code>SegmentedImage</code>. For more info, see <a href="@ref"><code>remove_segment!</code></a></p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageSegmentation.rem_segment!" href="#ImageSegmentation.rem_segment!"><code>ImageSegmentation.rem_segment!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">rem_segment!(seg, label, diff_fn)</code></pre><p>In place removal of the segment having label <code>label</code>, replacing it with the neighboring segment having least <code>diff_fn</code> value.</p><pre><code class="language-none">d = diff_fn(rem_label, neigh_label)</code></pre><p>A difference measure between label to be removed and its neighbors. <code>isless</code> must be defined for objects of the type of <code>d</code>.</p><p><strong>Examples</strong></p><pre><code class="language-julia">    # This removes the label `l` and replaces it with the label of
    # neighbor having maximum pixel count.
    julia&gt; rem_segment!(seg, l, (i,j)-&gt;(-seg.segment_pixel_count[j]))

    # This removes the label `l` and replaces it with the label of
    # neighbor having the least value of euclidian metric.
    julia&gt; rem_segment!(seg, l, (i,j)-&gt;sum(abs2, seg.segment_means[i]-seg.segment_means[j]))</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageSegmentation.prune_segments" href="#ImageSegmentation.prune_segments"><code>ImageSegmentation.prune_segments</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">new_seg = prune_segments(seg, rem_labels, diff_fn)</code></pre><p>Removes all segments that have labels in <code>rem_labels</code> replacing them with their neighbouring segment having least <code>diff_fn</code>. <code>rem_labels</code> is a <code>Vector</code> of labels.</p><pre><code class="language-none">new_seg = prune_segments(seg, is_rem, diff_fn)</code></pre><p>Removes all segments for which <code>is_rem</code> returns true replacing them with their neighbouring segment having least <code>diff_fn</code>.</p><pre><code class="language-none">is_rem(label) -&gt; Bool</code></pre><p>Returns true if label <code>label</code> is to be removed otherwise false.</p><pre><code class="language-none">d = diff_fn(rem_label, neigh_label)</code></pre><p>A difference measure between label to be removed and its neighbors. <code>isless</code> must be defined for objects of the type of <code>d</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageSegmentation.region_tree" href="#ImageSegmentation.region_tree"><code>ImageSegmentation.region_tree</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">t = region_tree(img, homogeneous)</code></pre><p>Creates a region tree from <code>img</code> by splitting it recursively until all the regions are homogeneous.</p><pre><code class="language-none">b = homogeneous(img)</code></pre><p>Returns true if <code>img</code> is homogeneous.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; img = 0.1*rand(6, 6);

julia&gt; img[4:end, 4:end] .+= 10;

julia&gt; function homogeneous(img)
           min, max = extrema(img)
           max - min &lt; 0.2
       end
homogeneous (generic function with 1 method)

julia&gt; t = region_tree(img, homogeneous);</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageSegmentation.region_splitting" href="#ImageSegmentation.region_splitting"><code>ImageSegmentation.region_splitting</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">seg = region_splitting(img, homogeneous)</code></pre><p>Segments <code>img</code> by recursively splitting it until all the segments are homogeneous.</p><pre><code class="language-none">b = homogeneous(img)</code></pre><p>Returns true if <code>img</code> is homogeneous.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl">julia&gt; img = 0.1*rand(6, 6);

julia&gt; img[4:end, 4:end] .+= 10;

julia&gt; function homogeneous(img)
           min, max = extrema(img)
           max - min &lt; 0.2
       end
homogeneous (generic function with 1 method)

julia&gt; seg = region_splitting(img, homogeneous);</code></pre></div></section></article><h2 id="ImageFeatures-1"><a class="docs-heading-anchor" href="#ImageFeatures-1">ImageFeatures</a><a class="docs-heading-anchor-permalink" href="#ImageFeatures-1" title="Permalink"></a></h2><h3 id="Types-1"><a class="docs-heading-anchor" href="#Types-1">Types</a><a class="docs-heading-anchor-permalink" href="#Types-1" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="ImageFeatures.Feature" href="#ImageFeatures.Feature"><code>ImageFeatures.Feature</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">feature = Feature(keypoint, orientation = 0.0, scale = 0.0)</code></pre><p>The <code>Feature</code> type has the keypoint, its orientation and its scale.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFeatures.Features" href="#ImageFeatures.Features"><code>ImageFeatures.Features</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">features = Features(boolean_img)
features = Features(keypoints)</code></pre><p>Returns a <code>Vector{Feature}</code> of features generated from the <code>true</code> values in a boolean image or from a list of keypoints.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFeatures.Keypoint" href="#ImageFeatures.Keypoint"><code>ImageFeatures.Keypoint</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">keypoint = Keypoint(y, x)
keypoint = Keypoint(feature)</code></pre><p>A <code>Keypoint</code> may be created by passing the coordinates of the point or from a feature.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFeatures.Keypoints" href="#ImageFeatures.Keypoints"><code>ImageFeatures.Keypoints</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">keypoints = Keypoints(boolean_img)
keypoints = Keypoints(features)</code></pre><p>Creates a <code>Vector{Keypoint}</code> of the <code>true</code> values in a boolean image or from a list of features.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFeatures.BRIEF" href="#ImageFeatures.BRIEF"><code>ImageFeatures.BRIEF</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">brief_params = BRIEF([size = 128], [window = 9], [sigma = 2 ^ 0.5], [sampling_type = gaussian], [seed = 123])</code></pre><table><tr><th style="text-align: right">Argument</th><th style="text-align: right">Type</th><th style="text-align: right">Description</th></tr><tr><td style="text-align: right"><strong>size</strong></td><td style="text-align: right">Int</td><td style="text-align: right">Size of the descriptor</td></tr><tr><td style="text-align: right"><strong>window</strong></td><td style="text-align: right">Int</td><td style="text-align: right">Size of sampling window</td></tr><tr><td style="text-align: right"><strong>sigma</strong></td><td style="text-align: right">Float64</td><td style="text-align: right">Value of sigma used for inital gaussian smoothing of image</td></tr><tr><td style="text-align: right"><strong>sampling_type</strong></td><td style="text-align: right">Function</td><td style="text-align: right">Type of sampling used for building the descriptor (See <a href="#brief-sampling-patterns">BRIEF Sampling Patterns</a>)</td></tr><tr><td style="text-align: right"><strong>seed</strong></td><td style="text-align: right">Int</td><td style="text-align: right">Random seed used for generating the sampling pairs. For matching two descriptors, the seed used to build both should be same.</td></tr></table></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFeatures.ORB" href="#ImageFeatures.ORB"><code>ImageFeatures.ORB</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">orb_params = ORB([num_keypoints = 500], [n_fast = 12], [threshold = 0.25], [harris_factor = 0.04], [downsample = 1.3], [levels = 8], [sigma = 1.2])</code></pre><table><tr><th style="text-align: right">Argument</th><th style="text-align: right">Type</th><th style="text-align: right">Description</th></tr><tr><td style="text-align: right"><strong>num_keypoints</strong></td><td style="text-align: right">Int</td><td style="text-align: right">Number of keypoints to extract and size of the descriptor calculated</td></tr><tr><td style="text-align: right"><strong>n_fast</strong></td><td style="text-align: right">Int</td><td style="text-align: right">Number of consecutive pixels used for finding corners with FAST. See [<code>fastcorners</code>]</td></tr><tr><td style="text-align: right"><strong>threshold</strong></td><td style="text-align: right">Float64</td><td style="text-align: right">Threshold used to find corners in FAST. See [<code>fastcorners</code>]</td></tr><tr><td style="text-align: right"><strong>harris_factor</strong></td><td style="text-align: right">Float64</td><td style="text-align: right">Harris factor <code>k</code> used to rank keypoints by harris responses and extract the best ones</td></tr><tr><td style="text-align: right"><strong>downsample</strong></td><td style="text-align: right">Float64</td><td style="text-align: right">Downsampling parameter used while building the gaussian pyramid. See [<code>gaussian_pyramid</code>] in Images.jl</td></tr><tr><td style="text-align: right"><strong>levels</strong></td><td style="text-align: right">Int</td><td style="text-align: right">Number of levels in the gaussian pyramid.  See [<code>gaussian_pyramid</code>] in Images.jl</td></tr><tr><td style="text-align: right"><strong>sigma</strong></td><td style="text-align: right">Float64</td><td style="text-align: right">Used for gaussian smoothing in each level of the gaussian pyramid.  See [<code>gaussian_pyramid</code>] in Images.jl</td></tr></table></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFeatures.FREAK" href="#ImageFeatures.FREAK"><code>ImageFeatures.FREAK</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">freak_params = FREAK([pattern_scale = 22.0])</code></pre><table><tr><th style="text-align: right">Argument</th><th style="text-align: right">Type</th><th style="text-align: right">Description</th></tr><tr><td style="text-align: right"><strong>pattern_scale</strong></td><td style="text-align: right">Float64</td><td style="text-align: right">Scaling factor for the sampling window</td></tr></table></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFeatures.BRISK" href="#ImageFeatures.BRISK"><code>ImageFeatures.BRISK</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">brisk_params = BRISK([pattern_scale = 1.0])</code></pre><table><tr><th style="text-align: right">Argument</th><th style="text-align: right">Type</th><th style="text-align: right">Description</th></tr><tr><td style="text-align: right"><code>pattern_scale</code></td><td style="text-align: right"><code>Float64</code></td><td style="text-align: right">Scaling factor for the sampling window</td></tr></table></div></section></article><h3 id="Corners-1"><a class="docs-heading-anchor" href="#Corners-1">Corners</a><a class="docs-heading-anchor-permalink" href="#Corners-1" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="ImageFeatures.corner_orientations" href="#ImageFeatures.corner_orientations"><code>ImageFeatures.corner_orientations</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">orientations = corner_orientations(img)
orientations = corner_orientations(img, corners)
orientations = corner_orientations(img, corners, kernel)</code></pre><p>Returns the orientations of corner patches in an image. The orientation of a corner patch is denoted by the orientation of the vector between intensity centroid and the corner. The intensity centroid can be calculated as <code>C = (m01/m00, m10/m00)</code> where mpq is defined as -</p><pre><code class="language-none">`mpq = (x^p)(y^q)I(y, x) for each p, q in the corner patch`</code></pre><p>The kernel used for the patch can be given through the <code>kernel</code> argument. The default kernel used is a gaussian kernel of size <code>5x5</code>.</p></div></section></article><h3 id="BRIEF-Sampling-Patterns-1"><a class="docs-heading-anchor" href="#BRIEF-Sampling-Patterns-1">BRIEF Sampling Patterns</a><a class="docs-heading-anchor-permalink" href="#BRIEF-Sampling-Patterns-1" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="ImageFeatures.random_uniform" href="#ImageFeatures.random_uniform"><code>ImageFeatures.random_uniform</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">sample_one, sample_two = random_uniform(size, window, seed)</code></pre><p>Builds sampling pairs using random uniform sampling.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFeatures.random_coarse" href="#ImageFeatures.random_coarse"><code>ImageFeatures.random_coarse</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">sample_one, sample_two = random_coarse(size, window, seed)</code></pre><p>Builds sampling pairs using random sampling over a coarse grid.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFeatures.gaussian" href="#ImageFeatures.gaussian"><code>ImageFeatures.gaussian</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">sample_one, sample_two = gaussian(size, window, seed)</code></pre><p>Builds sampling pairs using gaussian sampling.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFeatures.gaussian_local" href="#ImageFeatures.gaussian_local"><code>ImageFeatures.gaussian_local</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">sample_one, sample_two = gaussian_local(size, window, seed)</code></pre><p>Pairs <code>(Xi, Yi)</code> are randomly sampled using a Gaussian distribution where first <code>X</code> is sampled with a standard deviation of <code>0.04*S^2</code> and then the <code>Yi’s</code> are sampled using a Gaussian distribution – Each <code>Yi</code> is sampled with mean <code>Xi</code> and standard deviation of <code>0.01 * S^2</code></p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFeatures.center_sample" href="#ImageFeatures.center_sample"><code>ImageFeatures.center_sample</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">sample_one, sample_two = center_sample(size, window, seed)</code></pre><p>Builds sampling pairs <code>(Xi, Yi)</code> where <code>Xi</code> is <code>(0, 0)</code> and <code>Yi</code> is sampled uniformly from the window.</p></div></section></article><h3 id="Feature-Description-1"><a class="docs-heading-anchor" href="#Feature-Description-1">Feature Description</a><a class="docs-heading-anchor-permalink" href="#Feature-Description-1" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="ImageFeatures.create_descriptor" href="#ImageFeatures.create_descriptor"><code>ImageFeatures.create_descriptor</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">desc, keypoints = create_descriptor(img, keypoints, params)
desc, keypoints = create_descriptor(img, params)</code></pre><p>Create a descriptor for each entry in <code>keypoints</code> from the image <code>img</code>. <code>params</code> specifies the parameters for any of several descriptors:</p><ul><li><a href="#ImageFeatures.BRIEF"><code>BRIEF</code></a></li><li><a href="#ImageFeatures.ORB"><code>ORB</code></a></li><li><a href="#ImageFeatures.BRISK"><code>BRISK</code></a></li><li><a href="#ImageFeatures.FREAK"><code>FREAK</code></a></li><li><a href="@ref"><code>HOG</code></a></li></ul><p>Some descriptors support discovery of the <code>keypoints</code> from <a href="#Images.fastcorners"><code>fastcorners</code></a>.</p></div></section></article><h3 id="Feature-Matching-1"><a class="docs-heading-anchor" href="#Feature-Matching-1">Feature Matching</a><a class="docs-heading-anchor-permalink" href="#Feature-Matching-1" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="ImageFeatures.hamming_distance" href="#ImageFeatures.hamming_distance"><code>ImageFeatures.hamming_distance</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">distance = hamming_distance(desc_1, desc_2)</code></pre><p>Calculates the hamming distance between two descriptors.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="ImageFeatures.match_keypoints" href="#ImageFeatures.match_keypoints"><code>ImageFeatures.match_keypoints</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia">matches = match_keypoints(keypoints_1, keypoints_2, desc_1, desc_2, threshold = 0.1)</code></pre><p>Finds matched keypoints using the <a href="#ImageFeatures.hamming_distance"><code>hamming_distance</code></a> function having distance value less than <code>threshold</code>.</p></div></section></article><h3 id="Texture-Matching-1"><a class="docs-heading-anchor" href="#Texture-Matching-1">Texture Matching</a><a class="docs-heading-anchor-permalink" href="#Texture-Matching-1" title="Permalink"></a></h3><h4 id="Gray-Level-Co-occurence-Matrix-1"><a class="docs-heading-anchor" href="#Gray-Level-Co-occurence-Matrix-1">Gray Level Co-occurence Matrix</a><a class="docs-heading-anchor-permalink" href="#Gray-Level-Co-occurence-Matrix-1" title="Permalink"></a></h4><pre><code class="language-julia">glcm
glcm_symmetric
glcm_norm
glcm_prop
max_prob
contrast
ASM
IDM
glcm_entropy
energy
dissimilarity
correlation
glcm_mean_ref
glcm_mean_neighbour
glcm_var_ref
glcm_var_neighbour</code></pre><h4 id="Local-Binary-Patterns-1"><a class="docs-heading-anchor" href="#Local-Binary-Patterns-1">Local Binary Patterns</a><a class="docs-heading-anchor-permalink" href="#Local-Binary-Patterns-1" title="Permalink"></a></h4><pre><code class="language-julia">lbp
modified_lbp
direction_coded_lbp
lbp_original
lbp_uniform
lbp_rotation_invariant
multi_block_lbp</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../democards/examples/">« Demos</a><a class="docs-footer-nextpage" href="../api_comparison/">Comparison with other image processing frameworks »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Tuesday 11 February 2020 07:31">Tuesday 11 February 2020</span>. Using Julia version 1.0.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
